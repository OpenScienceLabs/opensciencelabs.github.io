[{"body":"","link":"https://opensciencelabs.org/","section":"","tags":null,"title":""},{"body":"","link":"https://opensciencelabs.org/blog/","section":"blog","tags":null,"title":"Blog"},{"body":"","link":"https://opensciencelabs.org/categories/","section":"categories","tags":null,"title":"Categories"},{"body":"","link":"https://opensciencelabs.org/tags/google-summer-of-code/","section":"tags","tags":null,"title":"google summer of code"},{"body":"Google Summer of Code- Week 4th \u0026amp; 7th Midterm Evaluation In this article, I will share the progress for Week 4th week to 7th week for my contribution to Open-science labs as a part of Google Summer of Code 2023.\nAs my Google Summer of Code journey continued, I found myself faced with an exciting yet daunting task: implementing a whole new build-system as an option for templates in the esteemed Open-Science Lab. This endeavor demanded meticulous planning, unwavering dedication, and the exploration of various build-systems, including Maturin, Hatchling, Scikit-build, and pybuild11.\nIn this period, I started working on to add support for Maturin build-system.\nMaturin Maturin was the first build-system I explored. Its unique approach of building Python bindings for Rust libraries intrigued me, and I wondered if it could provide a novel solution to the lab's needs. The seamless blending of Python and Rust offered the potential for unparalleled performance and memory efficiency in research projects. However, I faced a steep learning curve to master the intricacies of Rust and its integration with Python. Overcoming these challenges was a significant achievement, and I managed to create a functional prototype that demonstrated Maturin's potential to revolutionize the Open-Science Lab's workflow. My contribution to this issue is here\nAfter merging this pull request, I started to add support for Hatchling build-system.\nHatchling Hatchling known for its user-friendly nature, was my next target. It promised to simplify the build and deployment processes, which could be particularly beneficial for newcomers to the lab and projects with straightforward requirements. Integrating Hatchling into the lab's ecosystem required thorough documentation and integration tests to ensure its smooth adoption. Overcoming initial hurdles, I was elated to see the positive response from the lab's community as they began adopting Hatchling for their projects. My contribution to this issue is here\nAfter completetion of this issue, I jumped to a task to add support for Scikit-Build-Core.\nScikit-build-core Scikit-build-core a cross-platform build-system, offered a robust option for integrating CPython extensions. While challenging to implement, I recognized its potential to support projects with complex native code dependencies. My experience with Scikit-build exposed me to advanced build and packaging concepts, and I was thrilled to see it complementing the existing build-systems in the lab, catering to a broader range of projects. My contribution to this issue is here\nConclusions In conclusion, my Google Summer of Code experience with implementing new build-systems for the Open-Science Lab was a transformative journey. Overcoming hurdles with Maturin, embracing user-friendliness with Hatchling, exploring the potential of Scikit-build.I realized the importance of innovation and adaptability in the world of open-source development. This experience has not only enriched my technical skills but also instilled in me a passion for contributing to projects that drive positive change in the world of scientific research. As I look to the future, I am excited to continue this journey, collaborating with the open-source community to create solutions that empower researchers and advance the boundaries of knowledge.\nYou can read my previous blog here\nIf want to connect with me on LinkedIn here. Github here.\n","link":"https://opensciencelabs.org/blog/google-summer-of-code-week-4th-and-7th-midterm-evaluation/","section":"blog","tags":["google summer of code","gsoc","open-source open-sciencelab"],"title":"Google Summer of Code- Week 4th \u0026 7th Midterm Evaluation"},{"body":"","link":"https://opensciencelabs.org/tags/gsoc/","section":"tags","tags":null,"title":"gsoc"},{"body":"","link":"https://opensciencelabs.org/categories/gsoc/","section":"categories","tags":null,"title":"gsoc"},{"body":"","link":"https://opensciencelabs.org/categories/open-source/","section":"categories","tags":null,"title":"open-source"},{"body":"","link":"https://opensciencelabs.org/tags/open-source-open-sciencelab/","section":"tags","tags":null,"title":"open-source open-sciencelab"},{"body":"","link":"https://opensciencelabs.org/tags/","section":"tags","tags":null,"title":"Tags"},{"body":"OSL Team OSL is a Open-Source community and everyone can join, check our GitHub to be apart of the issues.\nHow can you contribute? To be contributing with the community you must know our Guidelines, there you will find the workflow of the running projects and how you can apply to our team.\n","link":"https://opensciencelabs.org/team/","section":"team","tags":null,"title":"OSL Team"},{"body":"","link":"https://opensciencelabs.org/tags/apache-superset/","section":"tags","tags":null,"title":"apache superset"},{"body":"","link":"https://opensciencelabs.org/categories/ciencia-de-datos/","section":"categories","tags":null,"title":"ciencia de datos"},{"body":"Fuente:Apache Superset\nSi eres analista o científico de datos, investigador, trabajas en un equipo de inteligencia de negocios o simplemente estás buscando una plataforma atractiva que te permita explorar y visualizar tus datos de manera rápida y eficiente a gran escala; aquí te presentamos Apache Superset. Conoce con nosotros sus características más importantes, las funcionalidades que ofrece, algunas empresas que lo utilizan y cómo hacer tu primer gráfico y dashboard.\n¿Qué es Apache Superset? Es una plataforma moderna muy utilizada en equipos de inteligencia de negocios. Una aplicación web de código abierto implementada en Python que está en período de incubación en The Apache Software Foundation (ASF) y es patrocinada por Apache Incubator. Cuenta con una interfaz simple y permite al usuario crear y compartir dashboards, explorar, filtrar y organizar datos a gran escala, esto significa que puedes modificar la aplicación según tus necesidades.\nEsta iniciativa comenzó en Airbnb en 2015 como un proyecto de hackathon y se unió al programa Apache Incubator en 2017. Para 2021, la Apache Software Foundation anunció que Superset era un proyecto de alto nivel. Puedes encontrar el proyecto alojado en GitHub.\nCaracterísticas y funcionalidades Es intuitivo y rápido.\nBrinda una amplia variedad de opciones de gráficos y consultas que facilitan la exploración y visualización de datos. Así como la creación de reportes.\nEs utilizado por usuarios con todo tipo de conocimientos. No necesitas ser experto en programación o SQL para usarlo.\nPermite la creación de dashboards interactivos y gráficos sin escribir código.\nEs compatible con la mayoría de fuentes de datos basadas en SQL a través de SQLAlchemy, entre ellas: Amazon Redshift, druid, ClickHouse, databricks, MySQL, SQLServer, SQLite, PostgreSQL, entre otras. Puedes consultar esta lista con todas las fuentes de datos que soporta Superset.\nOfrece un entorno llamado SQL Lab que permite hacer consultas SQL para la exploración de los datos antes de la representación gráfica.\nProporciona un sencillo e intuitivo constructor de visualizaciones sin código que te permite personalizar tus gráficos.\nTiene una arquitectura nativa de la nube. Permite escalar a grandes entornos distribuidos y funciona bien dentro de contenedores. Es flexible y permite elegir el servidor web, motor de base de datos, cola de mensajes, backend de resultados y capa de almacenamiento en caché.\nSu instalación y configuración es rápida.\nPermite trabajar con grandes configuraciones de data lake y data warehouse.\nBrinda un modelo de seguridad con reglas complejas que pueden configurarse de acuerdo a quién puede acceder y a qué características.\nTiene la posibilidad de añadir plugins de visualizaciones personalizados.\nHemos visto una gran cantidad de ventajas y funcionalidades que ofrece Superset. Debido a esto, existe una gran variedad de industrias y empresas que lo utilizan en sus tareas, entre ellas se encuentran: Airbnb, American Express, Netflix, Udemy, Twitter. Puedes consultar una lista más amplia aquí\nEpiGraphHub: un ejemplo de Superset EpiGraphHub es una aplicación web para el manejo y visualización de datos de salud pública.\nFuente:EpigraphHub Superset\nAllí puedes crear una cuenta o ingresar con la cuenta de invitado para la cual el usuario y la contraseña es guest. EpiGrapHub Superset te ofrece una variedad de dashboards referentes, entre otras cosas, a datos de COVID en distintos países y continentes. Allí se visualizan características importantes en cada caso (sexo, fecha, grupos de edad, número de casos positivos, división política, estado de salud, entre otras). Podemos explorar estos datos a través de sus servidores.\nA continuación te mostramos un dashboard en el Superset de EpiGraphHub.\nFuente:EpigraphHub Superset\nPuedes conocer más sobre EpiGrapHub en nuestro artículo: EpiGraphHub: un proyecto de código abierto para el análisis de datos de calidad\nCómo iniciar con Superset A continuación te presentamos algunas formas diferentes de empezar con Superset:\nDescarga el código fuente del sitio web de The Apache Foundation\nDescarga la última versión de Superset desde Pypi\nConfigura Superset localmente con un comando usando Docker Compose\nDescarga el Docker image desde Dockerhub\nInstala la última versión de Superset desde GitHub\nPuedes consultar sobre la instalación y configuración de Superset aquí.\nUna introducción a cómo crear tu primer dashboard Si vas a utilizar Superset para tu flujo de trabajo de análisis y exploración de datos, a continuación te mostramos algunos pasos necesarios que te permitirán crear un gráfico y guardarlo en un dashboard en esta aplicación. Puedes consultar un paso a paso más detallado sobre esto en la documentación oficial de Superset.\nConectar Superset a una nueva base de datos. Como Superset no puede guardar los datos, debe conectarse a una base de datos existente que soporte SQL. Inicialmente debemos añadir las credenciales de conexión a esa base de datos para poder consultar y visualizar los datos.\nEste paso puede obviarse si se utiliza Superset localmente a través de Docker compose. Esto se debe a que está incluida, preconfigurada y disponible una base de datos Postgres, llamada examples.\nPara hacer la conexión, seleccionamos la opción Databases del menú Data y seguimos los pasos para crear y probar la conexión.\nRegistrar una tabla en la base de datos. Ahora seleccionamos las tablas específicas (denominadas datasets en Superset) que deseemos explorar. Esto lo hacemos seleccionando la opción Data, luego Datasets y nuevo dataset (en la esquina superior derecha). Seleccionamos la base de datos, el esquema, la tabla y añadimos estos cambios.\nPersonalizar las propiedades de las columnas. Se configuran las propiedades de las columnas como: tipo de dato, si la columna es temporal, si debe ser filtrada, si es dimensional, cómo debe tratarla Superset si es una columna de fecha-hora, entre otras. Esto se hace para saber cómo deben manejarse las columnas del dataset al momento de la exploración.\nCapa semántica de Superset. Esta capa nos ofrece mejoras como analistas, puede almacenar 2 tipos de datos calculados:\nMétricas virtuales: podemos escribir consultas SQL con funciones de agregación para varias columnas y colocar los resultados como nuevas columnas disponibles para la visualización.\nColumnas calculadas virtuales: también podemos hacer consultas SQL que involucren cambios en la apariencia o el comportamiento de una columna específica, por ejemplo, cambiar el tipo de dato que almacena. No debemos usar funciones de agregación, como SUM, en las columnas calculadas.\nCrear gráficos en la vista de exploración. En Superset podemos explorar los datos utilizando dos interfaces:\nExplore: es un constructor de visualizaciones sin código. Es tan simple como seleccionar el dataset, el tipo de gráfico que corresponda, lo personalizamos y lo publicamos.\nSQL Lab: es un IDE (Entorno de Desarrollo Integrado) que nos permite preparar y unir los datos que son tomados en el flujo de trabajo de Explore.\nPara crear un gráfico, si estamos en la pestaña Datasets hacemos clic en el nombre del dataset y así inicamos el flujo de trabajo de la vista Explore. Aquí se muestra una vista del dataset con una lista de las columnas y las métricas (en el lado izquierdo). También se observa una vista previa de los datos en la parte inferior. Esta vista contiene las pestañas Data y Customize (datos y personalizar, respectivamente), a partir de allí podemos interactuar cambiando el tipo de visualización, seleccionando distintas métricas para mostrar los datos y personalizando la estética del gráfico. Cabe resaltar que cada vez que hacemos un cambio, debemos ejecutarlo haciendo clic en el botón RUN de la parte superior.\nGuardar un gráfico en un dashboard. Luego de crear el gráfico lo guardamos haciendo clic en el botón Save en la parte superior de la vista. Podemos guardarlo y añadirlo a un dashboard existente o a uno nuevo. Para publicarlo, hacemos clic en Save and goto Dashboard. Podemos cambiar el tamaño del gráfico, haciendo clic en el botón del lápiz en la esquina superior derecha.\nY !Esto es todo! hemos creado un gráfico y lo añadimos a un dashboard en Superset. Existen muchas opciones de configuración y visualización de datasets, es cuestión de que comiences a probar y explorar y te sorprenderás de lo que puedes lograr con esta plataforma.\nOtros recursos Consulta el CONTRIBUTING.md del proyecto si estás interesado en contribuir. Este contiene también una guía detallada sobre cómo configurar un entorno de desarrollo. Referencias Website de Apache Superset\nDocumentación oficial de Apache Superset\n","link":"https://opensciencelabs.org/blog/apache-superset/","section":"blog","tags":["apache superset","datos","visualización de datos","dashboard"],"title":"Crea una aplicación web eficiente y atractiva para el manejo, exploración y visualización de datos con Apache Superset"},{"body":"","link":"https://opensciencelabs.org/tags/dashboard/","section":"tags","tags":null,"title":"dashboard"},{"body":"","link":"https://opensciencelabs.org/tags/datos/","section":"tags","tags":null,"title":"datos"},{"body":"","link":"https://opensciencelabs.org/categories/sql/","section":"categories","tags":null,"title":"SQL"},{"body":"","link":"https://opensciencelabs.org/tags/visualizaci%C3%B3n-de-datos/","section":"tags","tags":null,"title":"visualización de datos"},{"body":"","link":"https://opensciencelabs.org/tags/an%C3%A1lisis/","section":"tags","tags":null,"title":"análisis"},{"body":"","link":"https://opensciencelabs.org/categories/ciencia-abierta/","section":"categories","tags":null,"title":"ciencia abierta"},{"body":"","link":"https://opensciencelabs.org/categories/c%C3%B3digo-abierto/","section":"categories","tags":null,"title":"código abierto"},{"body":"","link":"https://opensciencelabs.org/tags/epidemiolog%C3%ADa/","section":"tags","tags":null,"title":"epidemiología"},{"body":"","link":"https://opensciencelabs.org/tags/epigraphhub/","section":"tags","tags":null,"title":"epigraphhub"},{"body":"¿Quieres realizar un análisis y no encuentras datos?, ¿quieres realizar visualizaciones como dashboards o gráficos?, o simplemente explorar, ¿cómo puedes analizar datos? Entonces este artículo es para ti. Vamos a describir EpiGraphHub, un proyecto de código abierto orientado al análisis de datos de calidad.\n¿Qué es EpiGraphHub? Es una plataforma de código abierto que integra y permite gestionar datos de diversas fuentes. Fue diseñada principalmente para describir datos de salud pública, pero incluye otros tópicos como socio-economía, demografía o censos. Esto es posible porque posee conectores a muchas bases de datos y conjuntos de datos abiertos.\nCon EpiGraphHub podemos hacer exploraciones rápidas y dashboarding (gráficos interactivos). Además, puede servir como backend de datos para apps analíticas.\nSus funciones de visualización están impulsadas por Apache Echarts, está compuesta por un servidor de bases de datos Postgresql integrado con un frontend web Apache Superset personalizado para el acceso y la exploración de datos.\nCuenta con servidores, lo que nos permite acceder a grandes cantidades de datos sin que tengamos que preocuparnos si nuestro computador soporta o no cientos de datos.\nEpiGraphHub, al ser un proyecto de código abierto permite que cualquiera pueda tomarlo y trabajar con él, lo hace disponible para programadores, empresarios, analistas de datos y el público en general. Otro aspecto importante es que puede conectarse a bases de datos locales, remotas o en la nube, incluso hojas de cálculo de Google y su equipo está constantemente recopilando conjuntos de datos abiertos relevantes. Esto nos permite más opciones en la exploración de datos.\nBibliotecas de EpiGraphHub Además de permitir hacer análisis visual, EpiGraphHub se complementa con bibliotecas, las cuales están diseñadas para proporcionar a los usuarios externos toda la funcionalidad analítica utilizada para potenciar la plataforma y sus aplicaciones.\nLas bibliotecas permiten realizar o aplicar:\nEstadística Bayesiana Análisis epidemiológico Modelado matemático Análisis de Costo-efectividad Pronósticos Aprendizaje automático Minería de textos Análisis Geoespacial Esto se encuentra disponible para los lenguajes de programación R y Python.\n¿Cómo utilizar la plataforma EpiGraphHub? Este procedimiento es muy sencillo, debes acceder a su dirección web: https://dash.epigraphhub.org/. Luego puedes crear un usuario o emplear la cuenta de invitado (usuario:guest y contraseña:guest).\nPara la cuenta de invitado no tienes todas las opciones disponibles, pero con ella puedes explorar los datasets y las bases de datos en los servidores. También tienes acceso a los dashboards y gráficos que los miembros del proyecto han generado.\nSi creas una cuenta tendrás una opción adicional en la que puedes realizar consultas a través de SQL y personalizar los datos de acuerdo a lo que necesites.\nEn caso de que deseas ver un tutorial de cómo funciona EpiGraphHub puedes dar clic aquí.\n¿Cómo unirse a la comunidad de EpiGraphHub? Si quieres formar parte de la comunidad de EpiGraphHub, puedes unirte a su servidor en Discord. Allí tienes un espacio para expresar tus preguntas, sugerencias o estar atento a los próximos eventos organizados en la comunidad.\n¿Cómo contribuir en EpiGraphHub? EpiGraphHub al ser un proyecto de código abierto crea espacios en los que es posible contribuir, su repositorio principal se encuentra en GitHub por lo que los issues y la forma en que podemos brindar nuestro granito de arena se encuentra expresado allí. Igualmente, si tienes dudas puedes acudir a Discord.\nEn resumen, EpiGraphHub es una herramienta que nos permite acceder y analizar datos a través de sus servidores, lo cual logra que trabajemos sin preocuparnos por la cantidad y el espacio que pudiesen ocupar en nuestro computador. También podemos utilizar sus funcionalidades para analizar datos almacenados en local y obtener resultados interesantes que no percibimos a simple vista en los datos. Además de esto, los gráficos y dashboards que podemos obtener a través de la plataforma son muy llamativos y podemos interactuar fácilmente con la información, recordemos que provienen de Apache Echarts.\nSi ya le echaste un vistazo a este proyecto puedes dejarnos tus comentarios a cerca de lo que percibiste y si te gustó.\nReferencias GRAPH Network. (2022, 1 junio). EpiGraphHub: a data integration platform for health | Flavio Coelho [Vídeo]. YouTube. Recuperado 28 de septiembre de 2022, de https://www.youtube.com/watch?v=8Mz52O_VzVc\u0026amp;feature=youtu.be\nWelcome to EpigraphHub libraries documentation! — EpigraphHub Library 2022-01-01 documentation. (s. f.). Recuperado 28 de septiembre de 2022, de https://epigraphhub-libraries.readthedocs.io/en/latest/\nEpiGraphHub. (s. f.). Recuperado 28 de septiembre de 2022, de https://epigraphhub.org/superset/welcome/\nEpidemias, D. M. A. (2022, 4 abril). Introduction to EpigraphHub. YouTube. Recuperado 28 de septiembre de 2022, de https://www.youtube.com/watch?v=JOxbiovCtdEf\u0026amp;feature=youtu.be\n","link":"https://opensciencelabs.org/blog/epigraphhub/","section":"blog","tags":["epigraphhub","visualización de datos","análisis","datos","epidemiología"],"title":"EpiGraphHub: un proyecto de código abierto para el análisis de datos de calidad"},{"body":"The Open Science Labs Guideline is a collection of documents about how to get started in specific areas. Articles In this section, there are the guideline about how to write the blog posts for Open Science Labs. OSL Blogs can be accessed at: https://opensciencelabs.org/blog/.\nVersión en Español Diversity, Equity and Inclusion (DEI) Open Science Labs (OSL) is a community that offers an open space to share, learn and teach topics related to Open Science and Computational Technologies to people from Latin America or any part of the world.\nDEI is a very important aspect of our community and we really care about that.\nIn this section we can find our initial DEI declaration.\nVersión en Español DevOps In this section, we have the documentation about all our infrastucture (work in progress), and our goal is to have the necessary information for anyone who wants to help us in the DevOps tasks.\nDiscord English Version Fund Raiser In the section, we are gathering all the information and investigation results about grants, institutes, fiscal sponsors, etc that can help us to decide the fund raising activities and help other communities as well.\nDocuments in Spanish:\nGuía para Recaudación de Fondos Posibles instituciones para aplicar por una subvención NumFOCUS como patrocinador fiscal Mentoring In this section, there are documents about Open Science Labs Mentoring program. The mentoring could be running as a community mentoring, where someone from the community for the mentoring program and Open Science Labs tries to find one mentor inside our community, using discord, or using the social media, in order to reach someone outside.\nAnother way that the mentoring can happen is inside the internship program.\nDocuments in Spanish:\nGuía de Mentorías Código de Conducta Google Summer of Code Documents in English:\nMentoring Guideline Code of Conduct Marketing In this section, we have some materials researched that maybe could be useful for other communities or for OSL in the future.\nOpen Collective Roadmap If you are interested in the Open Science Labs next steps, please check our Roadmap.\nGovernance For more information about our project governance, please check governance document.\n","link":"https://opensciencelabs.org/guidelines/","section":"guidelines","tags":null,"title":""},{"body":"","link":"https://opensciencelabs.org/tags/coc/","section":"tags","tags":null,"title":"coc"},{"body":"Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\nOur Standards Examples of behavior that contributes to a positive environment for our community include:\nDemonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include:\nThe use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\nScope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.\nEnforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at opensciencelabs@gmail.com. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident.\nEnforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n1. Correction Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n2. Warning Community Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n3. Temporary Ban Community Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n4. Permanent Ban Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community.\nAttribution This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.\n","link":"https://opensciencelabs.org/guidelines/coc/","section":"guidelines","tags":["coc"],"title":"Contributor Covenant Code of Conduct"},{"body":"","link":"https://opensciencelabs.org/categories/acceso-abierto/","section":"categories","tags":null,"title":"acceso abierto"},{"body":"","link":"https://opensciencelabs.org/tags/dataframe/","section":"tags","tags":null,"title":"dataframe"},{"body":"","link":"https://opensciencelabs.org/categories/datos-abiertos/","section":"categories","tags":null,"title":"datos abiertos"},{"body":"","link":"https://opensciencelabs.org/tags/ibis/","section":"tags","tags":null,"title":"ibis"},{"body":"Escalonando a Análise de Dados com Expressões Ibis Ibis Framework é uma biblioteca Python que gera expressões de busca em banco de dados. O framework foi idealizado por Wes McKinney, o mesmo criador do Pandas, voltado para integração de diferentes Engines de Bancos de Dados através de Expressões Ibis com Python.\nEnquanto os motores de busca e análise de dados crescem e ficam mais robustos com o avanço da era dos Dados, algumas complicações podem ser encontradas em diferentes ambientes de desenvolvimento. Um dos exemplos mais comuns é o crescimento de aplicações que realizam buscas SQL em um banco de dados, com o tempo as buscas se tornam complexas e de difícil leitura.\nAtualmente o Ibis possui 12 backends em seu escopo, alguns deles são responsáveis pela manipulação dos dados, outros, como por exemplo o SQLAlchemy, são responsáveis pela tradução das expressões Ibis em buscas SQL, etc. Você pode conferir todos os backends aqui.\nSetup e Base de Dados O Ibis pode ser instalado via pip ou conda. Nos exemplos a seguir utilizaremos apenas a instalação padrão do Ibis, mas você pode conferir como instalar outros Backends como o Google BigQuery, Apache Impala, PostgreSQL dependendo da sua necessidade.\n1!mamba install ibis-framework matplotlib sqlalchemy -c conda-forge -y Estaremos trabalhando com um dataset disponibilizado pelo Ministério da Saúde em formato CSV.\n1!wget -c https://data.brasil.io/dataset/covid19/caso_full.csv.gz \u0026amp;\u0026amp; gunzip -c caso_full.csv.gz \u0026gt; data/caso_full.csv 1import matplotlib.pyplot as plt 2import pandas as pd 3import sqlite3 4import ibis Como funciona o Ibis? O Ibis, a partir da criação de Expressões, se consitui em uma camada de abstração entre as Engines de banco de dados e o usuário final. Em seu backend, o Ibis utiliza Pandas como sua Engine de execução, então podemos ler o arquivo CSV com a função read_csv() do Pandas:\n1df = ibis.backends.pandas.pd.read_csv(\u0026#39;data/caso_full.csv\u0026#39;) 1df.head() city city_ibge_code date epidemiological_week estimated_population estimated_population_2019 is_last is_repeated last_available_confirmed last_available_confirmed_per_100k_inhabitants last_available_date last_available_death_rate last_available_deaths order_for_place place_type state new_confirmed new_deaths 0 Rio Branco 1200401.0 2020-03-17 202012 413418.0 407319.0 False False 3 0.72566 2020-03-17 0.0 0 1 city AC 3 0 1 NaN 12.0 2020-03-17 202012 894470.0 881935.0 False False 3 0.33539 2020-03-17 0.0 0 1 state AC 3 0 2 Rio Branco 1200401.0 2020-03-18 202012 413418.0 407319.0 False False 3 0.72566 2020-03-18 0.0 0 2 city AC 0 0 3 NaN 12.0 2020-03-18 202012 894470.0 881935.0 False False 3 0.33539 2020-03-18 0.0 0 2 state AC 0 0 4 Rio Branco 1200401.0 2020-03-19 202012 413418.0 407319.0 False False 4 0.96754 2020-03-19 0.0 0 3 city AC 1 0 1df.info() \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt; RangeIndex: 3853648 entries, 0 to 3853647 Data columns (total 18 columns): # Column Dtype --- ------ ----- 0 city object 1 city_ibge_code float64 2 date object 3 epidemiological_week int64 4 estimated_population float64 5 estimated_population_2019 float64 6 is_last bool 7 is_repeated bool 8 last_available_confirmed int64 9 last_available_confirmed_per_100k_inhabitants float64 10 last_available_date object 11 last_available_death_rate float64 12 last_available_deaths int64 13 order_for_place int64 14 place_type object 15 state object 16 new_confirmed int64 17 new_deaths int64 dtypes: bool(2), float64(5), int64(6), object(5) memory usage: 477.8+ MB E para demonstrar o verdadeiro poder do Ibis, iremos transformar nosso arquivo CSV em uma Base de Dados SQL. Na instalação padrão do Ibis, o backend SQL é o sqlite3, então nos exemplos a seguir utilizaremos SQLite para realizar buscas na base de dados. Caso queira utilizar outra Engine SQL, como BigQuery ou Postgres, acesse a documentação oficial e siga instruções de instalação.\n1df.to_sql(\u0026#39;casos_covid19_BR\u0026#39;, sqlite3.connect(\u0026#39;data/casof.db\u0026#39;)) 3853648 1con = ibis.sqlite.connect(\u0026#39;data/casof.db\u0026#39;) 2casos = con.table(\u0026#39;casos_covid19_BR\u0026#39;) O Ibis, junto com o SQLAlchemy, utiliza grafos para representar suas Expressões. Portanto é possível visualizar todas as etapas ocorridas no Backend com a configuração de representação de grafos ativa. Da mesma forma, podemos representar o Schema da nossa tabela através da função display():\n1ibis.options.graphviz_repr = True 2display(casos) Assim como no Pandas, as colunas podem ser chamadas diretamente. Entretanto, como o Ibis funciona por padrão em Lazy mode, o resultado da query não fica armazenado em memória e ela só será executada utilizando o comando execute(). O lazy mode busca diminuir a utilização da memória, ao invés de executar a busca quando o objeto é instanciado, o Ibis retorna uma expressão contendo os parâmetros de busca, executando a busca somente quando necessário:\n1# Semelhante ao pandas, podemos realizar uma busca SQL que retorna os valores max. e min. da coluna 2data_min = casos.date.min().name(\u0026#39;first_entry\u0026#39;) 3data_max = casos.date.max().name(\u0026#39;last_entry\u0026#39;) 1print(data_min.execute()) # Dia da primeira entrada registrada na base de dados 2print(data_max.execute()) # Dia da última entrada registrada na base de dados 2020-02-25 2022-03-27 E por que usar Ibis ao invés das ferramentas SQL diretamente? Ibis, por ser uma ferramenta escrita em Python, é atraente para quem não tem tanta familiaridade com SQL. Ao automatizar as buscas, novos desenvolvedores poderão entender como as buscas são feitas na Engine SQL. Com o crescimento da aplicação, os parâmetros de busca em SQL podem se tornar confusos e de difícil replicação. Com o Ibis é possível portabilizar as Expressões para serem reutilizadas em outras buscas sem a necessidade de reescrever código. Caso você esteja trabalhando com diferentes Engines SQL, seja por causa do tamanho da base de dados, por exemplo. Com o Ibis é possível rapidamente conectar à uma Engine que consiga lidar diferentes volumes de dados (ClickHouse, HeavyAI, etc) e continuar com o mesmo fluxo de trabalho. Por exemplo: já vimos que é possível criar buscas SQL através de expressões Ibis, entretanto, o oposto também pode ser visualizado. Com a função compile() podemos retornar os parâmetros da busca realizada pela Expressão Ibis na base de dados. Ou seja, é possível realizar análises das buscas na base de dados com facilidade, pois o Ibis te mostra como fez para retornar o resultado desejado:\n1print(data_min.compile()) SELECT min(t0.date) AS first_entry FROM main.\u0026quot;casos_covid19_BR\u0026quot; AS t0 Um dos pontos chave do Ibis, é a possibilidade de criar Expressões com o resultado de interesse, renomeá-las, e utilizá-las para outras buscas sem precisar repetir código:\n1total_new_cases = casos[\u0026#39;new_confirmed\u0026#39;].sum().name(\u0026#39;total_new_cases\u0026#39;) 2total_new_deaths = casos[\u0026#39;new_deaths\u0026#39;].sum().name(\u0026#39;total_new_deaths\u0026#39;) 1total_new_cases 1epiweek_covid = casos.group_by(\u0026#39;epidemiological_week\u0026#39;).aggregate(( 2 total_new_cases, 3 total_new_deaths, 4 )) 5 6print(epiweek_covid.compile()) SELECT t0.epidemiological_week, sum(t0.new_confirmed) AS total_new_cases, sum(t0.new_deaths) AS total_new_deaths FROM main.\u0026quot;casos_covid19_BR\u0026quot; AS t0 GROUP BY t0.epidemiological_week Lembra que o Ibis utiliza o Pandas como Backend de execução? Podemos agora salvar o Pandas DataFrame gerado na execução em uma variável para termos acesso às funções do Pandas:\n1df = epiweek_covid.execute() 2df.head() epidemiological_week total_new_cases total_new_deaths 0 202009 4 0 1 202010 33 0 2 202011 231 0 3 202012 1935 30 4 202013 5476 183 1df[\u0026#39;week\u0026#39;] = df[\u0026#39;epidemiological_week\u0026#39;].astype(str).str[4:6] 2df[\u0026#39;year\u0026#39;] = df[\u0026#39;epidemiological_week\u0026#39;].astype(str).str[0:4] 3 4df.pop(\u0026#39;epidemiological_week\u0026#39;) 5df.insert(0, \u0026#39;year\u0026#39;, df.pop(\u0026#39;year\u0026#39;)) 6df.insert(1, \u0026#39;week\u0026#39;, df.pop(\u0026#39;week\u0026#39;)) 7df.head() year week total_new_cases total_new_deaths 0 2020 09 4 0 1 2020 10 33 0 2 2020 11 231 0 3 2020 12 1935 30 4 2020 13 5476 183 1df = df.head(15) 2plt.bar(df.week, df.total_new_cases) 3plt.bar(df.week, df.total_new_deaths) 4plt.xlabel(\u0026#39;Epidemiological week\u0026#39;) 5plt.ylabel(\u0026#39;Population\u0026#39;) 6plt.legend([\u0026#39;New cases\u0026#39;, \u0026#39;New deaths\u0026#39;]) 7plt.show() Manipulando os dados e inserindo novas colunas: Os DataFrames gerados pelo Pandas Engine são estáticos. Isso quer dizer que ao manipular os dados, as expressões não alteram o DataFrame em si, mas preparam os parâmetros de busca para gerar um novo DataFrame a partir do comando execute(), que pode ser visualizado, armazenado e exportado.\nNo exemplo abaixo, estaremos parametrizando a busca a ser realizada na base de dados. Com uma sintaxe \u0026quot;Pandas-like\u0026quot;, pode-se imaginar que estaremos manipulando o DataFrame em si. Entretanto, o Ibis armazena o resultado desejado para que a busca seja realizada somente quando o resultado deve ser exibido, executando-o. Ao extrair as colunas como em percentage_cases, por exemplo, uma query SQL é armazenada\nOperações matemáticas entre as colunas podem ser escritas de maneira Pythonica com o Ibis e facilmente adicionadas em outros critérios de busca:\n1percentage_cases = (casos[\u0026#39;new_confirmed\u0026#39;] / casos[\u0026#39;estimated_population\u0026#39;] * 100).name(\u0026#39;porc_cases\u0026#39;) Assim como em SQL, when clauses podem ser usadas para extrair apenas certas partes dos dados. Neste exemplo estaremos extraindo as informações dos estados do Sul do país, para que no final seja retornado um DataFrame com os parâmetros definidos. Com o modo de gráficos ativo, podemos visualizar os passos armazenados nos parâmetros de busca:\n1south_br = (casos.state.case() 2 .when(\u0026#39;SC\u0026#39;, \u0026#39;Santa Catarina\u0026#39;) 3 .when(\u0026#39;RS\u0026#39;, \u0026#39;Rio Grande do Sul\u0026#39;) 4 .when(\u0026#39;PR\u0026#39;, \u0026#39;Parana\u0026#39;) 5 .end() 6 .name(\u0026#39;Regiao Sul\u0026#39;)) 7 8south_br Compilando as buscas com os parâmetros, podemos visualizar a query que acabamos de criar e que será executada com a função execute():\n1# Query SQL referente a `percentage_cases`: 2print(percentage_cases.compile().compile( 3 compile_kwargs={\u0026#34;literal_binds\u0026#34;: True})) SELECT (t0.new_confirmed / t0.estimated_population) * 100 AS porc_cases FROM main.\u0026quot;casos_covid19_BR\u0026quot; AS t0 1# Query SQL referente a `south_br` 2print(south_br.compile().compile( 3 compile_kwargs={\u0026#34;literal_binds\u0026#34;: True})) SELECT CASE WHEN (t0.state = 'SC') THEN 'Santa Catarina' WHEN (t0.state = 'RS') THEN 'Rio Grande do Sul' WHEN (t0.state = 'PR') THEN 'Parana' ELSE CAST(NULL AS TEXT) END AS \u0026quot;Regiao Sul\u0026quot; FROM main.\u0026quot;casos_covid19_BR\u0026quot; AS t0 Agora que temos a porcentagem de casos e a região separadas em duas variáveis, podemos agregar as buscas e encontrar as porcentagem de casos nos estados em questão e retorná-lo em Dataframe:\n1# Agregando as duas queries SQL como se fosse um Pandas DataFrame: 2sul = casos.group_by(south_br).aggregate(percentage_cases.mean().name(\u0026#39;Media Casos\u0026#39;)).dropna() 3print(sul.compile().compile(compile_kwargs={\u0026#34;literal_binds\u0026#34;: True})) SELECT t0.\u0026quot;Regiao Sul\u0026quot;, t0.\u0026quot;Media Casos\u0026quot; FROM (SELECT CASE WHEN (t1.state = 'SC') THEN 'Santa Catarina' WHEN (t1.state = 'RS') THEN 'Rio Grande do Sul' WHEN (t1.state = 'PR') THEN 'Parana' ELSE CAST(NULL AS TEXT) END AS \u0026quot;Regiao Sul\u0026quot;, avg((t1.new_confirmed / t1.estimated_population) * 100) AS \u0026quot;Media Casos\u0026quot; FROM main.\u0026quot;casos_covid19_BR\u0026quot; AS t1 GROUP BY CASE WHEN (t1.state = 'SC') THEN 'Santa Catarina' WHEN (t1.state = 'RS') THEN 'Rio Grande do Sul' WHEN (t1.state = 'PR') THEN 'Parana' ELSE CAST(NULL AS TEXT) END) AS t0 WHERE t0.\u0026quot;Regiao Sul\u0026quot; IS NOT NULL AND t0.\u0026quot;Media Casos\u0026quot; IS NOT NULL 1# O resultado da query com o DataFrame desejado: 2sul.execute() Regiao Sul Media Casos 0 Parana 0.018670 1 Rio Grande do Sul 0.028637 2 Santa Catarina 0.029332 Conclusão Como pudemos ver, o Ibis é uma ferramenta poderosa para acelerar sua análise de dados, capaz de integrar diferentes engines SQL com o Pandas, o Framework traz melhorias de performance e legibilidade ao código Python. Crie e realize buscas SQL como se estivesse trabalhando com um Pandas DataFrame, mas com uma economia de memória e alta portabilidade! Com o Ibis é possível utilizar o mesmo padrão de trabalho para desenvolvimento e produção, acelerar seus testes unitários, escalonar a aplicação para diferentes bases de dados, e muito mais!\nReferências https://ibis-project.org/ https://github.com/ibis-project/ibis ","link":"https://opensciencelabs.org/blog/ibis-framework/","section":"blog","tags":["ibis","dataframe","datos","pandas"],"title":"Ibis -  Escalonando a Análise de Dados com Expressões Ibis"},{"body":"","link":"https://opensciencelabs.org/tags/pandas/","section":"tags","tags":null,"title":"pandas"},{"body":"","link":"https://opensciencelabs.org/categories/python/","section":"categories","tags":null,"title":"Python"},{"body":"","link":"https://opensciencelabs.org/tags/bibliotecas/","section":"tags","tags":null,"title":"bibliotecas"},{"body":"","link":"https://opensciencelabs.org/tags/filtrar-datos/","section":"tags","tags":null,"title":"filtrar datos"},{"body":"","link":"https://opensciencelabs.org/categories/r/","section":"categories","tags":null,"title":"R"},{"body":" En este artículo, veremos cómo modificar la forma de una tabla, combinando varias columnas en una sola o viceversa, veremos ejemplos en los que utilizaremos la biblioteca tidyr con sus funciones gather(), spread(), separate(), y unite().\nRequisitos Por comodidad usamos la biblioteca pacman como gestor de paquetes.\n1 2# install.packages(\u0026#34;pacman\u0026#34;) Para instalar la biblioteca pacman 3library(pacman) # Gestor de paquetes en R 4p_load(\u0026#34;readr\u0026#34;) # Biblioteca para importar archivos csv 5p_load(\u0026#34;tidyr\u0026#34;) # Biblioteca para manipular datos 6p_load(\u0026#34;ggplot2\u0026#34;) # Biblioteca para graficar datos 7p_load(\u0026#34;dplyr\u0026#34;) # Biblioteca para filtrar datos de la tabla 8p_load(\u0026#34;zoo\u0026#34;) # Biblioteca para transformar fechas a trimestres 9p_load(\u0026#34;scales\u0026#34;) # Biblioteca para dar formato de miles en el eje \u0026#34;y\u0026#34; Recuerda, también puedes instalar y abrir las bibliotecas de manera tradicional, por ejemplo con: install.packages(\u0026quot;tidyr\u0026quot;), luego abrir la misma biblioteca con library(tidyr).\nImportando nuestros datos Los datos usados han sido descargados de la base de datos del Instituto de Estadística de Bolivia (INE). Una vez que se tiene los datos en nuestro equipo, se modifica para que se encuentren en formato .csv y los importamos a nuestro entorno de R.\nPuedes descargar los archivos usados en este artículo aquí.\nImportamos el archivo .csv a la variable datos_turistas.\n1 2covid_data \u0026lt;- read_csv(\u0026#34;turistas.csv\u0026#34;) En la consola observamos lo siguiente:\n1 2Rows: 44 Columns: 169 3── Column specification ─────────────────────────────────────────────────────────────── 4Delimiter: \u0026#34;,\u0026#34; 5chr (1): Nacionalidad 6dbl (168): 31/01/08, 28/02/08, 31/03/08, 30/04/08, 31/05/08, 30/06/08, 31/07/08, 31... 7 8ℹ Use `spec()` to retrieve the full column specification for this data. 9ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Nuestra tabla tiene varias columnas correspondientes al acumulativo por mes, si queremos graficar estos datos, ggplot() no nos será de mucha utilidad. Por ello vamos a usar gather() para convertir las fechas de las columnas en datos de una sola columna.\nSi quieres explorar los datos manualmente puedes ejecutar la función (View(datos_turistas)) en la consola.\n¿Cómo usar la función gather()? La función gather() puede agrupar los nombres de las columnas en una sola, así como se muestra en la siguiente animación.\nEn nuestro caso queremos hacer algo similar, agrupar las fechas en una columna llamada Fecha.\n1 2# A tibble: 6 × 169 3 Nacionalidad `31/01/08` `28/02/08` `31/03/08` `30/04/08` `31/05/08` `30/06/08` 4 \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; 51 Estados Unidos 2795 2365 2055 2258 2058 4141 62 Argentina 2304 1603 1780 869 2534 1293 73 Brasil 2996 3041 1499 3215 964 1128 84 Chile 1323 1195 1021 1115 754 1076 95 España 1050 875 721 727 744 670 106 Perú 1141 909 841 806 661 1438 11# … with 162 more variables … Usando la función gather() tenemos:\n1 2datos_turistas \u0026lt;- 3 gather(data = datos_turistas, 4 key = Fecha, 5 value = Turistas, 6 2:ncol(datos_turistas)) 7 8# ncol(tabla) Devuelve el número de columnas de tabla Ejecutando head(datos_turistas), notamos que hemos obtenido lo deseado.\n1 2# A tibble: 6 × 3 3 Nacionalidad Fecha Turistas 4 \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; 51 Estados Unidos 31/01/08 2795 62 Argentina 31/01/08 2304 73 Brasil 31/01/08 2996 84 Chile 31/01/08 1323 95 España 31/01/08 1050 106 Perú 31/01/08 1141 gather(data, key, value, ...)\nFunción que es usada para agrupar columnas en dos nuevas columnas.\ndata : Dataframe o tabla que se va a modificar. key : Nombre de la nueva columna que va almacenar los nombres de la columnas que se van a agrupar. value : Nombre de la nueva columna que va contener los valores de la columnas que se van a agrupar. ... : Nombres o selección de columnas a agruparse, puedes usar los nombres de las columnas con la función concatenar c(). Por ejemplo, c(nombre_col1, nombre_col2...) o hacer la selección del complemento con !c(), también puedes utilizar como referencia el número de columna. Para hacer referencia a una serie sucesiva emplea :, algo como: n_col1:n_col2. Separa una columna con separate() Para ejemplificar el operador separate() vamos a separar la columna Fecha en las columnas día, mes y año.\n1 2datos_turistas \u0026lt;- 3 separate(datos_turistas, 4 col = Fecha, 5 into = c(\u0026#34;día\u0026#34;, \u0026#34;mes\u0026#34;, \u0026#34;año\u0026#34;), 6 sep = \u0026#34;/\u0026#34;, 7 remove = FALSE 8 ) Podemos observar en la consola.\n1 2\u0026gt; head(datos_turistas) 3# A tibble: 6 × 6 4 Nacionalidad Fecha día mes año Turistas 5 \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; 61 Estados Unidos 31/01/08 31 01 08 2795 72 Argentina 31/01/08 31 01 08 2304 83 Brasil 31/01/08 31 01 08 2996 94 Chile 31/01/08 31 01 08 1323 105 España 31/01/08 31 01 08 1050 116 Perú 31/01/08 31 01 08 1141 separate(data, col, into, sep, remove)\nFunción que es usada para separar una columna en varias.\ndata : Dataframe o tabla que se va a modificar. col : Nombre de la columna que va a separarse. into : Nombres de la nuevas columnas que van a crearse a partir de col. Puedes usar la función concatenar c() para nombrar a las columnas. sep : Separador, un carácter que va a servir para identificar en donde se separa para generar las nuevas columnas. Puedes usar Regular Expressions. remove : Acepta valores booleanos TRUE y FALSE, por defecto es TRUE, si es igual TRUE borra la columna que se separa, en FALSE la mantiene. Vamos a aprovechar los nuevos datos generados, para graficar el top de turistas que han visitado Bolivia en los años 2016-2021.\nEn el código abajo usamos muchas funciones de la biblioteca dplyr si quieres aprender más sobre esa biblioteca lee este artículo.\n1 2# Añadimos \u0026#34;20\u0026#34; al año y lo convertimos a variable entera. 3datos_turistas$año \u0026lt;- 4 as.integer(paste(\u0026#34;20\u0026#34;, datos_turistas$año, sep = \u0026#34;\u0026#34;)) 5 6# Filtramos por año 7datos_turistas_2016_2021 \u0026lt;- 8 datos_turistas %\u0026gt;% 9 filter(as.integer(año) \u0026gt;= 2016, na.rm =TRUE) 10 11# Agrupando por Nacionalidad y año 12datos_turistas_2016_2021 \u0026lt;- 13 datos_turistas_2016_2021 %\u0026gt;% 14 group_by(Nacionalidad, año) %\u0026gt;% 15 summarise(turistas_anuales = sum(Turistas)) 16 17# Extrayendo los top turistas visitantes de Bolivia 18top_turistas_2016_2021 \u0026lt;- 19 datos_turistas_2016_2021 %\u0026gt;% 20 arrange(desc(turistas_anuales)) %\u0026gt;% 21 group_by(año) %\u0026gt;% 22 slice(1:7) 23 24# Graficando con ggplot2 25ggplot(data = top_turistas_2016_2021) + 26 geom_bar( 27 aes(x = año, y = turistas_anuales, fill = Nacionalidad), 28 stat = \u0026#34;identity\u0026#34;, 29 alpha = 0.8 30 ) + 31 theme_minimal() + scale_fill_brewer(palette = \u0026#34;Paired\u0026#34;) + 32 scale_x_continuous(breaks = c(2016:2021)) + 33 scale_y_continuous(labels = comma_format(big.mark = \u0026#34; \u0026#34;)) + 34 labs( 35 x = \u0026#34;\u0026#34;, 36 y = \u0026#34;\u0026#34;, 37 fill = \u0026#34;Nacionalidad\u0026#34;, 38 title = \u0026#34;Viajeros llegados por avión a Bolivia 2016-2021\u0026#34;, 39 subtitle = \u0026#34;Top 7 nacionalidades por año\u0026#34;, 40 caption = \u0026#34;Fuente: INE Bolivia\u0026#34; 41 ) Función unite() Unite es una función complementaria a separate() y hace lo contrario, une las columnas en un sola. Vamos a usarlo para juntar las columnas de mes y año.\n1 2datos_turistas_trimestre \u0026lt;- 3 unite(datos_turistas, mes_año, c(\u0026#34;mes\u0026#34;,\u0026#34;año\u0026#34;), sep = \u0026#34;-\u0026#34;) Observando en la consola:\n1 2\u0026gt; head(datos_turistas_trimestre) 3# A tibble: 6 × 5 4 Nacionalidad Fecha día mes_año Turistas 5 \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; 61 Estados Unidos 31/01/08 31 01-2008 2795 72 Argentina 31/01/08 31 01-2008 2304 83 Brasil 31/01/08 31 01-2008 2996 94 Chile 31/01/08 31 01-2008 1323 105 España 31/01/08 31 01-2008 1050 116 Perú 31/01/08 31 01-2008 1141 unite(data, col, ..., sep, remove)\nFunción que une varias columnas en una.\ndata : Dataframe o tabla que se va a modificar. col : Nombre de la nueva columna que va a unir otras columnas. ... : Nombres de las nuevas columnas que van a juntarse en col. Puedes emplear la función concatenar c() para nombrar las columnas. sep : Separador, un carácter que va a servir para unir los valores de las columnas que se unen. remove : Acepta valores booleanos TRUE y FALSE. Si es igual a TRUE, borra las columnas que se unen, pero si es FALSE, las mantiene. Por defecto, su valor es TRUE. Función spread() Esta función es la que complementa a la función gather(), y hace exactamente lo contrario. Esparcir una columna en varias.\nAntes de utilizar spread() vamos a agrupar nuestro datos en trimestres.\n1 2# Agrupamos los datos por trimestres 3datos_turistas_trimestre \u0026lt;- datos_turistas_trimestre %\u0026gt;% 4 mutate(trimestre = as.yearqtr(mes_año, format =\u0026#34;%m-%Y\u0026#34;)) %\u0026gt;% 5 group_by(Nacionalidad, trimestre) %\u0026gt;% 6 summarise(turistas_trimestre = sum(Turistas)) 7 8# También podemos utilizar la columna `Fecha` para transformar a trimestres, con el argumento `format=%d/%m/%y` En la consola podemos ver\n1 2\u0026gt; head(datos_turistas_trimestre) 3# A tibble: 6 × 3 4# Groups: Nacionalidad [1] 5 Nacionalidad trimestre turistas_trimestre 6 \u0026lt;chr\u0026gt; \u0026lt;yearqtr\u0026gt; \u0026lt;dbl\u0026gt; 71 Alemania 2008 Q1 3318 82 Alemania 2008 Q2 1392 93 Alemania 2008 Q3 1458 104 Alemania 2008 Q4 1516 115 Alemania 2009 Q1 4008 126 Alemania 2009 Q2 1646 Ahora podemos usar spread(), para expandir los datos de la columna trimestre en columnas independientes.\n1 2# Mostar en columnas los valores de trimestre 3datos_turistas_trimestre \u0026lt;- 4 spread( 5 data = datos_turistas_trimestre, 6 key = trimestre, 7 value = turistas_trimestre) Ahora observamos que nuestros datos se han esparcido, este formato es útil para visualización de datos en otros frameworks.\n1 2\u0026gt; head(datos_turistas_trimestre) 3# A tibble: 6 × 57 4# Groups: Nacionalidad [6] 5 Nacionalidad `2008 Q1` `2008 Q2` `2008 Q3` `2008 Q4` `2009 Q1` `2009 Q2` `2009 Q3` 6 \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; 71 Alemania 3318 1392 1458 1516 4008 1646 1924 82 Argentina 5687 4696 8537 6884 4734 4667 5810 93 Australia 988 1269 944 1384 980 771 1253 104 Austria 587 176 221 300 632 206 293 115 Bélgica 1029 246 784 602 1504 556 531 126 Brasil 7536 5307 7199 5693 4178 5941 9843 13# … with 49 more variables … spread(data, key, value)\nFunción que es usada para esparcir los datos de una columna como nombres de columnas.\ndata : Dataframe o tabla que se va a modificar. key : Nombre de la columna cuyos valores se van esparcir como los nombres de las nuevas columnas. value : Nombre de la columna cuyos valores van a convertirse en los nuevos valores de las nuevas columnas. Aprovechemos estos datos para graficar el top de países que han visitado Bolivia en el primer trimestre del 2019.\n1 2top_turistas_trimestre_1_2019 \u0026lt;- 3 datos_turistas_trimestre %\u0026gt;% 4 select(Nacionalidad, `2019 Q1`) %\u0026gt;% 5 rename(trimestre1_2019= `2019 Q1`) %\u0026gt;% 6 arrange(desc(trimestre1_2019)) %\u0026gt;% as.data.frame() %\u0026gt;% 7 slice_head(n = 10) Graficando\n1 2ggplot(data = top_turistas_trimestre_1_2019) + 3 geom_bar(aes(x=Nacionalidad, y=trimestre1_2019, fill=Nacionalidad), stat=\u0026#34;identity\u0026#34;, alpha = 0.8)+ 4 theme_minimal() + scale_fill_brewer(palette = \u0026#34;Paired\u0026#34;)+ 5 scale_y_continuous(labels = comma_format(big.mark=\u0026#34; \u0026#34;)) + 6 labs( 7 x = \u0026#34;\u0026#34;, 8 y = \u0026#34;\u0026#34;, 9 fill = \u0026#34;Nacionalidad\u0026#34;, 10 title = \u0026#34;Viajeros llegados por avión a Bolivia Primer Trimestre 2019\u0026#34;, 11 subtitle = \u0026#34;Top 10 nacionalidades\u0026#34;, 12 caption = \u0026#34;Fuente: INE Bolivia\u0026#34; 13 ) 14#p_unload(all) #Ejecute esta línea de comando para cerrar las bibliotecas abiertas con \u0026#34;pacman\u0026#34; Otros detalles Las funciones mostradas en el artículo son las más usadas, y permiten un mejor manejo de datos en R. Te recomiendo revisar la documentación oficial si quieres aprender más.\nEn el caso de que quieras descargar el repositorio de este artículo puedes hacerlo aquí.\nReferencias Git Hub Issues tidyr\nInstituto de Estadística de Bolivia (INE)\nDocumentación de R\n","link":"https://opensciencelabs.org/blog/reorganiza-tus-tablas-con-tidyr/","section":"blog","tags":["tidyr","bibliotecas","tablas","reorganizar","filtrar datos"],"title":"Reorganiza tus tablas con tidyr en R"},{"body":"","link":"https://opensciencelabs.org/tags/reorganizar/","section":"tags","tags":null,"title":"reorganizar"},{"body":"","link":"https://opensciencelabs.org/tags/tablas/","section":"tags","tags":null,"title":"tablas"},{"body":"","link":"https://opensciencelabs.org/tags/tidyr/","section":"tags","tags":null,"title":"tidyr"},{"body":" En este artículo mostraremos como usar algunas funciones importantes de la biblioteca de dplyr, específicamente veremos como usar las funciones filter(), select(), group_by(), sumarize() y mutate() dentro de un ejemplo práctico.\nRequisitos Por comodidad usamos la biblioteca pacman como gestor de paquetes.\n1# install.packages(\u0026#34;pacman\u0026#34;) Para instalar la biblioteca pacman 2library(pacman) # Gestor de paquetes en R 3p_load(\u0026#34;readr\u0026#34;) # Biblioteca para importar archivos csv 4p_load(\u0026#34;dplyr\u0026#34;) # Biblioteca para manipular datos 5p_load(\u0026#34;ggplot2\u0026#34;) # Biblioteca para graficar datos Recuerde, que tambien puede instalar y abrir las bibliotecas de manera tradicional, por ejemplo con: install.packages(\u0026quot;readr\u0026quot;), luego abrir la misma biblioteca con library(readr).\nImportando nuestros datos La base de datos usada ha sido descargada de Our World In Data, la cual muestra los datos recolectados de la reciente pandemia. Una vez descargada nuestra base de datos en formato .csv, la importamos a nuestro entorno de R. Puede descargar los archivos usados en este artículo Repositorio de este artículo aquí.\nImportamos los el archivo .csv a la variable covid_data.\n1covid_data \u0026lt;- read_csv(\u0026#34;owid-covid-data.csv\u0026#34;) En la consola observamos lo siguiente:\n1Rows: 193573 Columns: 67 2── Column specification ──────────────────────────────────────────────────────────────────────────── 3Delimiter: \u0026#34;,\u0026#34; 4chr (4): iso_code, continent, location, tests_units 5dbl (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_deaths, new_deaths_smoo... 6date (1): date 7 8ℹ Use `spec()` to retrieve the full column specification for this data. 9ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Como puede ver esta tabla es muy extensa, contiene 67 columnas (variables) y 193573 filas, manejar los datos directamente de esta tabla puede ser complicado, por lo que se recomienda reducir las variables o extraer información relevante para nosotros. Si quiere explorar los datos manualmente puede ejecutar la función (View(datos_covid)) en la consola.\nCómo usar la función filter() y select() Queremos ver los datos de la región de Sudamérica (continent = \u0026quot;South America\u0026quot;) y sólo las variables de país, fecha y nuevos casos que corresponderían a las columnas de location, date, new_cases respectivamente en el dataframe datos_covid (para graficar curvas suaves usamos la columna new_cases_smoothed en vez de new_cases).\nUsando la función filter() y tenemos:\n1# Filtramos los las filas que cumplan con la condición de que en su columna continent sea igual a \u0026#34;South America\u0026#34;. 2# Almacenamos lo deseado en la variable covid_sudamerica 3covid_sudamerica \u0026lt;- filter(covid_data, continent == \u0026#34;South America\u0026#34;) 4# Filtramos las filas que no contengan valores en la columna de new_cases_smoothed, es decir valores iguales a NA. 5covid_sudamerica \u0026lt;- filter(covid_sudamerica, !is.na(new_cases_smoothed)) 6# Seleccionamos sólo las columnas que nos importan 7covid_sudamerica \u0026lt;- select(covid_sudamerica, location, date, new_cases_smoothed) filter(tabla, condicion)\nFunción que es usada para filtrar en filas, selecciona un subconjunto de filas que cumplan con la condicion\ntabla : Dataframe o tabla de donde va se va a filtrar datos. condicion : Prueba lógica que devuelve valores booleanos TRUE o FALSE, de esta condicion depende si la fila se incluye en la nueva tabla. Para armar la condicion, puede usar los nombres de la columna como variables y usar los siguientes operadores lógicos:\n\u0026gt; : Corresponde a mayor que. == : Corresponde a igual que. \u0026gt;= : Corresponde a mayor o igual que. \u0026lt;= : Corresponde a menor o igual que. != : Corresponde a diferente que. Puede combinarlas las condiciones con:\n\u0026amp; : Operador AND. | : Operador OR. ! : Operador NOT o negación. is.na(x) : Función que verifica si un dato es NA (Not Available/ Missing value), valor faltante o no disponible. Devuelve TRUE cuando x es NA. valor %in% vector : Operador que verifica si un valor existe en un vector. Devuelve TRUE cuando valor esta incluido en vector. select(tabla, nombre_col, ...) Función que filtra columnas por nombre de columna para un nueva tabla.\ntabla : Dataframe o tabla de donde va se va a filtrar datos. nombre_col : Nombre de la columna o variable que va a componer la nueva tabla. Operador Pipe %\u0026gt;% Este operador nos permite combinar muchas operaciones en una sóla línea, una simple cadena de comandos. Considere lo siguiente para entender el flujo de datos del operador Pipe %\u0026gt;%.\nTome x use x como entrada para la función f(x) use la salida de f(x) como entrada de la función g(x) use la salida de g(x) como entrada de la función h(x). Simplificando tenemos h(g(f(x))) , esta es una expresión complicada para escribirla, su equivalente usando el operador Pipe (%\u0026gt;%) es: x %\u0026gt;% f() %\u0026gt;% g() %\u0026gt;% h() que es mucho más entendible y fácil de escribir.\nUsando el operador %\u0026gt;% podemos simplificar a una línea de comando encadenada, la obtención de nuestra variable covid_sudamerica de la sección anterior\n1covid_sudamerica \u0026lt;- 2 covid_data %\u0026gt;% 3 filter(continent == \u0026#34;South America\u0026#34; \u0026amp; !is.na(new_cases_smoothed)) %\u0026gt;% 4 select(location, date, new_cases_smoothed) Para poder graficar este ejemplo lo vamos a reducir un poco más, obteniendo una tabla que sólo contenga países de la región.\n1paises_andinos = c(\u0026#34;Bolivia\u0026#34;, \u0026#34;Peru\u0026#34;, \u0026#34;Chile\u0026#34;, \u0026#34;Ecuador\u0026#34;) 2covid_paises_region \u0026lt;- 3 covid_data %\u0026gt;% 4 filter(location %in% paises_andinos) %\u0026gt;% 5 select(location, date, new_cases_smoothed) Para observar nuestros datos obtenidos graficamos\n1ggplot(covid_paises_region) + 2geom_line(aes(x = date, y = new_cases_smoothed, color = location), size = 0.5) + 3 scale_color_brewer(palette = \u0026#34;Set1\u0026#34;) + theme_bw() + 4 labs( 5 x = \u0026#34;\u0026#34;, 6 y = \u0026#34;\u0026#34;, 7 title = \u0026#34;Registro de contagios diario en países de la región por COVID-19\u0026#34;, 8 subtitle = \u0026#34;(Datos suavizados)\u0026#34;, 9 caption = \u0026#34;Fuente: Our World In Data\u0026#34;, 10 color = \u0026#34;Países\u0026#34; 11 ) Cómo usar summarise() y group_by() Si, queremos saber el total de contagiados y el total de días desde que se registraron los contagios podemos usar summarize()\n1summarise( 2 covid_paises_region, 3 total = sum(new_cases_smoothed, na.rm = TRUE), 4 dias = n_distinct(date) 5) Ejecutanto obtenemos en la consola:\n1# A tibble: 1 × 2 2 total dias 3 \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; 41 9174748. 841 summarise(tabla, nueva_columa = funcion_vector(columna_tabla), ...) Función que crea una nueva tabla a partir de la agrupación de columnas de una tabla anterior, los valores de la nueva columna dependen también del tipo de función vector que se use para agruparlas.\ntabla: Dataframe o tabla de donde sus columnas servirán para contruir la nueva tabla. nueva_columna: nueva columna o variable creada a partir de las anteriores columnas. funcion_vector(): función que devuelve un solo valor a partir de un vector. Algunas funciones que se pueden usar como función vector son:\nsum(vector) : Devuelte la suma de los componentes de vector. mean(vector) : Devuelve el valor promedio de los valores de vector. min(vector) : Devuelve el valor mínimo de los valores de vector. max(vector) : Devuelve el valor mínimo de los valores de vector. n_distinc(vector) : Devuelve el conteo de los valores diferentes dentro de vector. n(vector) : Devuelve el conteo de los valores dentro de vector. sd(vector) : Devuelve la desviación estandar de los valores de vector. Todas las funciones tienen la opción ra.rm para omitir o pasar por alto los valores que sean NA (No Applicable/Missing values) durante los cálculos, por ejemplo puede usar mean(vector, na.rm = TRUE) para calcular el promedio de vector descartando los datos que sean NA.\nLa función summarise() agrupa todos los datos de una columna, y devuelve un sólo valor por columna.\nPara el ejemplo, si quisieramos no obtener el total sino el total por países usamos la función group_by().\n1total_covid_paises_region \u0026lt;- 2 covid_paises_region %\u0026gt;% group_by(location) %\u0026gt;% 3 summarise(total_contagios = sum(new_cases_smoothed, na.rm = TRUE)) 4 5total_covid_paises_region Ejecutando, observamos en la consola:\n1# A tibble: 4 × 2 2 location total_contagios 3 \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; 41 Bolivia 911503. 52 Chile 3785492. 63 Ecuador 889635. 74 Peru 3588117. Nota: estos son resultados de datos suavizados\ngroup_by(tabla, columna_1, columna_2 ...) Agrupa varias filas en una sola, las agrupa si y sólo si tienen el mismo valor en columna_1, luego las agrupa por valores en la columna_2 y así sucesivamente. Esta función siempre va acompañada de la función summarise()\ntabla: Dataframe o tabla de donde sus columnas servirán para contruir la nueva tabla. columna_n: nombre la columna de la cual se van a agrupar los valores con la función summarise(). Hagamos algo más interesante, queremos ver la evolución del contagios de COVID-19 por continentes.\n1covid_continentes \u0026lt;- 2 covid_data %\u0026gt;% 3 group_by(continent, date) %\u0026gt;% 4 summarise(total_contagios = sum(new_cases_smoothed, na.rm = TRUE)) %\u0026gt;% 5 filter(!is.na(continent)) Graficando los resultados\n1ggplot(covid_continentes) + 2 geom_line(aes(x = date, y = total_contagios, color = continent), size = 0.8) + 3 scale_color_brewer(palette = \u0026#34;Set1\u0026#34;) + theme_bw() + 4 labs( 5 x = \u0026#34;\u0026#34;, 6 y = \u0026#34;\u0026#34;, 7 title = \u0026#34;Registro de contagios COVID-19 por Continente\u0026#34;, 8 subtitle = \u0026#34;(Datos suavizados)\u0026#34;, 9 caption = \u0026#34;Fuente: Our World In Data\u0026#34;, 10 color = \u0026#34;Continente\u0026#34; 11 ) Para que sirve la función mutate() Una buen indicador, para saber si hemos mejorado el tratamiento y prevención contra la COVID-19 es hallar la relación entre el muertes por cada 1000 contagiados (mientras menor valor tenga la variable, mejor estamos preparados para afrontar la COVID). Llamemos a esta nueva variable indicador, esta dependera de otras para su cálculo, la función mutate() no ayudará a calcularla.\nPuede que no sea excelente indicador y que no refleje muy bien lo que se quiere, pero para propositos de este ejemplo nos servirá\n1# Obtenemos nuestros datos que nos van a ayudar a calcular el indicador 2# Filtramos los valores que sean iguales a 0 y los datos NA con filter() 3covid_continentes_indicador \u0026lt;- 4 covid_data %\u0026gt;% 5 group_by(continent, date) %\u0026gt;% 6 summarise(nuevos_casos = sum(new_cases_smoothed, na.rm = TRUE), nuevas_muertes = sum(new_deaths_smoothed, na.rm = TRUE)) %\u0026gt;% 7 filter(!is.na(continent) \u0026amp; nuevos_casos != 0 \u0026amp; nuevas_muertes != 0) Usamos la función mutate para obtener nuestro indicador\n1covid_continentes_indicador \u0026lt;- 2 covid_continentes_indicador %\u0026gt;% 3 mutate(indicador = nuevas_muertes/nuevos_casos*1000) mutate(tabla, nueva_columna_1 = f(columna_1, columna_2...), nueva_columna_2 = f(columna_n, ...)... ) Crea una nuevas columnas las modifica a partir de los datos de otras columnas.\ntabla : Dataframe o tabla de donde sus columnas servirán para obtener la nueva tabla. nueva_columna_n : Nombre la nueva columna que se crea a partir de otras columnas. columna_n : Nombre la columna o variable de la tabla. f(columna_1, columna_2, ...) : Representa la combinación algebraica de las variables que van a devolver el nuevos valores de la nueva_columna_n. (Observe que usamos nombre de la columna y variable como sinónimos) Mostrando los resultados en una gráfica\n1ggplot(covid_continentes_indicador) + 2 geom_line(aes(x = date, y = indicador, color = continent), size = 0.8) + 3 scale_color_brewer(palette = \u0026#34;Dark2\u0026#34;) + theme_bw() + 4 labs( 5 x = \u0026#34;\u0026#34;, 6 y = \u0026#34;\u0026#34;, 7 title = \u0026#34;Relación diaria de (muertes)/(1000 contagiados) COVID-19\u0026#34;, 8 subtitle = \u0026#34;(Datos suavizados)\u0026#34;, 9 caption = \u0026#34;Fuente: Our World In Data\u0026#34;, 10 color = \u0026#34;Continente\u0026#34; 11 ) Conclusiones Las funciones mostradas en el árticulo son las más usadas y permiten una mejor manipulación de datos en R. Como siempre es bueno revisar la documentación oficial de los correspondientes paquetes si se quiere aprender más.\nPuede descargar el repositorio de este artículo aquí.\nReferencias Our World In Data\nDocumentacion de R\n","link":"https://opensciencelabs.org/blog/filtrar-datos-r/","section":"blog","tags":["datos","paquetes","tablas","dplyr","filtrar datos"],"title":"Cómo filtrar datos de tu tabla con dplyr en R"},{"body":"","link":"https://opensciencelabs.org/tags/dplyr/","section":"tags","tags":null,"title":"dplyr"},{"body":"","link":"https://opensciencelabs.org/tags/paquetes/","section":"tags","tags":null,"title":"paquetes"},{"body":"","link":"https://opensciencelabs.org/tags/blockchain/","section":"tags","tags":null,"title":"Blockchain"},{"body":"","link":"https://opensciencelabs.org/tags/criptomoneda/","section":"tags","tags":null,"title":"criptomoneda"},{"body":" Este breve tutorial te mostrará como graficar mapas en R, extraer datos de archivos de formato shapefile, resaltar puntos en tu mapa y modificar su apariencia utilizando las bibliotecas rgdal y ggplot2.\nComenzando Para que todas las bibliotecas funcionen correctamente, se recomienda instalar o actualizar a las últimas versiones de R y de su IDE RStudio con su correspondiente complemento RTools.\nEn este artículo, vamos a utilizar archivos de formato Shapefile. Si todavía no sabes de qué se trata, te explicamos a continuación.\nUn archivo Shapefile contiene al menos:\n.shp - un archivo tipo shape, es la geometría misma. .shx - un archivo tipo index, tiene las posiciones indexadas del archivo .shp. .dbf - un archivo tipo attribute, tiene los atributos de cada forma en una columna, es de tipo dBase IV. Adicionalmente, la carpeta donde se encuentran dichos archivos pueden contener otros archivos de formato .prj o .sbn, estos aportan más datos de la geometría o pueden ser usados en otros programas de sistemas de información geográfica.\nLos datos importados con rgdal a partir de un archivo shapefile, son objetos que contienen polígonos vectoriales, con las coordenadas la latitud y la longitud en formato decimal. A partir de estos objetos, podemos extraer datos para graficarlos desde una tabla. La biblioteca broom nos ayuda en la extracción y agrupación de los datos para su correspondiente graficación.\nObteniendo nuestros archivos shapefile\nMuchos de estos archivos Shapefile representan mapas de nuestros Estados, por lo que están disponibles de manera gratuita en la mayoría de los casos, en otros, son de paga o están más completos, actualizados y/o poseen datos específicos. Debajo mostramos algunos recursos web gratuitos que puedes usar.\ndata.humdata.org para shapefiles de varios países del mundo (algunos están desactualizados).\ngeo.gob.bo para shapefiles de Bolivia.\nInstalación de pre-requisitos Las siguientes bibliotecas de R son necesarias, para realizar nuestro ejemplo.\n1install.packages(\u0026#34;ggplot2\u0026#34;) # biblioteca para graficar. 2install.packages(\u0026#34;rgdal\u0026#34;) # biblioteca para abrir archivo de formato shapefiles (datos geográficos) 3install.packages(\u0026#34;broom\u0026#34;) # biblioteca usada para extraer datos del archivo importado de shapefiles 4install.packages(\u0026#34;tidyverse\u0026#34;) # biblioteca usada para unir tablas 5install.packages(\u0026#34;rio\u0026#34;) # biblioteca para importar datos de archivos csv 6install.packages(\u0026#34;dplyr\u0026#34;) # biblioteca usada para agrupar por valores de columnas 7install.packages(\u0026#34;extrafont\u0026#34;) # biblioteca para importar los tipos de letra de windows. (Recuerde que para ejecutar una línea de comando en el Editor de RStudio se usa Ctrl+Enter)\nPreparación de los datos para graficar Nuestra base de datos fue descargada de GeoBolivia, INE Bolivia y geodatos.net. Una vez descargados los datos, fueron depurados para el ejemplo.\nAbrimos nuestras bibliotecas requeridas:\n1library(ggplot2) 2library(rgdal) 3library(broom) 4library(tidyverse) 5library(rio) 6library(dplyr) 7library(extrafont) Redireccionamos el directorio actual a nuestro directorio de trabajo e importamos nuestros archivos shapefiles:\n1setwd(\u0026#34;../mypath/\u0026#34;) # redirecciona el directo actual a nuestro directorio de trabajo 2# importamos los datos geográficos a nuestra variable shapefile 3shapefile = readOGR( 4 dsn = \u0026#34;.\u0026#34;, 5 layer = \u0026#34;departamentos_geo\u0026#34;, 6 encoding = \u0026#39;utf-8\u0026#39;, 7 use_iconv = TRUE 8) dsn: carpeta dentro del directorio actual, donde se encuentran ficheros shapefiles. Si se pone solo un punto \u0026quot;.\u0026quot; hace referencia a que los ficheros se encuentran en la carpeta actual.\nencoding=\u0026quot;utf-8\u0026quot;, use_iconv=TRUE: indica a la función readOGR que debe importarse con la codificación utf-8. Como nuestro archivo contiene caracteres del español como ñ y vocales con tildes, es conveniente usar este comando.\nPara observar el contenido de shapefile, use View(shapefile).\nExtraemos datos en geotable y a continuación mostramos su cabecera:\n1geotable = tidy(shapefile) 2head(geotable) 1\u0026gt; head(geotable) 2# A tibble: 6 x 7 3 long lat order hole piece group id 4 \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; 51 -65.8 -18.0 1 FALSE 1 0.1 0 62 -65.8 -18.0 2 FALSE 1 0.1 0 73 -65.8 -18.0 3 FALSE 1 0.1 0 84 -65.8 -18.0 4 FALSE 1 0.1 0 95 -65.8 -18.0 5 FALSE 1 0.1 0 106 -65.8 -18.0 6 FALSE 1 0.1 0 Nótese que geotable, no posee las etiquetas de los nombres de las regiones a graficar, esto lo arreglamos con:\n1# añadiendo una columna id para poder juntar las columnas de nuestro geotable 2shapefile$id \u0026lt;- row.names(shapefile) 3 4# añadiendo a geotable los datos que faltan desde shapefile y lo juntamos por el id 5geotable \u0026lt;- left_join(geotable, shapefile@data, by = \u0026#34;id\u0026#34;) Para verificar que se han añadido los correspondientes nombres de regiones, use head(geotable)\nFunciones auxiliares:\nshapefile$id \u0026lt;- : crea una nueva columna id en shapefile o la reemplaza. row.names(shapefile) : extrae los nombres de las filas del shapefile que por defecto es una numeración que va desde 0 y coincide con el id de nuestro geotable. shapefile@data accede a la tabla o dataframe data de nuestro shapefile. left_join(tabla1, tabla2, by = clave) : junta dos tablas por izquierda, es decir, añade valores que faltan de tabla2 a la tabla1 de acuerdo al código clave o columna común. Ahora importamos nuestra tabla con los datos de población por departamento: (haciendo header = TRUE nos aseguramos que la primera fila se convierta en los nombres de las columnas)\n1# importando la tabla de datos de población 2poblacion \u0026lt;- import(\u0026#34;departamentospoblacion.csv\u0026#34;, header = TRUE) Nótese que cambiamos el nombre de nuestra columna en población DEPARTAMENTO por DEPARTAMEN, para que coincidan y luego juntarlas con left_join().\n1# cambiando el nombre de la columna de DEPARTAMENTO POR DEPARTAMEN 2colnames(poblacion)[colnames(poblacion) == \u0026#34;DEPARTAMENTO\u0026#34;] \u0026lt;- \u0026#34;DEPARTAMEN\u0026#34; 3# juntamos en datos ambas tablas 4datos\u0026lt;-left_join(geotable, poblacion, by = \u0026#34;DEPARTAMEN\u0026#34;) Graficando el mapa con ggplot2 Ahora, graficamos con ggplot2:\n1ggplot() + 2 geom_polygon(data = datos, aes( 3 x = long, 4 y = lat, 5 group = group, 6 fill = Poblacion2022 7 )) + 8 coord_equal() + labs(fill = \u0026#34;POBLACION\u0026#34;) geom_polygon(data, aes(x, y, group, fill)): dibuja polígonos con la tabla data y muestra la estética con aes(). x, y son los valores en ejes de las abscisas y las ordenadas. Están agrupadas por el valor de la columna group y se colorea con base a los valores de la columna fill. coord_equal(): obliga a la gráfica a que la relación de aspecto entre coordenadas sea 1:1. lab(fill): pone el título a la leyenda con fill. Mejorando la presentación de nuestro mapa Entre las cosas que podemos hacer para mejorar la apariencia de nuestra gráfica están: poner un título, cambiar los colores, el fondo, el formato de nuestra leyenda. A continuación mostramos como hacerlo.\nExtraemos los valores de la población para ponerlas como etiquetas dentro de nuestro mapa, para ello utilizamos las funciones group_by() y summarise() de la biblioteca dplyr.\n1etiquetas_poblacion \u0026lt;- datos %\u0026gt;% group_by(DEPARTAMEN) %\u0026gt;% 2 summarise( 3 label_long = mean(range(long)), 4 label_lat = mean(range(lat)), 5 pob = mean(Poblacion2022) 6 ) tabla0 %\u0026gt;% funcion0 %\u0026gt;% funcion1 ...: Esta notación indica que se debe tomar la tabla0 como argumento de la funcion0, luego los resultados de la funcion0 deben tomarse como argumentos de la función1 y así sucesivamente. El símbolo %\u0026gt;% es conocido como pipe operator, este nos ayuda a concatenar valores de entrada y salida de diferentes funciones. group_by(col) %\u0026gt;% summarise(col1=accion1, col2=accion2 ...): agrupa los datos en función del valor de columna col y con summarise() usa los datos agrupados para devolver nuevos valores: col1, col2 ..., que pueden estar en función de los valores agrupados. range(v): extrae los valores máximo y mínimo de un rango de datos v. mean(v): devuelve el valor promedio del vector v. Si queremos incluir nuevas fuentes para el tipo de letra para nuestro mapa, empleamos los siguientes comandos: (Nota: nos pedirá confirmación para realizar la importación de fuentes y tardará unos minutos):\n1extrafont::font_import(\u0026#34;C:/Windows/Fonts\u0026#34;) 2loadfonts(device = \u0026#34;win\u0026#34;) 3fonts() # Nos muestra las fuentes disponibles. Incluimos los datos de etiquetas_población en nuestra gráfica.\n1ggplot() + 2 geom_polygon(data = datos, aes( 3 x = long, 4 y = lat, 5 group = group, 6 fill = Poblacion2022 7 )) + 8 coord_equal() + theme_void() + 9 geom_text( 10 size = 4.5, 11 alpha = 0.9, 12 fontface = \u0026#34;bold\u0026#34;, 13 data = etiquetas_poblacion, 14 mapping = aes( 15 x = label_long, 16 y = label_lat, 17 label = format(pob, big.mark = \u0026#34; \u0026#34;), 18 color = pob 19 ) 20 ) + 21 labs(title = \u0026#34;Población estimada de Bolivia por departamentos para el año 2022\u0026#34;, 22 fill = \u0026#34;Habitantes\u0026#34;, 23 caption = \u0026#34;Datos:INE Boliva; GeoDatos: GeoBolivia\u0026#34;) + 24 scale_colour_gradientn(colours = c(\u0026#34;black\u0026#34;, \u0026#34;black\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;white\u0026#34;), 25 guide = \u0026#34;none\u0026#34;) + 26 scale_fill_continuous( 27 low = \u0026#34;#C4FFD1\u0026#34;, 28 high = \u0026#34;#05693E\u0026#34;, 29 guide = \u0026#34;colorbar\u0026#34;, 30 labels = scales::label_number(big.mark = \u0026#34; \u0026#34;) 31 ) + 32 theme( 33 plot.title = element_text( 34 size = 14, 35 face = \u0026#34;bold\u0026#34;, 36 family = \u0026#34;Helvetica\u0026#34;, 37 hjust = 0.5 38 ), 39 legend.title = element_text(size = 12, family = \u0026#34;Rubik\u0026#34;), 40 plot.caption = element_text(family = \u0026#34;Helvetica\u0026#34;) 41 ) theme_void(): elimina el fondo y los ejes de nuestra gráfica. geom_text(size, alpha, fontface, data, mapping = aes(x, y, label), color): extrae los datos de data, para graficar el texto label en las coordenadas x e y, si se desea una diferenciación de colores se usa color. Con size, alpha y fontface, se establece el tamaño, la opacidad y la estética del texto respectivamente. format(v, big.mark): da el formato al valor v, indicando la separación de miles con big.mark (En nuestro ejemplo el separador de miles es solo el espacio \u0026quot; \u0026quot;). labs(title, fill, caption): con title, fill, caption pone el texto del título, la leyenda y el pie del gráfico respectivamente. scale_colour_gradientn(colours, guide): aplica una escala de colores a todos los valores asignados al argumento color. En nuestro ejemplo tenemos color dentro de la función geom_text(... aes(.. color = pob ...) ...), es decir, los valores de pob estarán coloreados según los valores de colours (la sintaxis color y colors pueden intercambiarse sin problema con colour y colours) y para que la guía de leyenda no se muestre usamos guide = \u0026quot;none\u0026quot;. scale_fill_continuous(low, high, guide, labels): establece una escala de colores continua a los valores asignados a fill. En nuestro ejemplo fill está dentro de la función geom_polygon(... aes(... fill = Poblacion2022 ...) ...), es decir, los valores de la columna Poblacion2022 estarán afectados por esta función. Usamos low para el color correspondiente al valor más bajo y high para el color del valor más alto. Con guide = colorbar mostramos nuestra leyenda en forma de colorbar y conlabels modificamos la apariencia en la escala de nuestro colorbar. scales::label_number(big.mark=\u0026quot; \u0026quot;): usa la función label_number() de la biblioteca scales. Con esto modificamos la apariencia de los números de nuestra leyenda poniéndole un espacio \u0026quot; \u0026quot; como separador de miles. (Nótese que podemos usar scales::funcion() en lugar de library(scales) funcion()). theme(plot.title, legend.title, plot.caption): modifica la apariencia del título del gráfico, el título de la leyenda y el pie del gráfico respectivamente. element_text(size, face, family, hjust): extrae propiedades del texto para modificar el tamaño, la estética, el tipo y la posición en horizontal. Añadiendo ubicaciones a nuestro mapa Incluyendo las ubicaciones de ciudades capitales de departamentos a nuestro mapa:\n1ciudades = import(\u0026#34;ciudades.csv\u0026#34;) # importamos la localización de las ciudades capitales 2 3ggplot() + 4 geom_polygon( 5 data = datos, 6 aes( 7 x = long, 8 y = lat, 9 group = group, 10 fill = DEPARTAMEN 11 ), 12 color = \u0026#34;gray\u0026#34;, 13 size = 0.5 14 ) + 15 geom_point( 16 alpha = 0.7, 17 data = ciudades, 18 mapping = aes(x = lat, y = long, colour = Ciudad), 19 size = 5 20 ) + 21 coord_equal() + labs(title = \u0026#34;Capitales de Departamento en Bolivia\u0026#34;, 22 color = \u0026#34;Ciudades Capitales\u0026#34;, 23 caption = \u0026#34;Fuente: geodatos.net, GeoBolivia\u0026#34;) + 24 scale_fill_brewer(palette = \u0026#39;PuBuGn\u0026#39;, guide = \u0026#34;none\u0026#34;) + 25 scale_color_manual(values = rainbow(9)) + 26 theme_void() + 27 theme( 28 plot.title = element_text( 29 size = 14, 30 face = \u0026#34;bold\u0026#34;, 31 family = \u0026#34;Helvetica\u0026#34;, 32 hjust = 0.5 33 ), 34 legend.title = element_text(size = 12, family = \u0026#34;Rubik\u0026#34;), 35 plot.caption = element_text(family = \u0026#34;Helvetica\u0026#34;) 36 ) geom_point(alpha, data, mapping = aes(x, y, colour), size): dibuja puntos dentro del gráfico, comparte similares argumentos con geom_poligon() y geom_text(). scale_fill_brewer(palette, guide): similar a la función scale_fill_continuous(low, high, guide, labels) aplica una escala de colores tipo brewer a todos los objetos asignados a fill y con pallete seleccionamos el tipo de paleta de colores a aplicar. scale_color_manual(values): nos permite usar una escala de colores manual, values debe ser un vector que contenga los valores de los colores de la escala. raibow(9): devuelve un vector con 9 colores del arcoiris. Asignando colores Puedes asignar los colores simplemente usando su nombre en inglés. Para el blanco es white, para el rojo, red. También puedes utilizar el código hexadecimal, como #FF4500 para el rojo anaranjado; agruparlos en una escala de colores utilizando el comando c(\u0026quot;red\u0026quot;,\u0026quot;#FF4500\u0026quot;...). Una página recomendable para seleccionar colores y obtener su código de color con un click es r-charts.com/colors/. También puedes emplear las funciones auxiliares que ofrece R, por ejemplo: scale_color/fill_brewer/viridis_. Estas proporcionan escalas predefinidas que podrían mejorar el impacto visual.\nGuardando nuestro mapa RStudio ofrece la posibilidad de exportar fácilmente desde su menú ubicado encima de la vista previa del gráfico \u0026quot;Export\u0026quot;. Podemos optar por guardar nuestro mapa con mayor calidad o cierto formato y, para ello, podemos usar ggsave(), que nos permite exportar o guardar nuestro último gráfico ejecutado.\n1ggsave( 2 filename = \u0026#34;grafica.png\u0026#34;, 3 path = \u0026#34;.../mypath/\u0026#34;, 4 scale = 1, 5 device = \u0026#34;png\u0026#34;, 6 dpi = 320 7) Guarda el mapa con el nombre filename en la ruta path, con la escala y formato de scale y device. Con dpi indicamos la cantidad de píxeles por pulgada, que es la calidad de nuestro archivo a exportar.\nReferencias Repositorio del ejemplo Instituto Nacional de Estadística Bolivia GeoBolivia geodatos.net Robinlovelace Documentacion de R ","link":"https://opensciencelabs.org/blog/dibuja-tus-mapas-en-r-usando-archivos-de-formato-shapefile/","section":"blog","tags":["mapas","datos","visualización de datos","shapefile"],"title":"Dibuja tus mapas en R usando archivos de formato Shapefile"},{"body":"","link":"https://opensciencelabs.org/tags/gganimate/","section":"tags","tags":null,"title":"gganimate"},{"body":"","link":"https://opensciencelabs.org/tags/ggplot2/","section":"tags","tags":null,"title":"ggplot2"},{"body":"","link":"https://opensciencelabs.org/tags/mapas/","section":"tags","tags":null,"title":"mapas"},{"body":"","link":"https://opensciencelabs.org/tags/nft/","section":"tags","tags":null,"title":"nft"},{"body":" Quizá hayas escuchado el término NFT últimamente. Títulos de noticias descabelladas como «Porque este CryptoPunk NFT fue vendido por $532 millones de USD» o «Memes clásicos que fueron vendidos como NFT».\nEn este último artículo, se hace mención al meme de la «novia posesiva» que fue vendido por $411,000.00 USD.\nOverly attached Girlfriend MEME Pero, ¿Qué es un NFT? Equivocadamente, se entiende como un JPG, o sea, un archivo de imagen. Si le doy click derecho y \u0026quot;guardar imagen\u0026quot;, ¿también tendría el NFT?, y ¿gratis?.\nRecientemente, se hizo viral el hecho de que en un torrent estaban todos los NFTS actuales, una colección billonaria, descargable para cualquiera.\nTorrents de NFTs NFT es mucho más que una imagen, o un video, o una canción. Es la representación digital de una propiedad. Imagina un sistema totalmente independiente, inmutable, donde se reconoce tu propiedad. Por el momento lo que está pegando, es arte, más específico, artes visuales digitales (imágenes y videos). Sin embargo, no te extrañes ver campañas de NFT que sean mucho más que imágenes, que podrían ser canciones, películas, cortos y lo que puedas imaginar digital.\nDejando claro que es mucho más que una imagen, entonces podemos decir que un NFT es un registro de propiedad, validado por una cadena de bloques, descentralizada e inmutable, que nunca caducará. Creo que en este punto la pregunta es: ¿Qué no podría ser un NFT?, bueno, hay muchas cosas que no pueden ser digitales, pero imagina todo lo que sí pueden, y todo lo que ya lo es.\nLeí el caso de un músico que creó su proyecto, su propio token, en vez de ser bitcoin o eth, y lo usó para juntar fondos para su disco. Los fans pudieron dar apoyo a su artista favorito, colaborando a su crowdfunding, y obtienen cierta cantidad del token del artista (un NFT). Al tener ingresos por su nuevo álbum, el artista le dio parte de las regalías a los que tenían los NFTs.\nPodrás leer más aquí: NFTs are revolutionizing the music industry too. Esto nos lleva a lo que realmente mueve la web 3.0, propiedad de nuestros bienes digitales (ownership).\nLo cierto es que, el NFT le viene a dar más poder e independencia al artista. Jack Conte, el CEO de Patreon, es un músico independiente que notó un fenómeno: se esforzaba minuciosamente por hacer sus videos musicales, le metía todo su dinero para hacer sus videos creativos, con stop motion, y proyecciones, y nada pasaba, unas cuantas vistas en sus videos de youtube. Luego notó que a pesar de tener éxito en youtube, y que la gente llegaba a sus presentaciones, no lograba ser económicamente sostenible. Tienes talento, tienes fans, y entregas constantemente tu arte, ¿Qué es lo que falta?.\nEl modelo de negocio actual se trata del intermediario. Amazon no hace dinero fabricando productos, AirBnb no hace dinero alquilando sus propiedades, Uber no hace dinero con sus propios autos. Todos son intermediarios, y sus modelos de negocio les permiten ganar mucho dinero manejando el uso de la propiedad ajena. Lo mismo pasaba con Jack y youtube, así que creó Patreon, una plataforma en la que los fans apoyan al artista directamente. Para mí esta es la primera versión de la revolución del arte, y el NFT solo va a venir a acelerarlo. Imagina que ser artista o creador de contenido, ya no sea una carrera en las que tus familiares te dirían «de eso no vas a poder vivir», «pero necesitas una carrera de verdad».\n¿Estamos ante una burbuja? Hay muchas opiniones al respecto, y como en cualquier tema te recomiendo hacer tu propia investigación y llegar a tus propias conclusiones, especialmente si hay dinero en juego.\nPersonalmente, pienso que si esto es una burbuja, los precios son ridículamente altos y eventualmente se normalizarán.\nEs importante entender que, la burbuja aquí es el precio, no la tecnología, y esta tecnología vino para quedarse.\nBubuja de las .com La burbuja de las “.com” es algo que resuena cuando se habla de este punto. Cuando vino la tecnología de la web 2.0, se creó una burbuja, que explotó y apenas 2 de cada 10 compañías sobrevivieron. Sin embargo, la tecnología se quedó, y nos dio los gigantes tech que tenemos hoy en día como: google, facebook, twitter, etc.\nClaro, el NFT actual hace una intersección entre dos mundos que no todos tenemos acceso, el invertir cantidades ridículamente altas de dinero en arte, y la tecnología disruptiva que no está lista para ser mainstream. Si le quitamos la tecnología, solo nos queda gente gastando un montón de dinero en representaciones visuales que son interpretadas. Y eso ya pasa, hay pinturas y arte moderno que hoy en día se venden por precios ridículamente altos. Así que el consejo es, no le busques el sentido al precio del arte, entiende la tecnología por detrás, y no te dejes engañar o cegar por JPGs de millones de dólares.\n","link":"https://opensciencelabs.org/blog/nft-mas-que-un-jpg/","section":"blog","tags":["nft","criptomoneda","Blockchain"],"title":"NFT. Más que un JPG"},{"body":"","link":"https://opensciencelabs.org/tags/shapefile/","section":"tags","tags":null,"title":"shapefile"},{"body":"","link":"https://opensciencelabs.org/categories/tecnolog%C3%ADa/","section":"categories","tags":null,"title":"tecnología"},{"body":" Una gráfica es una buena manera de expresar los datos, estos ayudan a ver detalles que simplemente pueden pasar desapercibidos cuando sólo se los analizan numericamente, estos pueden tener aún mayor impacto si estan animados. ¿Por qué no hacerlo?. En este artículo se describe como hacer animación usando ggplot2 y gganimate en R.\nComenzando Usamos R por ser un lenguaje especializado para ciencia de datos y tener una gran Comunidad Open Source. Antes de comenzar recomendamos tener las versiones actualizadas de R y su IDE RStudio.\nPuedes descargar R y RStudio desde sus páginas web oficiales:\ncran.r-project.org\nrstudio.org\nInstalación de pre-requisitos Para este ejemplo usamos las bibliotecas de rio, dplyr, ggplot2 y gganimate. Las instalamos con los siguientes comandos en R (Recuerde que para ejecutar una linea de Comando en el Editor de RStudio Es con Ctrl+Enter o puede escribirlo directamento en la Consola)\n1install.package(rio) # Biblioteca para importar archivos csv o xlsx 2install.package(dplyr) # Biblioteca para filtrar datos 3install.package(ggplot2) # Biblioteca para realizar las gráficas 4install.package(gganimate) # Biblioteca para realizar la animación Preparación de los datos para graficar Los datos usados pertenecen a la base de datos del INE (Instituto Nacional de Estadística Bolivia), el archivo usado tiene el nombre de \u0026quot;Importaciones de Productos y Artículos de Bolivia 1992-2021p\u0026quot;\nAbrimos nuestras bibliotecas:\n1library(rio) 2library(ggplot2) 3library(gganimate) 4library(dplyr) Importamos los datos a un objeto llamado libro con:\n1libro \u0026lt;- import(\u0026#34;.my/path/DatosImportacionBolivia1992-2021.csv\u0026#34;) Para ver la cabecera del libro, y para ver la estructura del libro ejecutamos respectivamente head(libro) y str(libro).\n1\u0026gt; head(libro) 2 Fecha ALIMENTOS Y BEBIDAS SUMINISTROS INDUSTRIALES COMBUSTIBLES Y LUBRICANTES 31 1992-01-01 12.686477 30.38827 1.738607 42 1992-02-01 9.139570 32.57593 1.822906 53 1992-03-01 6.150201 21.37546 2.000110 64 1992-04-01 9.225652 28.34524 1.455245 75 1992-05-01 14.503611 22.06801 2.168646 86 1992-06-01 5.875804 25.43617 3.084602 9 BIENES DE CAPITAL EQUIPO DE TRANSPORTE Y SUS PIEZAS Y ACCESORIOS ARTÍCULOS DE CONSUMO 101 25.66374 22.20454 5.585219 112 22.00027 18.68626 6.528652 123 22.92478 17.40578 6.196415 134 31.14429 16.77957 5.422824 145 26.82719 22.79343 5.458318 156 23.47011 16.00698 5.647866_ 1\u0026gt; str(libro) 2\u0026#39;data.frame\u0026#39;:\t358 obs. of 7 variables: 3 $ Fecha : IDate, format: \u0026#34;1992-01-01\u0026#34; \u0026#34;1992-02-01\u0026#34; ... 4 $ ALIMENTOS Y BEBIDAS : num 12.69 9.14 6.15 9.23 14.5 ... 5 $ SUMINISTROS INDUSTRIALES : num 30.4 32.6 21.4 28.3 22.1 ... 6 $ COMBUSTIBLES Y LUBRICANTES : num 1.74 1.82 2 1.46 2.17 ... 7 $ BIENES DE CAPITAL : num 25.7 22 22.9 31.1 26.8 ... 8 $ EQUIPO DE TRANSPORTE Y SUS PIEZAS Y ACCESORIOS: num 22.2 18.7 17.4 16.8 22.8 ... 9 $ ARTÍCULOS DE CONSUMO : num 5.59 6.53 6.2 5.42 5.46 ... Es importante verificar el tipo de dato, antes de graficar, en este caso nos importa que la fecha tenga formato de IDate y los demás sean tengan formato de num. En caso de que la fecha no tenga formato IDate puedo tranformar la columna usando la el comando columna\u0026lt;-as.Date(columna).\nCon las siguientes líneas de código, compactamos el número de columnas de nuestro libro en un nuevo objeto llamado datos. (Notese que solamente utilizaremos las primeras 4 columnas del objeto libro). Es decir una columna para la fecha, una columna para su valor y otra columna que muestre su clasificación.\n1# Simplificando nuestra tabla para realizar las gráficas 2# Cuando se escribe el nombre del objeto libro$.. en RStudio el autocomplado con los nombres de la columnas del libro 3datos \u0026lt;- 4 data.frame( 5 Fecha = c(libro$Fecha, libro$Fecha, libro$Fecha, libro$Fecha), 6 Valor = c( 7 libro$`ALIMENTOS Y BEBIDAS`, 8 libro$`SUMINISTROS INDUSTRIALES`, 9 libro$`COMBUSTIBLES Y LUBRICANTES`, 10 libro$`EQUIPO DE TRANSPORTE Y SUS PIEZAS Y ACCESORIOS` 11 ), 12 Clasificacion = c( 13 rep(\u0026#34;Alimentos y Bebidas\u0026#34;, nrow(libro)), 14 rep(\u0026#34;Suministros Industriales\u0026#34;, nrow(libro)), 15 rep(\u0026#34;Combustibles y Lubricantes\u0026#34;, nrow(libro)), 16 rep(\u0026#34;Equipo de Transporte\u0026#34;, nrow(libro) 17 ) Funciones auxiliares usadas:\nlibro$columna: para acceder al columna del libro.\ndata.frame(columna1, columna2 ...): para crear una nuevo objeto de Datos.\nc(elemento1, elemento2, ...): para juntar elementos en un vector.\nrep(elemento, n_veces): para generar un vector con el elemento repetido n_veces.\nnrow(tabla): para obtener el número de filas de tabla.\nObservemos la cabecera de datos para verificar, con head(datos) :\n1\u0026gt; head(datos) 2 Fecha Valor Clasificacion 31 2018-01-01 56.34888 Alimentos y Bebidas 42 2018-02-01 47.42231 Alimentos y Bebidas 53 2018-03-01 59.54501 Alimentos y Bebidas 64 2018-04-01 56.08808 Alimentos y Bebidas 75 2018-05-01 51.86330 Alimentos y Bebidas 86 2018-06-01 43.84668 Alimentos y Bebidas Gráfica estática Para graficar con ggplot2, es conveniente entender que esta biblioteca añade sus componentes en layers (capas), estos layers son objetos a los cuales se le puede modificar su apariencia y especificar de donde extraer sus valores.\nAsignamos a un objeto ggplot llamado p1 lo que vamos a graficar:\n1# Modificando el theme a uno con el fondo blanco 2theme_set(theme_bw()) 3 4p1 \u0026lt;- ggplot(data = datos) + 5 geom_line(aes(x = Fecha, y = Valor, color = Clasificacion), size = 0.5) + 6 theme(legend.position = \u0026#34;right\u0026#34;) + 7 labs( 8 x = \u0026#34;Fecha\u0026#34;, 9 y = \u0026#34;Valor en MM Bs\u0026#34;, 10 color = \u0026#34;\u0026#34;, 11 title = \u0026#34;Datos de Importación de Bolivia 1991-2021p\u0026#34;, 12 subtitle = \u0026#34;Expresado en Millones de Bolivianos\u0026#34; 13 ) 14p1 Funciones utilizadas\ntheme_set(theme_bw()): modifica el conjunto de colores usado en el tema para realizar la gráfica.\nggplot(data): esta es la primera capa a utilizarse inicialmente le asignamos nuestos datos data para que cree las dimensiones de las coordenadas y esta se herede a las otras capas.\ngeom_line(aes(x, y, color), size): capa que hereda los datos de ggplot(), se los puede usar directamente con el nombre de sus columnas, grafica los datos x e y como líneas, las clasifica de acuerdo al color y size determina el grosor de sus líneas.\ntheme(legend.position): capa que modifica la posición de la leyenda dentro gráfico, con legend.position, esta puede adquirir valores de top, left, etc.\nlabs(x, y, color, title, subtitle): capa que pone los nombres a eje x y al eje y, además de poner el nombre encima de las leyendas con color, el nombre título y subtítulo con title y subtitle respectivamente.\nGráfica Animada Ya teniendo nuestra nuestra gráfica estática, vamos a realizar algunas modificaciones para que se resalten los datos de nuestro interés.\nFiltrando datos con fecha mayor al año 2019.\n1datos \u0026lt;- filter(datos, datos$Fecha \u0026gt;= as.Date(\u0026#34;2019-01-01\u0026#34;)) filter(datos, condicion): evalua cada fila de datos y filtra de acuerdo a la condicion.\nas.Date(var) convierte var a un formato de fecha IDate\nAgregando un nuevo data frame periodos para resaltar las fechas de confinamiento por Covid19.\n1periodos \u0026lt;- 2 data.frame( 3 xmin = as.Date(\u0026#34;2020-03-22\u0026#34;), 4 xmax = as.Date(\u0026#34;2020-08-31\u0026#34;), 5 ymin = -Inf, 6 ymax = Inf, 7 Periodo = \u0026#34;Confinamiento por COVID19\u0026#34; 8 ) Creando un nuevo objeto ggplot2 p2 para incluir las nuevas modificaciones.\n1p2 \u0026lt;- ggplot(data = datos) + 2 geom_line(aes(x = Fecha, y = Valor, color = Clasificacion), size = 1) + 3 geom_rect( 4 data = periodos, 5 alpha = 0.2, 6 aes( 7 xmin = xmin, 8 xmax = xmax, 9 ymin = ymin, 10 ymax = ymax, 11 fill = Periodo 12 ) 13 ) + 14 theme(legend.position = \u0026#34;right\u0026#34;) + 15 labs( 16 x = \u0026#34;Fecha\u0026#34;, 17 y = \u0026#34;Valor en MM Bs\u0026#34;, 18 color = \u0026#34;\u0026#34; , 19 fill = \u0026#34;\u0026#34;, 20 title = \u0026#34;Datos de Importación Bolivia 2019-2021p\u0026#34;, 21 subtitle = \u0026#34;Expresado en Millones de Bolivianos\u0026#34; 22 ) 23p2 geom_rect(data, alpha, aes(xmin, xmax, ymin, ymax, fill)): dibuja un rectangulo a partir de los datos en Data, modifica su opacidad de acuerdo a alpha, extrae los datos de acuerdo a xmin, xmax, ymin, ymax, y los clasifica de acuerdo a fill.\nlab(fill): pone el nombre encima de la leyenda de los datos clasificados con fill.\nCon las modificaciones ya hechas en p2, creamos el objeto gganimate llamado anim el cuál contendrá nuestra grafico a animar.\n1anim \u0026lt;- p2 + transition_reveal(Fecha) + 2 geom_label(aes( 3 x = as.Date(\u0026#34;2019-06-01\u0026#34;), 4 y = 280, 5 label = format(datos$Fecha, \u0026#34;%Y\u0026#34;) 6 ), 7 col = \u0026#34;gray\u0026#34;, 8 size = 15) transition_reveal(var): añade la capa de animacion del tipo transición usando como referencia la variable var.\ngeom_label((aes(x,y,label)) col, size): añade la capa de etiquetas del año dentro de la gráfica, con aes(x, y, label): x e y son las coordenadas donde se grafica la etiqueta label, con col seleccionamos un color y con size el tamaño.\nNota: geom_label() fué diseñado para graficar etiquetas que acompañen a la gráfica. En este ejemplo en específico fué usado como una etiqueta estática fijando sus coordenadas x e y en un sólo punto. Se optó por esta opción ya que genera un buen impacto visual.\nCon el objeto anim creado podemos invocar la función animate() de gganimate. Una vez ejecutada la función se abrirá una ventana con el resultado en formato .gif.\n1animate( 2 anim, 3 fps = 25, 4 duration = 15, 5 width = 800, 6 height = 500, 7 end_pause = 30 8) animate(anim, fps, duration, width, height, end_pause): animate() funcion para generar la animación, anim objeto a animarse, fps cantidad de frames por segundo, duration duración de la animación en segundos, with, height ancho y alto de la animación respectivamente en pixeles, end_pause cantidad de veces a repetirse el último frame para la animación. Hay casos en los que extrañamente no se instalan los renders para hacer la renderización de la animación y aparece un error al tratar de ejecutar el código arriba mostrado, en ese caso puede probar con la siguiente solución: Ejecute en modo administrador RStudio e instale los renders con install.packages(\u0026quot;gifski\u0026quot;) para el render que viene por defecto con gganimate, tambien puede instalar el render magick con install.packages(\u0026quot;magick\u0026quot;) para tener otra opción para renderizar. Para saber que opciones tiene el render magick ejecute help(\u0026quot;magick_renderer\u0026quot;) y se le mostrara su breve manual.\nDespues de ver la animación podemos guardarla haciendo:\n1archivo \u0026lt;- 2 animate( 3 anim, 4 fps = 25, 5 duration = 15, 6 width = 800, 7 height = 500, 8 end_pause = 30 9 ) 10 11anim_save(filename = \u0026#34;datosimportpandemia.gif\u0026#34;, 12 animation = archivo, 13 path = \u0026#34;.my/path/save/\u0026#34;) anim_save(filename, animation, path): guarda el renderizado de animation con el nombre filename en la ruta path.\nReferencias Instituto Nacional de Estadística Bolivia Documentacion de R ","link":"https://opensciencelabs.org/blog/visualiza-tus-datos-en-r-con-ggplot-y-gganimate/","section":"blog","tags":["visualización de datos","ggplot2","gganimate"],"title":"Visualiza tus datos en R con ggplot2 y gganimate"},{"body":"","link":"https://opensciencelabs.org/tags/bitcoin/","section":"tags","tags":null,"title":"bitcoin"},{"body":" Alguna vez te has pregundado, ¿Cómo puedo mejorar mis habilidades de programación?. Este artículo tiene la respuesta, te mostraremos una de las mejores plataformas para que puedas practicar programación resolviendo problemas.\n¿Qué es Code Abbey ? Creemos que hay tres cosas que nos guían al éxito: Practica, Practica y ¡Practica!\nCode Abbey es una plataforma, impulsada y mantenida por Rodion Gorkovenko con ayuda de la comunidad de Code Abbey, contiene gran cantidad de problemas con dificultad variable, desde una simples sumas, hasta algunas donde tienes que aplicar conceptos de Inteligencia Artificial. Puedes resolver los problemas en varios lenguajes: C, C++, C#, Python, Java, JavaScript e incluso con algunos menos conocidos como: Turing y Brainf**k.\n¿Cómo funciona? Puedes registrarte con una cuenta de gmail, facebook o de GitHub.\nUn vez hecho el Login puedes ver los problemas haciendo click en la pestaña Problems. Seleccionado el problema se te abrira la siguiente ventana:\nLa primera sección podrás ver el enunciado del problema y un ejemplo de entrada y salida de lo solicitado. Cuando tengas la resolución del problema (script o código), lo haces correr con los datos de entrada del test (Test Data).\nLa solución que arroje tu programa la copias en el espacio vacio de de You Answer. Luego le puedes dar click a Submit, una vez se haya comprobado que la respuesta es correcta, la resolución del problema será dada como válida.\nOtra forma de verificar que tu código arroja la respuesta correcta es pegar el código a la plataforma en el espacio vacio que encuentra por encima del boton Submit, y hacerla correr con los botones que se encuentran en la parte inferior derecha, haciendo click en el botón de tu lenguaje de programación hará correr el script con los datos de test data y escribira la solución en la parte de Your Answer y guardará tu código en la plataforma. Es recomendable guardar el código en la plataforma incluso si no haces correr y sólo subes la respuesta manualmente, esto permite la compobracion para lo administradores de Code Abbey de que estas resolviendo los problemas por tu cuenta.\nUna vez tu solución haya sido validada se te añadiran puntos de Enlightment (que están calculados en base a la cantidad de personas que resolvieron el mismo problema) y con base a los problemas resueltos se te asignará un rango dentro de la comunidad.\nZealus Coder rank Cuando resuelvas 120 problemas de los marcados con negrita o con la etiqueta c-1, puedes reclamar el certificado de CodeAbbey Zealous Coder, que certificará que resolviste los problemas difíciles de la plataforma. Como forma de motivar a que más mujeres entren al mundo de la programación, Code Abbey da un diploma honorario a las chicas que resuelvan 85 problemas y el rango de Fanatic Girl-Coder.\n¿Por qué resolver problemas en Code Abbey? Muy aparte de la satifacción de resolver problemas, ascender rangos, pertenecer a una comunidad y/o obtener un certificado que puedas presumir en tus redes. Se tiene que tener en cuenta que la resolución de estos problemas, ayudan a afinar tus habilidades en programación, porque para la resolución de los problemas se requieren conocimientos de conceptos básicos, estadística, estructura de datos, algoritmos de busqueda, ordenación, criptografía, teoría de números, entre otros. Estos problemas, pueden ayudarte a prepararte para entrevistas y/o para mejorar tu propio código, viendo cómo lo han resuelto los demás (esta opción se habilita cuando tu solución sea tomada como válida).\n¿Qué hacer cuando un problema es muy complicado? Puedes ir a la sección de Volumes de la plataforma y darle una leida, y si no basta puedes darle un vistazo a los siguientes recursos:\nCS50X: Curso gratuito, ideal para los que empiezan a programar. Python Crash Course - Eric Matthes: Libro para iniciantes en python. Learn X in Y. Recurso web para aprender cualquier lenguaje de programación. Grokking algorithms- Aditya Bhargava: Libro para preparte en problemas complicados. Craking the Coding interview - Gayle Laskmann: Libro para preparte en problemas complicados. Libros para mejorar tus matemáticas\nMathematics for Computer Science - Eric Lehman and Tom Leighton Introduction to algorithms - Thomas H. Cormen Algorithm Design - Jon Kleinberg ¿Sitios similares? ROSALIND Orientado a problemas de programación en Bioinformática. Project Euler Contiene poblemas matemáticos y de programación. algo.is Problemas de competición de programación. exercism Contiene problemas variados de programación. Referencias Code Abbey\n","link":"https://opensciencelabs.org/blog/code-abbey-una-plataforma-mejorar-tu-habilidad-en-programacion/","section":"blog","tags":["codeabbey","retos de programación"],"title":"Code Abbey una plataforma para mejorar tu habilidad en programación"},{"body":"","link":"https://opensciencelabs.org/tags/codeabbey/","section":"tags","tags":null,"title":"codeabbey"},{"body":" Si ya eres desarrollador y tienes la meta, el deseo, o simplemente la curiosidad de adentrarte en la web3, en este blog te mencionaré las tecnologías que se utilizan en el tech stack para desarrollar.\nEmpecemos con un esquema básico, la web3, no funciona diferente de la web normal en teoría, lo que cambia es que en vez de tener un solo lugar centralizado con nuestros datos en el backend, está disperso por los nodos, ya sea directo en los smart contracts (si fuera Ethereum) o en el uso de algún servicio IPFS. Mientras el frontend es lo mismo que ya usas. Html, Css, JS, React, vue o cualquier otro frontend framework.\nEs importan destacar que la web3 no es excluyente de las tecnologías existentes. Puedes tener tu backend en nodejs, php, java, .net, python o el que prefieras y aun así interactuar con servicios web3.\nDesarrollo local Así como en la web2, tienes tu desarrollo local, ya sea con docker o con instalaciones de tu servidor en el localhost. En el web3 tenemos herramientas como hardhat o ganache\nBackend Hardhat Es una herramienta para correr Solidity localmente. Encuentras una manera fácil para hacer deploy de tus contratos, correr tests y debuguear código en Solidity en diferentes versiones.\nSe corre como un paquete global de Node.js que se instala con NPM 1npm install --save-dev hardhat Ganache (Truffle Suite) Tu blockchain local en un clic. Con `Ganache` pueden lanzar rápidamente un blockchain personal para correr tus tests, e inspeccionar el estado mientras controlas como la cadena opera. Para instalarlo se debe correr un ejecutable y se instala como cualquier otra aplicación en tu sistema.\nAprende Solidity Uso de ejemplo Solidity, pero podrías aprender cualquier otro lenguaje como Rust para programar en el blockchain de solana.\nRegresando a Solidity, si ya estás familiarizado con JavaScript, notaras muy familiar la sintaxis de Solidity. Es un lenguaje de tipado estático, con llaves, diseñado para desarrollar smart contracts que corren en Ethereum.\nAquí un ejemplo de un contrato en Solidity, un sencillo Hello World\n1// SPDX-License-Identifier: MIT 2 3pragma solidity ^0.8.0; 4 5contract MyContract { 6 7function helloWorld() public pure returns (string memory) { 8 9return \u0026#34;Hello, World!\u0026#34;; 10 11} 12 13} Si ya has programado antes podrás encontrar las similitudes.\nSe declara la licencia del contrato. Recuerda que la mayoría, por no decir todos, los contratos son open source, así que cualquiera puede leer o interactuar con ellos.\nSe declara la versión del compilador (pragma solidity ^0.8.0)\nSe declara el contrato como tal. Palabra reservada contract y el nombre designado.\nSe crea la función helloWorld. Nota que después del nombre, tienen otros términos. Estos términos se llaman modificadores de acceso. El public se comporta como ya imaginas, el interesante y nuevo es pure que indica que esta función no requiere gas para hacerla funcionar. Es solo lectura, entre otras cosas.\nComo todo lenguaje tiene sus partes complejas y únicas que te invito pruebes y aprendas en su documentación\nPerfecto, ya tengo mi blockchain y mi contrato ¿Ahora que? Listo, cada herramienta tiene su modo de publicar o desplegar tus contratos a tu red local.\nPor ejemplo, con Hardhat:\n1npx hardhat compile Con Ganache, se debe usar otra herramienta de la misma familia llamada truffle, y se ejecuta de la misma manera que hardhat\n1 2npm install truffle -g y luego para compilar\n1 2truffle compile Al tener tu contrato desplegado ya podrás interactuar con él, usando web3.js o ether.js. En otras palabras, ya se trata del frontend.\nFrontend Web3 JS Web3.js es la herramienta que maneja toda la lógica para conectarnos a nuestros smart contracts. Al compilar un contrato se genera un archivo llamado abi.json. Este archivo expone todos tus métodos públicos de tu smart contract, junto con los parámetros y tipos que espera. De esa manera tu frontend se podrá comunicar de manera exitosa con tus contratos.\nLa manera en que interactuamos con ellos es por pasos:\nInstancias una referencia a tu archivo abi. Recuerda que este es el que sabe, el cómo, cuando y donde, de la comunicación con tus contratos.\nAl tener la referencia de tu abi, puedes acceder por notación de objetos a tus métodos\n1 2// Importamos el abi del contrato 3 4import abi from \u0026#34;./utils/EtherFavoriteSongs.json\u0026#34;; 5 6this.contractABI = abi.abi; 7 8... 9 10// Obtenemos la referencia a la billetera del usuario 11 12const provider = new ethers.providers.Web3Provider(ethereum); 13 14const signer = provider.getSigner(); 15 16 17// Creamos una nueva instancia del contrato 18 19const favoriteSongsPortalContract = new ethers.Contract(this.contractAddress, this.contractABI, signer); 20 21 22// El método getTotalSongs esta definido en nuestro contrato de solidity 23 24let count = await favoriteSongsPortalContract.getTotalSongs(); Así de fácil podemos conectar nuestros nuevos contratos con nuestro conocido y confiable frontend.\nEl código completo de este ejemplo está en este repositorio\nBilletera (wallet) Otra diferencia entre web2 y web3 es que el usuario se identifica con una \u0026quot;billetera\u0026quot;, este es un término que no representa realmente lo que es y puede confundir a personas nuevas o que no tienen interés financiero en el blockchain. La más popular de estas herramientas es metamask aunque no la única, que te deja tener una dirección hexadecimal única, y puedes generar múltiples direcciones. Cada una de estas te sirve para identificarte con aplicaciones web3. En vez de tener que hacer login con tu correo una y otra vez, solo debes conectar tu dirección (en tu billetera) y ya puedes interactuar con la web3.\nEstas billeteras son gratuitas (si son software) y se instalan en segundos. Puede ser usada como extensión en tu navegador o en aplicaciones individuales.\nEsto es fundamental para el funcionamiento de la web3. Cada interacción con el blockchain queda firmado por quien hizo la petición. Así queda todo registrado en el blockchain.\nResumen Necesitas una blockchain local para tu desarrollo.\nNecesitas Aprender un lenguaje para hacer tus contratos (Solidity, por ejemplo).\nNecesitas compilar tus contratos.\nNecesitas un frontend, con lo que ya sepas o aprender sobre frontend. Html, css, js, react o vue js.\nNecesitas interactuar con web3.js en tu frontend.\nNecesitas una billetera para interactuar con tus contratos.\nEl ecosistema sigue creciendo aceleradamente, cada vez hay más herramientas y se van completando los vacíos. Todavía hace falta mucho product design, y desarrollo para volverlo mainstream. Hay gente que se refiere al estado actual del web3 como con los 90 en la web2. Largos tiempos de espera, a veces falla, falta de feedback al usuario. Así que si te interesa esto, puedes ser parte del futuro de la web, que hoy mismo se está construyendo.\n","link":"https://opensciencelabs.org/blog/que-necesitas-para-desarrollar-en-la-web3/","section":"blog","tags":["cripto","desarrollador"],"title":"Como desarrollador, ¿Qué necesito para entrar en la web3?"},{"body":"","link":"https://opensciencelabs.org/tags/cripto/","section":"tags","tags":null,"title":"cripto"},{"body":"","link":"https://opensciencelabs.org/tags/desarrollador/","section":"tags","tags":null,"title":"desarrollador"},{"body":"","link":"https://opensciencelabs.org/categories/desarrollo-de-software/","section":"categories","tags":null,"title":"desarrollo de software"},{"body":"","link":"https://opensciencelabs.org/tags/ethereum/","section":"tags","tags":null,"title":"ethereum"},{"body":" Oh sweet summer child, Ethereum ya no será el mismo, está evolucionando, al mismo tiempo que todo el ecosistema. No es secreto que todo el ecosistema crece, y a una velocidad agigantada. La masiva adopción de Ethereum trajo consigo problemas a la red como:\nTransacciones con gas demasiado alto (provocando transacciones de alto costo) Transacciones demasiado lentas. No te puedes imaginar pagar un café o una hamburguesa con Ethereum si el proceso tarde 5 o 10 minutos en validarse. Debido a las dos anteriores, demasiado consumo de energía eléctrica. Estos problemas lo sufren las dos blockchains más grandes del momento, bitcoin y Ethereum. En el caso de bitcoin, la solución es ligthing network. Para Ethereum, es este merge.\nEste puede ser uno de los cambios más esperado por la comunidad, trae consigo un gran cambio en el modo en que valida las transacciones, actualmente utiliza un mecanismo llamado POW (proof of work) y cambia a un mecanismo llamado POS (proof of stake). Este cambio mejorará la descentralización y el reducir bastante el consumo de energía que con eso traerá menores costos.\nProof of work Vs. Proof of stake El concepto de Proof of Work existe desde antes de los crypto assets. La primera idea fue publicada por Cynthia Dwork y Moni Naor en un artículo publicado en 1993, sin embargo, no fue hasta 1999 que el término \u0026quot;Proof of work\u0026quot; fue creada por Markus Jakobsson.\nPero, ¿Por qué se usa esto?. En el white paper de bitcoin, Satoshi Nakamoto teoriza que la única manera de vulnerar la fuerza de la red de bitcoin es a través de un ataque del 51% de la red. Por eso, propone el uso de proof of work para prevenir una entidad de ganar un control mayoritario sobre la red. Al aplicar proof of work en este sentido, se argumenta es la idea central necesaria para bitcoin, ya que permite un sistema de consenso realmente honesto y distribuido.\nAsí es como funciona actualmente bitcoin y Ethereum con el proof of work:\nUn grupo de transacciones son agrupadas en un memory pool (mempool). Los mineros verifican cada transacción en el mempool que se legitima al resolver un problema matemático. El primer minero en resolver el problema obtiene una recompensa con un nuevo bitcoin recién minado y el costo de la transacción. El mempool verificado, ahora llamado bloque, es añadido a la blockchain. Ahora el Proof of Stake, tiene el mismo propósito de validar transacciones y conseguir un consenso; sin embargo, se diferencia de proof of work, ya que no involucra un problema matemático a resolver. Ahora el validador de cada bloque se escoge determinísticamente basado en su stake. El stake es cuantas monedas/tokens posee. Ya podrás suponer que al no tener que resolver un problema matemático, la eficiencia energética de este sistema es mucho mayor, y esto lleva a menores costos de transacción. Además, que este sistema puede proveer un mejor incentivo para la salud de la red, al promover acumular moneda/tokens.\nPorque del merge Ethereum tiene muchos problemas, y este merge busca solucionar el blockchain trilemma\nSeguridad Descentralización Escabilidad Que beneficio trae el merge Descentralización y seguridad: El merge requiere un mínimo de nodos y hacer más fácil de correr un nodo. Para correr un nodo necesitas tener 32 ETH. Sostenibilidad: Proof of stake usa al menos 99% menos energía que proof of work. ETH 2.0 Este cambio en Ethereum ya venía siendo discutido desde el 2018, y había sido añadido al roadmap, pero se dieron cuenta de varias cosas:\nTomaría años en entregar por completo el roadmap. Hacer el cambio completo de PoW a PoS, requeriría una migración por parte de las aplicaciones existentes Entonces surgió la propuesta Eth1+Eth2 = Ethereum. Donde:\nEth1 = Execution Layer (actual red) Eth2 = Consensus Layer (el merge) El Consensus Layer es donde estará implementado el PoS, de esa manera se podrá aplicar el merge, sin requerir cambios en los usuarios actuales de la red. Este cambió lo explican más a fondo aquí The Great TH2 renaming.\nConclusión Para el usuario final no significará un cambio en billetera o en como interactúa con la red. Pero si verá los beneficios al tener transacciones más rápidas y de menor costo. Esto nos acercará a una blockchain más útil para el día a día, intercambiando valor. Es emocionante ver los cambios suceder y como se va mejorando el ecosistema.\nFuentes The great renaming The Ethereum merge is comming thread The Ethereum merge Pow and Pos explained ","link":"https://opensciencelabs.org/blog/ethereum-merge-is-coming-pero-que-significa/","section":"blog","tags":["ethereum","transacciones","bitcoin","criptomoneda"],"title":"Ethereum merge is coming. ¿Pero qué significa?"},{"body":"","link":"https://opensciencelabs.org/categories/programaci%C3%B3n/","section":"categories","tags":null,"title":"programación"},{"body":"","link":"https://opensciencelabs.org/tags/retos-de-programaci%C3%B3n/","section":"tags","tags":null,"title":"retos de programación"},{"body":"","link":"https://opensciencelabs.org/tags/transacciones/","section":"tags","tags":null,"title":"transacciones"},{"body":"","link":"https://opensciencelabs.org/categories/ui-ux/","section":"categories","tags":null,"title":"UI-UX"},{"body":"","link":"https://opensciencelabs.org/categories/web3/","section":"categories","tags":null,"title":"web3"},{"body":"Crea tu nube de palabras en R a partir de un documento de texto Una nube de palabras o wordcloud nos sirve para visualizar la frecuencia de palabras dentro de un texto. En este tutorial, usaremos el artículo de inteligencia artificial de Wikipedia para construir nuestra nube de palabras usando las bibliotecas tm y wordcloud.\nInstalación de pre-requisitos Para un mejor manejo de los paquetes, aquí vamos a utilizar la biblioteca pacman, esta nos permitirá hacer una instalación y activación de las bibliotecas de manera rápida. Recuerde instalar Rtools y la versión más reciente de R si está usando Windows.\n1# install.packages(\u0026#34;pacman\u0026#34;) # Si no tiene instalada la Biblioteca Pacman ejecutar esta línea de código 2library(\u0026#34;pacman\u0026#34;) Bibliotecas adicionales requeridas, instaladas y abiertas con pacman.\n1p_load(\u0026#34;tm\u0026#34;) # Biblioteca para realizar el preprocesado del texto, 2p_load(\u0026#34;tidyverse\u0026#34;) # Biblioteca con funciones para manipular datos. 3p_load(\u0026#34;wordcloud\u0026#34;) # Biblioteca para graficar nuestra nube de palabras. 4p_load(\u0026#34;RColorBrewer\u0026#34;) # Biblioteca para seleccionar una paleta de colores de nuestra nube de palabras. Importación del texto Para este ejemplo, descargamos nuestro artículo de formato texto de un repositorio, guardamos la dirección web en articulo_IA y lo descargamos usando la función read_file(). También puede usar los directorios locales para importar un texto de su preferencia. Si desea descargar el archivo que usamos en este ejemplo puede hacer hacerlo ejecutando download.file(\u0026quot;https://gist.github.com/EverVino/7bdbbe7ebdff5987970036f52f0e384f/raw/3a1997b6f9e3471555a941f8812ada0cef84977d/gistfile1.txt\u0026quot;, paste(getwd(),\u0026quot;/texto.txt\u0026quot;, sep=\u0026quot;\u0026quot;)) en la línea de comando de R, esto descargará el archivo y lo guardara en la carpeta de trabajo de R con el nombre de texto.txt.\nPara saber la carpeta de trabajo puede ejecutar getwd(). puede cambiar la carpeta de trabajo con la función setwd(\u0026quot;/nuevo_directorio_trabajo/\u0026quot;).\nLuego de importar el texto, vamos a convertirlo en un objeto tipo Source, esto facilitará la minería del texto y su posterior modificación.\n1articulo_IA \u0026lt;- \u0026#34;https://gist.github.com/EverVino/7bdbbe7ebdff5987970036f52f0e384f/raw/3a1997b6f9e3471555a941f8812ada0cef84977d/gistfile1.txt\u0026#34; 2texto \u0026lt;- read_file(articulo_IA) read_file(dir): Función de la biblioteca tidyverse que nos permite importar archivos de texto. El resultado de la función es un vector de un sólo elemento. dir es la direción local o url con el nombre del archivo de formato txt a importar. 1texto \u0026lt;- VCorpus(VectorSource(texto), 2 readerControl = list(reader = readPlain, language = \u0026#34;es\u0026#34;)) VCorpus (x, readerControl(y)): Donde x es un objeto del tipo Source, se recomienda que sea un objeto del tipo VectorSource. Para readerControl(y) y es una lista de parámetros para leer x.\nVectorSource(vector): Convierte una lista o vector a un objeto tipo VectorSource.\nPreprocesado de texto Una vez importado el texto, tenemos que eliminar la palabras que actúan como conectores, separadores de palabras , de oraciones, y números que no aportarán al análisis del texto, para ello usamos la función tm_map() que nos permite aplicar funciones al texto del Corpus.\n1texto \u0026lt;- tm_map(texto, tolower) 2texto \u0026lt;- texto %\u0026gt;% 3 tm_map(removePunctuation) %\u0026gt;% 4 tm_map(removeNumbers) %\u0026gt;% 5 tm_map(removeWords, stopwords(\u0026#34;spanish\u0026#34;)) 6texto \u0026lt;- tm_map(texto, removeWords, c(\u0026#34;puede\u0026#34;, \u0026#34;ser\u0026#34;, \u0026#34;pues\u0026#34;, \u0026#34;si\u0026#34;, \u0026#34;aún\u0026#34;, \u0026#34;cómo\u0026#34;)) 7texto \u0026lt;- tm_map(texto, stripWhitespace) tm_map(text, funcion_de_transformacion, parametros_de_funcion): Transforma el contenido de texto de un objeto Corpus o VCorpus, aplicando las funciones de transformación de texto.\ntolower: Función de transformación de texto, usado para convertir todas la mayúsculas a minúsculas.\nremoveNumber: Función para eliminar los números del texto.\nremoveWord: Función para remover palabras, stopword(\u0026quot;lang\u0026quot;): Lista de palabras conectoras en el lenguaje lang, es argumento de la función removeWord.\nstripWhitespace: Función para remover los espacios blancos de un texto.\nNótese que usamos ambas notaciones para transformar el texto del Corpus, la notación normal tm_map(x, FUN) y también la notación de la biblioteca de tydiverse pipeoperator \u0026gt;%\u0026gt;, que toma como argumento inicial el resultado de la anterior función.\nSi quiere observar los cambios del texto puede ejecutar en la consola writeLines(as.character(texto[[1]])), esto imprimirá el resultado en la consola.\nConstruyendo la tabla de frecuencia 1texto \u0026lt;- tm_map(texto, PlainTextDocument) PlainTextDocument: Convierte texto a un objeto tipo PlainTextDocument. Para el ejemplo, convierte un VCorpus a PlainTextDocument el cuál contiene metadatos y nombres de las filas, haciendo factible la conversión a un matriz. 1tabla_frecuencia \u0026lt;- DocumentTermMatrix(texto) DocumentTermMatrix(texto): Convierte texto a un objeto tipo term-document matrix. Es un objeto que va a contener la frecuencia de palabras. 1tabla_frecuencia \u0026lt;- cbind(palabras = tabla_frecuencia$dimnames$Terms, 2 frecuencia = tabla_frecuencia$v) Extraemos los datos que nos interesan del objeto tabla_frecuencia y los juntamos con cbind().\nEjecutando en la consola View(tabla_frecuencia) notamos que es un objeto, para acceder a sus valores usamos el símbolo $ dicho de otra manera: para acceder a las palabras usamos tabla_frecuencia$dimnames$Terms y para su correspondientes frecuencia en el texto tabla_frecuencia$v.\n1# Convertimos los valores enlazados con cbind a un objeto dataframe. 2tabla_frecuencia\u0026lt;-as.data.frame(tabla_frecuencia) 3# Forzamos a que la columna de frecuencia contenga valores numéricos. 4tabla_frecuencia$frecuencia\u0026lt;-as.numeric(tabla_frecuencia$frecuencia) 5# Ordenamos muestra tabla de frecuencias de acuerdo a sus valores numéricos. 6tabla_frecuencia\u0026lt;-tabla_frecuencia[order(tabla_frecuencia$frecuencia, decreasing=TRUE),] Con estos últimos ajustes ya tenemos nuestra tabla de frecuencias para graficarla. Puede verificar los resultados ejecutando en la consola head(tabla_frecuencia)\nGraficando nuestra nube de palabras Una vez obtenida nuestra tabla de frecuencia sólo es necesario aplicar la función wordcloud().\n1wordcloud(words = tabla_frecuencia$palabras, 2 freq = tabla_frecuencia$frecuencia, 3 min.freq = 5, 4 max.words = 100, 5 random.order = FALSE, 6 colors = brewer.pal(8,\u0026#34;Paired\u0026#34;)) wordcloud(word, freq, min.freq, max.words, random.order, color): Función para graficar la frecuencia de palabras, el tamaño de la palabra graficada será proporcional a la frecuencia de la misma. Esta función grafica las palabras en word con sus respectivas frecuencias freq, sólo usará las palabras que como mínimo tenga una frecuencia mínima min.freq, la cantidad de palabras en graficadas es igual a maxwords, las posiciones podrán ser aleatorias o no, dependiendo del valor de random.order, los colores estan dados en forma de lista en colors. brewer.pal(n, \u0026quot;paleta\u0026quot;): Devuelve n valores de la paleta. Para la función brewer.pal() puede usar las paletas \u0026quot;Dark2\u0026quot;, \u0026quot;Set1\u0026quot;, \u0026quot;Blues\u0026quot; entre otros. Cada vez que ejecute la función le mostrará diferentes resultados, para evitarlo si así se desea, puede fijar un estado inicial para generar números aleatorios que utiliza la función wordcloud. Use: set.seed(1234) para este propósito (puede alterar el valor del argumento numeral para diferentes resultados).\nGuardando nuestra nube de palabras Usamos la función png() para guardar la gráfica que se genera usando wordcloud. También puede usar otras funciones como jpeg, svg y otros. Nótese que usamos la función png() y dev.off() antes y despues de la función generadora de la grafica wordcloud()\n1png(\u0026#34;nube.png\u0026#34;, width = 800,height = 800, res = 100) 2 wordcloud(...) 3dev.off() png(\u0026quot;nombre.png\u0026quot;, with, height, res) ... dev.off(): Guarda el gráfico generado en formato png, dentro del directorio actual de trabajo. Lo guarda con el nombre \u0026quot;nombre.png\u0026quot; con el ancho y alto en pixeles de with y height respectivamente; y con la resolución res en ppi. Con dev.off() concluimos la obtención de datos de png(). Otra biblioteca muy utilizada para generar una nube de palabras es wordcloud2, esta posee muchos más parámetros para modificar la apariencia de la nube, pero teniendo en cuenta que R está optimizado para realizar tratamiento de datos y no tanto para dibujar palabras, es recomendable usar otras opciones online o programas de diseño gráfico, si queremos mejores resultados. Y usar R para la obtención de la tabla de frecuencia de las palabras. Nota: Existen palabras que pueden derivar de una misma palabra y expresan el mismo significado, como ser nube, nubes, nubarrón, que estan diferenciadas aquí en este ejemplo, estos requieren la aplicación adicional de una función que contemple estas variaciones linguisticas, lamentablemente a la fecha no hay una función equivalente para el español para R. Sin embargo si realiza el análisis de palabras en inglés puede usar tm_map(Corpus_en_ingles, stemDocument, language=\u0026quot;english\u0026quot;).\nFinalmente antes de concluir cerramos las bibliotecas abiertas con pacman. La ventaja de hacer esto se ve cuando manejamos diferentes bibliotecas que tienen funciones con el mismo nombre, al cerrar las bibliotecas con conflictos, nos evitamos de especificar en el código a que biblioteca de R nos referimos.\n1p_unload(all) Referencias Wikipedia-Inteligencia Artificial Documentacion de R ","link":"https://opensciencelabs.org/blog/r-nube-de-palabras/","section":"blog","tags":["nube de palabras","tm"],"title":"Crea una nube de palabras en R a partir de un documento de texto"},{"body":"","link":"https://opensciencelabs.org/categories/miner%C3%ADa-de-datos/","section":"categories","tags":null,"title":"minería de datos"},{"body":"","link":"https://opensciencelabs.org/tags/nube-de-palabras/","section":"tags","tags":null,"title":"nube de palabras"},{"body":"","link":"https://opensciencelabs.org/tags/tm/","section":"tags","tags":null,"title":"tm"},{"body":"","link":"https://opensciencelabs.org/tags/framework/","section":"tags","tags":null,"title":"framework"},{"body":"","link":"https://opensciencelabs.org/categories/investigaci%C3%B3n-abierta/","section":"categories","tags":null,"title":"investigación abierta"},{"body":"","link":"https://opensciencelabs.org/tags/osf/","section":"tags","tags":null,"title":"osf"},{"body":"","link":"https://opensciencelabs.org/tags/proyectos/","section":"tags","tags":null,"title":"proyectos"},{"body":" El Open Science Framework (OSF)1 es un conjunto de herramientas diseñadas tanto para organizar, facilitar y mantener el proceso de vida de la investigación, como para la captura de los distintos estados que esta toma a lo largo de su realización. Mediante la creación de un \u0026quot;proyecto\u0026quot; (asociado a un DOI) y su respectiva wiki en su sitio web1, los usuarios son llevados a un dashboard donde podrán administrar de manera sencilla archivos, componentes (\u0026quot;subproyectos\u0026quot;), metadatos, usuarios, y demás, con su respectivo registro de actividad, que junto a un sistema de control de versiones permiten la eficaz revisión de cualquier error que se presenté.\nEste sistema fue creado por el Center for Open Science (COS)2, una organización sin fines de lucro fundada en el 2013 en Charlottesville, Virginia con el proposito de incentivar e incrementar la integridad, reproducibilidad y transparencia de la investigación científica sin importar la disciplina en la que se desenvuelva. Como parte de su misión de crear la infraestructura necesaria para alcanzar estos objetivos, desarrollaron el OSF, el cual es utilizado por una variedad de instituciones alrededor del mundo y posée soporte para una multitud de servicios (tales como Google Scholar, Dropbox, Zotero, o SSO) que permite que pueda ser integrado de manera continua y inobstructiva en el flujo de investigación.\n¿Como funcióna el Open Science Framework? Como fue anteriormente mencionado, el OSF funciona mediante una pagina web que mantenga un repositorio de \u0026quot;proyectos\u0026quot;, tal como la pagina del OSF en si1 o cualquiera de la multitud de universidades que alojan y mantienen sus propios repositorios. En estos repositorios, los usuarios crean proyectos en los cuales pueden alojar información y archivos, hacerlos tanto públicos como privados e invitar colaboradores para trabajar dentro de la plataforma. A su conveniencia, se pueden asignar tanto privilegios individuales para los usuarios como identificadores a los contenidos que son agregados al proyecto, y de esta forma mantenerlo y publicitarlo de una forma mas eficaz. El OSF también posee métricas a nivel de proyecto, que informan a los administradores de este de cuantas personas han visto o descargado los contenidos.\nAdemás, ya que es una plataforma que intenta abrir la posibilidad de que hayan practicas mas abiertas y colaborativas en las ciencias, permite la creación y el uso de complementos de terceros, principalmente para integrar con mayor facilidad servicios como Zotero o Dropbox en el manejo de citaciones y almacenamiento, respectivamente. Aunque el OSF tiene restricciones de almacenamiento para los archivos (individualmente no pueden pasar los 5GB), de esta manera se hace practicamente ilimitada.\nAlgo que distingue al OSF de otros programas similares es que, con el proposito de fomentar la transparencia y la reproducibilidad, cada proyecto se puede \u0026quot;registrar\u0026quot;, y de esta forma mantenerse de manera indefinida una versión con estampilla de tiempo del proyecto, que no puede ser editada ni borrada según la voluntad del creador. Además, a esta versión registrada del proyecto se le puede dar un identificador DOI o ARK, y cualquier contenido que sea alojado en sitios de terceros es copiado como parte del proceso de registración.\n¿Quienes utilizan el Open Science Framework? La comunidad de OSF es bastante amplia. Basta con ver los numerosos repositorios de instituciones universitarias que lo utilizan para hospedar archivos4. En sí la plataforma gano notoriedad gracias al Psychology Reproducibility Study, un meta-estudio en el cual colaboró la Universidad de Virginia con el COS para replicar 100 estudios notables de psicología y ver si podían recibir los mismos resultados. Todo el proceso de investigación fue compartido de manera abierta en el OSF5, permitiendo a cualquiera revisar los resultados con comodidad.\nA pesar de que su principal audiencia son los investigadores y las instituciones en las que estos trabajan, tienen una serie de aplicaciones y herramientas gratis diseñadas para la interacción de sus usuarios con personas fuera del area. Estas son herramientas tales como OSF for Meetings6, donde pueden subir posters y presentaciones de conferencias y reuniones y OSF Preprints7, donde pueden compartir preprints con el proposito de recibir opiniones y exposición, y se le otorga a cada uno un identificador unico.\nInclusive mas alla de las necesidades de investigadores profesionales y colaboraciones grandes, el OSF resulta ser una asombrosa herramienta de organización para cualquiera que necesita una plataforma en la cual revisar, alojar, analizar, y compartir archivos entre los colaboradores de un estudio abierto, con capacidades unicas en cuanto al control de versiones, identificadores, y transparencia de los datos de investigación se refiere. Cualquiera interesado en utilizar el OSF es libre de crear una cuenta gratis y utilizarlo, así que, si te interesa, porque no probarlo?\n","link":"https://opensciencelabs.org/blog/que-es-el-open-science-framework/","section":"blog","tags":["osf","framework","proyectos"],"title":"Que es el Open Science Framework?"},{"body":"","link":"https://opensciencelabs.org/categories/ide/","section":"categories","tags":null,"title":"IDE"},{"body":" RStudio es un entorno de desarrollo integrado (IDE) para el lenguaje de programación R, el cual puedes utilizar para realizar scripts de análisis de datos, aplicaciones web interactivas, documentos, reportes, gráficos y mucho más.\nPara acceder o utilizar esta herramienta se tienen las siguientes opciones: RStudio Desktop y RServer. Cada una de ellas tiene una en versión Open Source (código abierto) y otra Pro.\nRStudio Desktop brinda acceso local a RStudio y tiene entre sus funcionalidades herramientas como resaltado de sintaxis, completado de código e indentación inteligente, te permite ejecutar el código R directamente desde el editor de fuentes, gestionar fácilmente múltiples directorios de trabajo usando proyectos, posee ayuda y documentación integradas de R.\nAdemás, cuenta con depurador interactivo para diagnosticar y corregir errores rápidamente.\nRStudio Server brinda acceso a RStudio a través de un navegador web, acerca el cálculo a los datos, permite hacer y tener de forma centralizada cálculos a escala y en la RAM. Cuenta con poderosas herramientas de codificación para mejorar la productividad.\nTambién existe la posibilidad de trabajar con esta herramienta completamente online a través de RStudio Cloud una versión web de RStudio que te permite acceder a todas sus funcionalidades desde un buscador. Sin embargo, en este artículo nos centraremos en RStudio Desktop.\n¿Cómo instalar RStudio Desktop?\nDebes instalar R (https://cloud.r-project.org/) Acceder a la web oficial de RStudio Ir a la sección Download https://rstudio.com/products/rstudio/download/ específicamente hasta \u0026quot;All Installers\u0026quot; cerca de la parte inferior de la página. Haz clic en el enlace de descarga correspondiente al sistema operativo de tu ordenador. Selecciona el archivo descargado e instala de acuerdo a tu sistema operativo. Ahora, Conozcamos la Interfaz de RStudio:\nEl ambiente de RStudio es similar en todas sus versiones. Por defecto está dividido en cuatro cuadrantes o regiones:\nEl cuadrante superior izquierdo contiene una ventana que permite crear y editar scripts y, mostrar datos. También cuenta con una serie de comandos o botones asociados con la ejecución de los scripts. Lo podemos encontrar en algunas referencias como Source Panel. Es importante mencionar que si es la primera vez que abres RStudio este cuadrante no aparece hasta que se genere un nuevo script o se abra uno que ya haya sido generado previamente. El cuadrante inferior izquierdo contiene una consola, que recibe directamente las instrucciones y las interpreta. Luego de esto muestra el resultado. Por ejemplo, ingresamos 9 + 3 entonces la consola interpreta que debe hacer una suma y finalmente devolverá el número 7.\nEn este cuadrante también encontramos el Terminal y la funcionalidad Job que permite mantenerse productivo mientras tu código funciona: trabajos locales y trabajos remotos. Puedes usarlas para ejecutar tus scripts en segundo plano mientras sigues usando el IDE.\nEn el cuadrante superior derecho podemos encontrar el Panel de Environment (ambiente), Historial y las Conexiones. Environment muestra las características de variables, dataframes u objetos que se estén trabajando en algún proyecto o sesión determinada. También hay un botón que permite cargar datos a la memoria de RStudio.\nPor otro lado, en el Historial puedes ver las líneas de comandos que han sido ejecutadas recientemente, buscar mediante la caja de búsqueda o copiar los comandos directamente a la consola, o al script. Además, es posible guardar el historial de comandos para utilizarlos en otra sesión.\nEl cuadrante inferior derecho contiene varias pestañas:\nFiles(Archivos): es un gestor de archivos propio de RStudio, te permite crear, editar y eliminar tus archivos, así como crear carpetas.\nPlots: en esta pestaña se muestran los gráficos que se generen a través del script o líneas de comandos. También te permite exportarlos en distintos formatos.\nPackages: Si damos clic en esta pestaña aparecen dos botones, install y update, seguido por una lista de paquetes que pueden estar o no instalados en tu ordenador y que puedes usar o instalar según sea el caso.\nHelp: Nos da acceso a la ayuda que está compuesta por varias secciones,\nR Resources: Contiene una lista de enlaces que te dirigen a páginas web de las ayudas oficiales de R.\nRStudio: Contiene enlaces asociados a los sitios web oficiales de RStudio.\nManuals: Esta sección contiene los enlaces que te permiten acceder de forma local a una serie de manuales a cerca de R.\nReference: Hay dos enlaces, uno es el índice de los paquetes instalados y otro muestra una serie de palabras clave y la clasificación por tópicos de paquetes; al hacer clic en cualquiera de estos enlaces la información es cargada de forma local.\nMiscellaneous Material: Muestra material diverso sobre R, tal como manuales de usuario preguntas frecuentes, Acerca de R, entre otros.\nViewer: esta pestaña es complemento de la extensión RMarkdown, la cual permite\ntener una vista previa de los archivos .rmd.\nNota: Los cuadrantes se pueden agrandar o reducir. Permitiendo ajustar la pantalla a tus necesidades.\nLa barra de menú tiene opciones asociadas con los archivos, proyectos y carpetas, puedes crearlos, editarlos y/o eliminarlos (File), edición de código en el Source Panel o Consola (Edit), ejecución de código y scripts (Code), visualización y ajustes de las ventanas (View), herramientas asociadas a los gráficos generados (Plots), opciones asociadas con la sesión actual(Session), construcción (Build), depuración(Debug), Perfiles del usuario (Profile), herramientas para instalar paquetes, versiones y otros elementos asociados al terminal y (Tools), al igual que la pestaña help te permite acceder a una serie de materiales informativos de ayuda (Help).\nDescargar e instalar paquetes\nPara descargar e instalar uno o varios paquetes directamente desde RStudio debes dar clic en la pestaña packages específicamente en el botón install y escribir en la pantalla que aparecerá el o los nombres de los paquetes que deseas instalar. En el caso de que sea más de un paquete, los nombres de estos se deben escribir de forma tal que estén separados por un espacio o una coma.\nTambién puedes descargar los paquetes desde R-cran e instalarlos a partir de RStudio.\nBuscar o ubicar Tutoriales y material de apoyo sobre R y RStudio\nLa comunidad de R es bastante amplia, por tanto, tendrás acceso a una serie de contenidos educativos muy completos. En el ambiente de RStudio como se mencionó anteriormente, podemos encontrar la sección de ayuda en la cual hay diversos links o enlaces que te permiten acceder a estos sitios.\nRStudio tiene una página web diseñada especialmente para al aprendizaje y enseñanza de R y RStudio. Tiene cuatro secciones principales: Un blog, aprende, enseña y certificate. Si eres completamente nuevo en R, la subsección Beginners https://education.rstudio.com/learn/beginner/ es ideal para ti.\nEntre las recomendaciones en Beginners se encuentra un grupo de chicas de Sydney desarrollaron un blog y una serie de contenidos que pueden orientarte sobre el lenguaje R y la interfaz RStudio. Aquí el enlace: https://rladiessydney.org/.\nOtro elemento web que puede ser útil es R-Básico. Un repositorio de información en Español sobre R y RStudio y de la cual se ha extraído información para este artículo.\n","link":"https://opensciencelabs.org/blog/primeros-pasos-con-rstudio/","section":"blog","tags":["rstudio"],"title":"Primeros pasos con RStudio"},{"body":"","link":"https://opensciencelabs.org/tags/rstudio/","section":"tags","tags":null,"title":"rstudio"},{"body":"","link":"https://opensciencelabs.org/categories/control-de-versiones/","section":"categories","tags":null,"title":"control de versiones"},{"body":"","link":"https://opensciencelabs.org/tags/dvc/","section":"tags","tags":null,"title":"dvc"},{"body":" Cuando colaboramos en proyectos que involucran un manejo y transformación constante de conjuntos de datos y/o modelos derivados de estos, nos vemos en la necesidad de indagar y poner en práctica técnicas que permitan tener un control de todos los cambios realizados en ellos durante la investigación; para lo cual se necesitan herramientas que lo hagan posible. Allí entra en juego el Control de versiones de datos o Data Version Control (DVC).\nEn este apartado definimos brevemente el control de versiones de datos, mencionamos algunas herramientas o Sistemas de control de versiones que permiten hacerlo y también listamos las ventajas que tiene su uso en equipos de trabajo.\nEn nuestro artículo Investigación colaborativa con Git mencionamos que los Sistemas de control de versiones permiten almacenar los cambios realizados en los archivos en todas sus fases de desarrollo y también la información asociada a ellos (fecha y autoría de los cambios). En la mayoría de ocasiones, se utilizan en entornos de desarrollo de software, pero son realmente útiles cuando necesitamos un control sobre cualquier tarea que estemos ejecutando. Para este caso hablamos de transformar conjuntos de datos y experimentar, por ejemplo, modelos de Machine Learning donde el seguimiento de todos los pasos y dependencias entre el código y los conjuntos de datos es fundamental.\nEn el control de versiones de datos (y en general, de cualquier tipo de archivo), podemos ver las versiones como \u0026quot;fotografías\u0026quot; que registran el estado en ese momento del tiempo. Luego se van tomando más fotografías (guardando nuevas versiones) a medida que se hacen modificaciones, en este caso, a conjuntos de datos o a scripts de actualización o transformación de estos (especificación y prueba de modelos). De tal forma que podamos experimentar modelos, observar qué modelos funcionaban con cuál conjunto de datos, reproducir experimentos anteriores o restaurar la investigación a una versión antigua en cualquier momento.\nA continuación se mencionan algunas herramientas de software libre para el versionado de conjuntos de datos y bases de datos.\nDVC Pachyderm Liquibase Dat Git lfs Git-annex En este punto hablaremos un poco sobre DVC, una de las herramientas más utilizadas para el versionado de datos en la actualidad.\nDVC Es una herramienta gratuita y de código abierto empleada, mayormente, en proyectos de ciencia de datos y Machine Learning facilitando la colaboración y reproducibilidad. La parte central del DVC es el versionado de datos para archivos grandes, modelos de Machine Learning, conjuntos de datos y flujo de trabajo. Como DVC hace que los proyectos sean reproducibles y compartibles; podemos saber cómo se construyeron y probaron los modelos y cómo han sido transformados los datos originales. DVC está basado en Git; aunque puede funcionar de manera autónoma (pero sin capacidad de versionado). \u0026quot;Es como un Git solo para Datos\u0026quot;.\nEsta herramienta se desarrolló en un 98% bajo el lenguaje de programación Python.\nCaracterísticas principales DVC funciona sobre los repositorios de Git y tiene una interfaz y un flujo de línea de comandos similares a este.\nNo requiere la instalación y el mantenimiento de bases de datos.\nPuede ser ejecutado en los principales sistemas operativos (Linux, Windows y MacOS). Funciona independientemente de los lenguajes de programación o de las bibliotecas de Machine Learning utilizadas en el proyecto.\nEs rápido de instalar, no depende de APIs o servicios externos.\nAquí puedes acceder al Repositorio de GitHub del proyecto DVC\nVentajas de implementar el control de versiones de datos El tener un seguimiento de los cambios en conjuntos de datos y scripts de especificación y prueba de modelos en una investigación, proporciona una serie de beneficios o ventajas como las mencionadas a continuación:\nGuardan toda la historia del proyecto.\nEl trabajo en equipo es más sencillo, debido a la especificación de fechas y autorías de cambios; aumentando la capacidad de colaborar en un proyecto.\nPermite el acceso compartido a los archivos y el desarrollo de ramas para experimentar cambios.\nNo te preocupes si alguien comete un error o sobrescribe algo importante, puedes volver a versiones anteriores en cualquier momento.\nFacilita la reproducibilidad de modelos de aprendizaje automático en ciencia de datos.\nPermite que los desarrolladores de un proyecto, que trabajan en un mismo archivo de datos, combinen de forma eficiente las ideas y cambios.\nEn OpenScienceLabs te invitamos a utilizar el versionado de datos y de modelos de Machine Learning con DVC, para que puedas llevar un seguimiento adecuado de los cambios de los conjuntos de datos y modelos durante todas las fases del proyecto, haciendo más eficiente dicho proceso.\nReferencias Herramientas de control de versiones\nWebsite oficial de la herramienta DVC\n","link":"https://opensciencelabs.org/blog/que-es-el-data-version-control-dvc-y-por-que-es-necesario-que-tu-equipo-sepa-como-utilizarlo/","section":"blog","tags":["dvc","datos","versionado"],"title":"Te contamos qué es el Data Version Control (DVC) y por qué es necesario que tu equipo sepa cómo utilizarlo"},{"body":"","link":"https://opensciencelabs.org/tags/versionado/","section":"tags","tags":null,"title":"versionado"},{"body":"","link":"https://opensciencelabs.org/categories/aprendizaje/","section":"categories","tags":null,"title":"aprendizaje"},{"body":"","link":"https://opensciencelabs.org/tags/carpentries/","section":"tags","tags":null,"title":"carpentries"},{"body":" Cuando estamos por aprender y comprender al máximo sobre algo en específico, es vital que tengamos fuentes de información que nos hagan este proceso más sencillo, y que ante cualquier duda que tengamos la ayuda sea oportuna.\n\u0026quot;The Carpentries es un proyecto que engloba las comunidades de instructores, capacitadores, mantenedores, ayudantes y simpatizantes de Software Carpentry, Data Carpentry, y Library Carpentry que comparten la misión de enseñar habilidades básicas de computación y ciencia de datos a los investigadores.\u0026quot; (https://carpentries.org/about/)\nEste proyecto es ideal para aprender ciencia de datos porque brinda una serie de materiales diseñados para ello. Hay dos modalidades de enseñanza, una que comprende talleres y otra en formato semestral. Los planes de estudio que ofrece The carpentries varía de acuerdo a las tres comunidades que engloba. Esto es porque cada una se centra en un aspecto práctico orientado a la necesidad del investigador. Para conocer un poco mejor acerca de ello veamos las siguientes descripciones,\nData Carpentry, facilita y desarrolla lecciones para talleres orientados a un área de estudio específico, de modo que se enseña a los investigadores las habilidades más relevantes para su dominio; utilizando ejemplos de su tipo de trabajo. Por lo tanto, por esta comunidad podemos encontrar varios tipos de talleres y planes de estudios organizados por dominio. Actualmente, los dominios son: ecología, biología, genómica, Ciencias Sociales y datos geoespaciales. Descripción extraída de: https://datacarpentry.org/lessons/\nSoftware Carpentry tiene como objetivo ayudar a los investigadores a ser más capaces de escribir software para aplicaciones de investigación. Esto significa centrarse en los lenguajes de programación, entornos de scripting y aplicar el control de versiones para gestionar el código. Los talleres de Software Carpentry emplean una pedagogía de tipo práctico para ayudar a los investigadores a crear confianza y capacidad en el UNIX Shell (BASH), Python o R y el software de control de versiones Git. Opcionalmente, posee módulos para pruebas de unidades y SQL. Software Carpentry es una manera de empezar a construir algunas habilidades y destrezas computacionales en una comunidad de investigación. Las habilidades prácticas y los métodos con los que se enseñan resultan ser útiles para otras enseñanzas avanzadas de seguimiento. Para ver esta descripción y otros aspectos fundamentales visita https://software-carpentry.org/lessons/ o https://cookbook.carpentries.org/the-carpentries.html#software-carpentry\nLibrary Carpentry, posee un plan de estudios básico que actualmente consiste en nueve lecciones. Estas han sido enseñadas muchas veces, y han sido refinadas después de la retroalimentación del instructor y del estudiante. Las lecciones introducen términos, frases y conceptos en el desarrollo de software y la ciencia de datos, cómo trabajar mejor con las estructuras de datos y cómo utilizar expresiones regulares para encontrar y comparar datos. Presenta la interfaz de línea de comandos de estilo Unix, y enseña la navegación básica en el shell, así como el uso de bucles y tuberías para vincular los comandos del shell. También introduce el grep para buscar y unir grupos de datos entre archivos. Los ejercicios cubren el conteo y la extracción de datos. Además, cubre el trabajo con OpenRefine para transformar y limpiar datos, y los beneficios de trabajar en colaboración a través de Git/GitHub y la utilización del control de versiones para realizar un seguimiento de su trabajo. Para encontrar esta descripción y más información, visita: https://librarycarpentry.org/lessons/\nCon estas descripciones se hace notar el empeño de estas comunidades por lograr que los investigadores tengan las herramientas necesarias a la hora de implementar análisis de datos y otros elementos importantes en sus investigaciones. Lo mejor de esto es que van desde lo más básico hasta lo que se considera pertinente para que el conocimiento quedé plasmado en cada estudiante. También, es valioso mencionar que todas las lecciones se distribuyen bajo la licencia CC-BY y son libres para su reutilización o adaptación, con atribución. Esto ha generado que las personas las utilicen en lecciones, en cursos, para construir nuevas lecciones o para el aprendizaje autoguiado.\nAhora, en torno a todo lo anterior, se tiene que\nExiste una o varias comunidades que respaldan este proyecto y las lecciones que han desarrollado.\nEl contenido de sus lecciones están disponibles en la web bajo un formato que da la facilidad para reutilizar su contenido.\nEl acceso a los materiales desarrollados por el proyecto puede hacerse mediante sus websites. En Library Carpentry los encontramos en la sección OUR LESSONS, en el caso de Data Carpentry, en LESSONS; para Software Carpentry también existe una sección LESSONS. De manera general y resumida podemos conseguir los planes de estudio de Carpentries en la sección LEARN/OUR CURRICULA.\nLas lecciones están bien estructuradas. En el caso de Data Carpentry se encuentran clasificadas según un dominio y, a pesar de esto, los conocimientos impartidos también se pueden aplicar a otras áreas. Mientras que Software Carpentry y Library Carpentry son ideales para aprender elementos de la programación haciendo uso de bibliotecas y otras herramientas vitales en el análisis de datos.\nPuedes tener acceso a contenidos nuevos con el trascurso del tiempo.\nTus dudas, sugerencias y aportes serán atendidas por la comunidad.\nPuedes encontrar lecciones tanto en Inglés como en Español.\nEstas son algunas de las tantas razones por la cual deberías considerar The Carpentries como una referencia para aprender ciencia de datos. Te invitamos a que le des un vistazo a este proyecto y nos dejes tus impresiones.\n","link":"https://opensciencelabs.org/blog/por-que-deberias-considerar-carpentries-como-una-referencia-para-aprender-ciencia-de-datos/","section":"blog","tags":["carpentries","datos","proyectos"],"title":"Por qué deberías considerar a The Carpentries como una referencia para aprender ciencia de datos"},{"body":"","link":"https://opensciencelabs.org/tags/c%C3%B3digo/","section":"tags","tags":null,"title":"código"},{"body":" Si has elegido programar en Python, luego de haberlo instalado quizás te preguntarás; ¿dónde voy a programar? Para esto necesitas un editor de código. Existen muchas opciones de IDE (Entorno de Desarrollo Integrado) que puedes usar, la elección dependerá de la herramienta que te haga sentir comodidad, se adapte a tus necesidades de trabajo y, muy importante, sea sencilla de manejar.\nEn este post presentamos lo que necesitas saber para utilizar Spyder como entorno de desarrollo para escribir, ejecutar, evaluar e inspeccionar el resultado de tu código escrito en Python.\nBásicamente, Spyder (acrónimo de Scientific Python Development Environment) anteriormente conocido como Pydee, es un entorno de desarrollo integrado escrito en Python y, desarrollado para científicos, ingenieros y analistas de datos que empleen este lenguaje de programación. Esta herramienta está liberada bajo la licencia del MIT y se financia gracias al generoso apoyo de NUMFOCUS y QUANSIGHT.\nCaracterísticas y funcionalidades de Spyder Es multiplataforma y de código abierto.\nEs multilenguaje.\nCuenta con edición avanzada.\nTiene depuración integrada y ejecución interactiva.\nOfrece capacidades de visualización.\nProvee de funcionalidades para análisis de código como coloreado de sintaxis.\nEs multiconsola.\nIncluye instrumentos para el control de calidad y el análisis de códigos específicos de Python, como Pyflakes, Pylint y Rope.\nContiene varios paneles que facilitan el trabajo: editor de código, explorador-editor de variables y la consola.\nPermite extender sus funcionalidades a través de plugins. Entre ellos:\nSpyder Notebook plugin. Para usar los cuadernos Jupyter dentro de Spyder.\nSpyder Terminal. Muestra una terminal virtual dentro de la ventana principal de Spyder.\nSpyder reports. Permite generar informes de Markdown utilizando Pweave como backend.\nSpyder-autopep8. Complemento para ejecutar autopep8 (el linter de python) dentro de Spyder.\nEstá en continua evolución y soporte gracias a una gran comunidad de desarrolladores y usuarios.\nPermite trabajar en varios proyectos simultáneamente.\nCon Spyder puedes tomar atajos de teclado.\nPosee documentación en línea y tutoriales para que aprendas a utilizarlo.\nInstalación y primeros pasos Para trabajar con Spyder tienes algunas opciones, entre las más comunes están:\nSpyder online, permite que trabajes con una copia de Spyder que se ejecuta directamente en tu navegador web, es decir, no es necesaria su instalación. Esto es posible gracias a Binder. Si deseas probarlo debes acceder a la página de Spyder en Binder.\nEmpleando Anaconda o Miniconda. Spyder viene incluido, por defecto, en estas distribuciones. Esta es la forma más fácil de instalarlo y lo recomendamos para evitar cualquier inconveniente.\nPuedes instalarlo también usando pip o conda en tu entorno local con los siguientes comandos conda install -c anaconda spyder o pip install spyder. La documentación oficial del proyecto te ofrece una guía de instalación que te será de gran ayuda si surgen dudas.\nYa tengo Spyder, ahora cómo lo uso Para correr Spyder en Windows, dirígete al menú Inicio y luego busca la aplicación de Spyder. En Linux, si instalaste Spyder usando Anaconda o Miniconda, puedes acceder buscando su nombre en tu ícono de Menú. Si deseas hacerlo utilizando la línea de comandos, en Windows abre Anaconda Prompt y haz clic en Spyder. En las demás plataformas accede a una ventana del terminal y teclea conda activate nombre_entorno (en su defecto, nombre_entorno es base para activar tu entorno de trabajo local; o coloca el nombre del entorno donde instalaste spyder) y luego escribe spyder.\nVeamos ahora lo que te ofrece esta interfaz:\nViene con un Editor para escribir código, una Consola (IPython Console) para evaluarlo, ver sus resultados en cualquier momento y consultar el historial de comandos, un Explorador de Variables para ver qué variables se han definido durante la evaluación, que cuenta con botones de ayuda para cualquier comando y explorador de archivos.\nComo puedes observar, del lado izquierdo tenemos el Editor de código. En la parte superior derecha se encuentran las pestañas: Explorador de variables, Explorador de archivos, Ayuda. En la parte inferior derecha tenemos: El intérprete interactivo de Python (IPython Console) y El historial de comandos.\nLa barra de Menú se encuentra en la parte superior y debajo de ella la barra de herramientas. Esta última contiene botones que permiten realizar distintas acciones como crear un archivo, ejecutarlo, entre otros.\nBásicamente, escribimos nuestros programas en el Editor y lo ejecutamos pulsando F5 (asimismo para ejecutar cualquier archivo en spyder), el resultado aparece en el Intérprete Interactivo (consola). Si se definen variables y objetos, estos aparecen en el Explorador de Variables. En caso de requerir un archivo adicional, accede al Explorador de archivos. Los archivos generados en Spyder se guardan, por defecto, con extensión .py.\nAl iniciar Spyder, puedes comenzar a trabajar en la ventana de la consola, si lo deseas. Estás en la potestad de cambiar los paneles de lugar y su diseño según tus preferencias.\nA continuación te mostramos de una manera sencilla cómo hacer para crear, abrir y guardar un archivo en spyder y como ejecutar un script:\nPara Crear un nuevo archivo, elige una de las siguientes opciones:\nAccede a la barra de Menú, haz clic en Archivo y luego en Nuevo. Presiona las teclas Ctrl + N. Haz clic en el botón Nuevo Archivo de la barra de herramientas. Si deseas Guardar un archivo, elige entre:\nHacer clic en Archivo y luego en Guardar en la barra de Menú. Presionar las teclas Ctrl + S. Dar clic en el botón Guardar Archivo de la barra de herramientas. Para Abrir un archivo .py existente tienes varias alternativas:\nDirígete a la barra de Menú, haz clic en Archivo, luego en Abrir, después busca el archivo que desees. Presiona Ctrl + O. En la barra de herramientas, haz clic en el botón Abrir archivo. Luego se abre una ventana donde buscarás la ubicación, luego selecciona el archivo deseado y haz clic en Abrir. Posteriormente, se mostrará el archivo en el Editor de Código. Te hemos presentado lo que debes saber para iniciarte en Spyder, esperamos que sea de provecho para tus proyectos. Anímate a usar este potente y popular Entorno de Desarrollo.\nReferencias Sitio web Spyder\nSpyder Wikipedia\n","link":"https://opensciencelabs.org/blog/primeros-pasos-con-spyder/","section":"blog","tags":["spyder","código"],"title":"Primeros pasos con Spyder"},{"body":"","link":"https://opensciencelabs.org/tags/spyder/","section":"tags","tags":null,"title":"spyder"},{"body":"Una de las areas de investigación mas prometedoras de la ultima decada es sín duda la inteligencia artificial. No solamente reune una increible cantidad de regiones del conocimiento que, superficialmente, son demasiado dispares (tales como la filosofía de la mente, la psicología, la biología, la robotíca, la lógica pura, entre muchas otras), sino que también los resultados de sus publicaciones se vuelven relevantes de forma retroactiva para las areas de la ciencia de cuya historia se nutre. El estudio y la utilización de las redes neuronales y el aprendizaje automático (o machine learning) ha demostrado ser increiblemente utíl no solamente a la hora de realizar investigaciones regulares con estas tecnícas, sino también para crear nuevas herramientas de simulación y experimentación, tanto para uso científico como el particular o comercial.\nAunque el machine learning aun tiene sus problemas y misterios por resolver, ya como area de investigación ha producido muchos hallazgos y descubrimientos de increible importancia para la ingeneria de sistemas y demás areas relacionadas con la informatica. Ya para aquellos que trabajan día a día haciendo experimentos con librerias tales como TensorFlow se vuelve una cuestión de suma importancia el andar pendiente de que nuevos artículos se publican o que nuevas aplicaciones se descubren para el machine learning, por no decir de que nuevas e increibles mejoras se podrían realizar a proyectos anteriores, tales como los llamados 'deep fake'.\nMuchas de las herramientas desarrolladas con inteligencia artificial poseen codigo fuente y bases de datos libremente disponibles para el publico. Ya sea para fines comerciales o simplemente como demostración, estan aquellas que a su vez poseen una aplicación web mediante la cual puedes interactuar con los scripts de una forma directa, realizando manipulación y generación de audio, imagenes o demás de una forma directa y sencilla, pero no por eso menos eficaz. De esta manera los usuarios pueden ver el funcionamiento del programa sin necesidad de compilarlo o de que el autór cree demostraciones, además que ayuda a difundir el proyecto si se permite la creación de contenidos independientes.\nTacotron2: Generación de audios donde se leen textos con las voces de personas reales Tacotron2 se trata de una implementación por TensorFlow de una arquitectura de redes neuronales profunda que busca sintetizar habla a partir de texto. Enlazada a un modelo generativo de formas de ondas llamado WaveNet, el cual fue utilizado anteriormente para el mismo proposito, Tacotron2 entrena la red neuronal utilizando una base de datos de voces anteriormente grabadas para crear espectrogramas en la escala Mel, lo cual a su vez permite su utilización para emular las voces de personas vivas o inclusive ya muertas, dado que tengan la suficiente cantidad de grabaciones disponibles. Los resultados son impresionantes, y se pueden ver, por ejemplo, en el canal de YouTube llamado Vocal Synthesis, donde se leen copypastas y demas textos con las voces de Ronald Reagan, The Notorious B.I.G., Ayn Rand, o inclusive la Reina Elizabeth, o en el sitio fifteen.ai, donde se pueden generar audios con las voces de personajes de series animadas.\nAnimación de imagénes a partir de un video En el paper First Order Motion Model for Image Animation creado por Siarohin et al. en el 2019, se demostró un framework que permite la creación de animaciónes a partir de una imagén base \u0026quot;fuente\u0026quot; y un video que \u0026quot;conduce\u0026quot; la animación, mediante el entrenamiento de una red neuronal con videos de una misma 'categoria'. Lo que esto permite es realizar cosas tales como cambiar las caras de las personas presentes en una grabación por las de otras, alterar el estilo de una animación, cambiar la ropa que tiene puesta una persona en un video, entre otras. Como te podrás imaginar, esto permite la creación tanto de deepfakes o videos promocionales 'falsos' como de otras alteraciones (dar vida a la Mona Lisa, por ejemplo), y es increiblemente convincente con la edición adecuada, como se puede observar en el video suplementario que muestran First Order Motion Model for Image Animation.\nMuseNet: Una red neuronal que 'continua' tu música MuseNet es un proyecto muy simple: se trata simplemente de una red neuronal profunda que fue creada con el proposito de crear música. Sus creadores afirman que es capaz de crear piezas de 4 minutos con 10 instrumentos distintos, \u0026quot;y que puede combinar estilos desde el country hasta inclusive Mozart o los Beetles\u0026quot;. Ya que ha sido entrenada a encontrar \u0026quot;patrones de armonia, ritmo y estilo aprendiendo a predecir el siguiente token en cientos de miles de archivos MIDI\u0026quot;, se le puede pedir que, por ejemplo, utilize las primeras 6 notas de un Nocturne de Chopin para generar una pieza con una instrumentación pop rock, el cual es un ejemplo que se ve en la pagina. Además, OpenAI permite que cualquiera pruebe la generación de audio mediante esta red desde la pagina del proyecto para que cualquiera cree nuevas composiciones.\nUna inteligencia artificial que 'mira' a traves de las paredes mediante señales WiFi En este paper RF-Pose publicado por Zhao et al. se presenta una aplicación llamada RF-Pose que analiza las señales radio en las frecuencias WiFi, aprovechandose que estas señales inalambricas traspasan las paredes y se reflejan del cuerpo humano, para estimar poses 2D. Para estimar la pose, unicamente es necesaria la señal inalambrica, siendo aspectos relevantes del individuo tales como altura o anchura predichos a partir de esta. Por lo tanto, aunque sea igualmente eficaz para predecir poses 2D como lo es la visión humana, la diferencia radica en que es capaz de predecir estas inclusive si su 'vision' esta siendo interferida por un obstaculo, tal como una pared. Los resultados en AI Senses People Through Walls llegan a ser asombrosos, y a la vez, algo perturbadores.\nDetección de cancer de seno mediante un sistema de inteligencia artificial La mamografía es la principal herramienta que tienen los medicos a mano para identificar y prevenir el cancer de seno antes de que síntomas mas serios ocurran. Sin embargo, exige que hayan expertos que identífiquen y interpreten dentro de las imagenes generadas por este proceso ciertas anormalidades, lo cual esta sujeto al error humano y, por lo tanto, sufre de tasas subóptimas de falsos positivos y negativos. Por lo tanto, en este paper International evaluation of an AI system for breast cancer screening publicado por Etemadi et al. en el 2020 se buscó crear un sistema que utilizara la inteligencia artificial para ayudar a los medicos a identíficarlo, y sorprendentemente, se encontro que el sistema no solamente funcionaba, sino que reducia los errores de manera significativa, aunque obviamente no era immune a ellos. También, los autores creen que con este tipo de sistemas se podrían realizar de una forma mucho mas eficaz esta detección en los paises que no posean los recursos necesarios para realizarla en números mayores.\nReferencias TensorFlow Tacotron2 Vocal Synthesis fifteen.ai First Order Motion Model for Image Animation First Order Motion Model for Image Animation MuseNet RF-Pose AI Senses People Through Walls International evaluation of an AI system for breast cancer screening ","link":"https://opensciencelabs.org/blog/ciencia-abierta/","section":"blog","tags":["datos"],"title":"5 proyectos de inteligencia artificial que te sorprenderán"},{"body":"","link":"https://opensciencelabs.org/categories/inteligencia-artificial/","section":"categories","tags":null,"title":"inteligencia artificial"},{"body":" El manejo de los equipos de trabajo es interés constante para Open Science Labs, porque tenemos la convicción de que un equipo de trabajo bien manejado puede crecer en conjunto y construir mejores resultados para la ciencia abierta.\nYa en artículos anteriores hemos hablado de las herramientas que pueden utilizarse en el manejo de investigación reproducible en equipos de trabajo, o cuáles son los aspectos clave a tener en cuenta en el manejo de equipos de ciencia abierta, y en este artículo queremos profundizar un poco más y mostrarte nuestra perspectiva del propósito de examinar no solo las herramientas utilizadas, sino también las prácticas de trabajo en equipo.\nLos equipos de trabajo y su organización Recientemente ha sido muy difundido este artículo) en el cual Mike Crittenden muestra su perspectiva sobre las herramientas que se utilizan en las comunicaciones internas y de cómo unas prácticas comunicativas inadecuadas pueden conducir a retrabajo y estrés en los equipos.\nLa premisa del autor en su artículo es que, en muchas ocasiones, la comunicación en los equipos de trabajo genera un problema adicional cuando algunos temas, que deberían trabajarse en mayor profundidad y con mayor dedicación, se acumulan al verterse en herramientas pensadas para conversaciones breves y puntuales.\nEste problema adicional que mencionamos tiene varias aristas. En primer lugar, muchas de las herramientas de colaboración pensadas para equipos de desarrollo tienen, además de las conexiones con repositorios, espacios de chats (canales) para que los equipos puedan tener un espacio de conversación. Sin embargo, estos chats que están generalmente pensados para conversaciones de alcance temporal corto, no cuentan con dispositivos que faciliten su seguimiento y, pese a ello, terminan utilizándose para conversaciones que pueden nutrirse de ser llevadas, por ejemplo, a través de una discusión en el manejador de issues de los proyectos en una plataforma como Github.\nVaciar conversaciones con detalles técnicos, diálogos en grupos de chat, en ocasiones conversaciones paralelas, interrumpidas por cualquier integrante del grupo con algún sticker o pregunta no relacionada, sin lugar a dudas hacen mucho más complicado llevar el seguimiento a detalles que, por ser determinantes para el desempeño del equipo o de alguna tarea, seguro se benefician de un trabajo más individualizado en un espacio que posibilite su seguimiento y sistematización posteriores.\nNo vamos a construir una crítica a ultranza del uso de chats en las comunicaciones grupales, de hecho, tienen un papel muy importante en el tratamiento de decisiones muy puntuales, recordatorios o incluso, con propósitos de distensión y relajación, especialmente si se trabaja de forma remota. Sin embargo, sostenemos la idea de que los grupos de trabajo necesitan que la gestión de sus procesos internos se adecúe a las actividades que realizan, a fin de facilitarlas sin hacerlas excesivamente complejas, y sabemos que hay plataformas que pueden hacerlo posible.\nPrácticas sanas en los equipos de trabajo Todo equipo de trabajo gira en torno, al menos, de un proyecto. Los proyectos se organizan en torno a hitos y estos en función de tareas y actividades cuya concresión debe organizarse y gestionarse. En medio de todo esto, ocurre el flujo de presupuestos y asignación de recursos financieros y también de tiempo.\nLos equipos de trabajo en desarrollo de software no son la excepción en este sentido. Aunque, en muchas ocasiones, se trate de equipos pequeños con varios proyectos, resulta vital identificar los componentes y las personas que lideran cada uno de sus procesos. Por ello, organizar las tareas, definir los flujos de información para la gestión de actividades y hacer seguimiento de los alcances, logros y problemas del equipo, a menudo requiere, no solo del uso de una herramienta que lo facilite, sino también que el equipo asimile y haga propias las prácticas necesarias para ello, convirtiéndolas en hábitos colectivos.\nSi nos centramos de forma estricta en la organización del trabajo, sabemos cómo los equipos de ciencia abierta deben cultivar algunas prácticas, y ahora sabemos que esto puede lograrse con el fomento en el uso de dispositivos que las faciliten:\nControl de versiones integrado a los dispositivos de comunicación,\nManejo de issues y sub-grupos en los repositorios,\nMetodología ágil para identificar hitos, metas, tareas y seguimiento,\nEntrenamiento en políticas de ciencia abierta para todo el equipo de trabajo, e\nIncentivo a la ciencia abierta apoyando el desarrollo de habilidades no solo para el desarrollo, sino también para la sistematización y la socialización de los avances.\nAfortunadamente existen varias herramientas que pueden ayudar a integrar, en un esquema todo en uno estas distintas prácticas. Sin embargo, sabemos que también es bastante probable que tu equipo de trabajo termine trasladando prácticas cotidianas que pueden no ayudar mucho en el aprovechamiento de estas herramientas.\nPara apoyarte en la decisión de cuál herramienta utilizar, hemos preparado para ti y para tu equipo, esta revisión de opciones para trabajo en equipos de desarrollo y otras formas de colaboración que, de seguro, podrán ayudarte a compaginar de una forma más adecuada el trabajo a distancia con el logro de los objetivos en tus proyectos.\nLas herramientas elegidas Hemos seleccionado 10 de las herramientas más utilizadas en el trabajo en equipo, algunas de uso general y otras de uso específico. La mejor recomendación en este punto es que conozcas las prácticas que tu equipo realiza y el propósito que tendría la incorporación de una herramienta, para tomar la decisión sobre cuál herramienta utilizar.\n1. Asana Asana es una plataforma en línea que permite la gestión de proyectos y grupos de trabajo. Es gratuita para personas o equipos que están comenzando, aunque tiene limitaciones en cuanto al manejo de tareas (solo hasta 1.000 tareas por equipo), número de integrantes de cada equipo (hasta 15) y ofrece más de 100 integraciones que están disponibles de forma gratuita. Asana, cuenta con un espacio de gestión de proyectos, actualización de estatus de proyectos, priorización de tareas, mensajes, conversaciones integradas sobre cada tarea programada, tablero tipo Kanban y calendario.\nCuenta también con plantillas que pueden adaptarse a los requerimientos que tenga cada tipo de proyecto. Estas plantillas son bastante prácticas si lo que deseas es comenzar a organizar y planificar las tareas del equipo pero no tienes muy claro cuáles herramientas utilizar. Puede que algunos de los componentes del proyecto sean de pago pero, en líneas generales, los que están disponibles en la versión gratuita cumplen con los propósitos mínimos requeridos de planificación. Ofrece integraciones con varias aplicaciones como Dropbox, Jira, MSTeams, Box y Zoom entre otros.\n2. Discourse for teams Discourse for teams es una versión de Discourse orientada a equipos de trabajo, pensada para mejorar su productividad. Ofrece organización de las conversaciones, un calendario que actualiza a hora local las citas y actividades en agenda, un buscador que permite localizar información a través de distintos tipos de documentos: desde conversaciones hasta documentación en wikis. Asimismo, brinda personalización de los temas del escritorio y la interfaz, además de algunos aspectos de seguridad como encriptación de conversaciones y dos factores de autenticación en las cuentas.\nEl enfoque de Discourse es la conversación que puede seguirse a través de notificaciones por correo e incluye integraciones interesantes para equipos de desarrollo como Slack, Github y Zendesk.\n3. Slack Sin lugar a dudas esta es la aplicación que domina el mercado de aplicaciones de comunicación para equipos, esto pese al grupo nada despreciable de personas y equipos que se resisten a utilizar Slack. Es un software que posibilita que los equipos de trabajo organicen sus intercambios de información en canales públicos o privados, facilita la búsqueda de información, intercambio de archivos y conexión con aplicaciones como Google Drive, Trello, Confluence, Jira, Asana y Zendesk.\nOtra funcionalidad que tiene Slack, es que permite conectar el trabajo entre equipos/empresas diferentes, así como integrar videollamadas y mensajería, y ofrece la función de generación de flujos de trabajo.\n4. Twist Twist es una plataforma que, al igual que otras reseñadas en este artículo, incluye espacio para gestionar el trabajo colaborativo remoto y también generar conversaciones entre los integrantes de los equipos. Twist promete estar centrada en la conversación que ocurre entre los equipos de trabajo, permitiendo que esté disponible y transparente para todos los integrantes del equipo, organizada por temas de trabajo, estructurándola para que sea sencillo retomar o entender una conversación luego de un tiempo sin participar en ella. De esta forma, la conversación de los equipos de trabajo ocurre de forma asíncrona pero no deja de ser un apoyo a los procesos internos. Quienes conocen Slack verán en Twist, a primera vista, una interfaz muy similar que muestra las conversaciones agrupadas en canales y por mensajes individuales. Twist incorpora, sin embargo, la opción de visualizar y localizar las conversaciones también por temas.\nAl igual que Slack, Twist facilita la configuración personalizada de las notificaciones, menciones e información suministrada a los integrantes del equipo y facilita la conexión con aplicaciones muy utilizadas por equipos de desarrollo como Github. Una comparativa que presenta Twist con su competencia directa, Slack, enfatiza en la posibilidad de organizar el proceso de comunicación entre los integrantes del equipo evitando que se sientan abrumados por el constante flujo de mensajes, notificaciones e información de Slack.\n5. Carrot Carrot es otra de las varias aplicaciones ideadas para favorecer el proceso de comunicación en equipos de trabajo, remotos o no. El aspecto diferenciador de Carrot es manejar las comunicaciones como feeds personalizados y tratando cada mensaje como una noticia. Es un proyecto Open source que es gratuito para organizaciones sin fines de lucro.\nUn aspecto interesante de Carrot es que muestra estadísticas de los mensajes dentro de una conversación, además de permitir compartir mensajes con canales específicos de Slack a través de su integración. Permite incorporar bloques de código y encabezados con formato H2, además de encuestas y recordatorios generales para los equipos de trabajo y configuración de tema en modo oscuro. Es una aplicación relativamente joven que cuenta con mejoras continuas.\n6. Threads A diferencia de las aplicaciones que hemos reseñado hasta aquí, Threads solo está disponible como aplicación descargable en computadoras de escritorio (ambiente Windows o Mac) y en móbiles (Apple y Android). Se centran en un caso de uso exitoso por parte de la empresa Buffer, que optó por utilizar esta herramienta para mejorar la comunicación entre su equipo de trabajo. Los números que exponen en ese caso de uso son realmente interesantes, registrando hasta un 80% de mejora en la productividad de los empleados de un equipo que, como el de Buffer, está totalmente distribuido a lo largo y ancho del mundo.\nEsta aplicación está centrada, al igual que las otras reseñadas, en dar estructura, orden y sistematización a la conversación de los equipos. La forma en que Buffer expone que la ha utilizado, echa mano de tarjetas de conversación, hilos y espacios en los cuales se puede dar lugar a chats para distensión del equipo de trabajo, pero también acceso a los distintos temas manejados a través de chats organizados a modo de tarjetas y un buscador que promete hacer mucho más sencilla la localización de conversaciones específicas.\n7. Basecamp Basecamp es otra de las aplicaciones disponibles para el manejo de las actividades grupales, que incluye mensajes, manejo de tableros de tareas pendientes, calendarios, vinculación de documentos y archivos, chats grupales y un banco de preguntas comunes. Ofrece la posibilidad de programar las notificaciones para garantizar tiempos de descanso en lugar de la exigente conectividad que imponen aplicaciones como Slack.\nEste producto incluye una opción gratuita para uso personal, con la posibilidad de manejar hasta 3 proyectos, 20 usuarios y 1GB de almacenamiento en la nube.\n8. Flarum A diferencia de las aplicaciones presentadas antes, Flarum está centrada en servir de plataforma para conducir los foros en páginas y portales web, y por ello ofrece una especie de interfaz renovada de la interfaz de foros web. Es un software de licencia abierta que garantiza su expansividad y flexibilidad a las necesidades de los equipos de trabajo.\nDespués de 6 años de desarrollo, Flarum 1.0.0 fue finalmente lanzado en 2021. Permite el manejo de etiquetas lo cual le permite organizar de una forma más pulcra la lista de discusiones visibles, tanto a través de la barra lateral como de las banderas indicadas junto a cada discusión dentro de la lista de las más recientes.\n9. Keybase Keybase es una aplicación gratuita, de código abierto, disponible para pc y móbiles. Enfatiza en sus capacidades para manejo de mensajería y y envío de archivos de forma encriptada. Aunque no está pensada de forma exclusiva para el manejo del trabajo en equipos, resulta un apoyo importante por la vinculación con aplicaciones como Github y Google Drive, por ejemplo.\nPermite el uso de etiquetas, el diseño de canales, el manejo de conversaciones particulares, la localización de mensajes y archivos de forma relativamente flexible. Se conecta también con identidades públicas, lo cual permite el manejo de comunidades amplias. Aunque se centra en el cifrado como valor agregado, y aunque resulta un poco pesada en su funcionamiento para algunos dispositivos, resulta muy potente para el manejo de conversaciones importantes para los equipos de trabajo.\n10. Notion Notion es una aplicación que incluye herramientas para buena parte de las tareas más necesarias en los equipos de trabajo: comunicación (chats), tareas (tasks) y bases de conocimiento (wikis) entre otras. La posibilidad de reordenar esta información en función de, por ejemplo, los proyectos y sus etiquetas, le aporta a Notion una flexibilidad mayor al momento de ser implementada en los equipos de trabajo.\nA quienes conocen Paper Dropbox, el manejo de los documentos de Notion puede resultarles muy similar en cuanto a las menciones, la inclusión de tareas y otros elementos que facilitan, dentro de los documentos, abrir y concretar discusiones dentro de los equipos de trabajo. Es gratuita para uso personal con acceso ilimitado a bloques y páginas, sincronización entre servicios y hasta 5 integrantes de un equipo de trabajo.\n¿Cuál recomendamos? Creemos que hemos abordado de forma precisa las opciones más destacables de cada una de las aplicaciones seleccionadas. Aunque, el manejo de conversaciones separadas, buscadores, calendarios y de tableros kanban puede agilizar la gestión de las actividades a realizar por los equipos de trabajo, sin embargo, el mensaje es hacia no perder de vista que la primera atención que debemos prestar es a los procesos de los grupos de trabajo.\n","link":"https://opensciencelabs.org/blog/plataformas-que-te-ayudaran-en-la-gestion-de-tu-grupo-de-trabajo/","section":"blog","tags":["comunicación","gestión"],"title":"10 Plataformas que te ayudarán en la gestión de tu grupo de trabajo."},{"body":"","link":"https://opensciencelabs.org/tags/comunicaci%C3%B3n/","section":"tags","tags":null,"title":"comunicación"},{"body":"","link":"https://opensciencelabs.org/tags/gesti%C3%B3n/","section":"tags","tags":null,"title":"gestión"},{"body":"","link":"https://opensciencelabs.org/categories/gesti%C3%B3n-de-equipos/","section":"categories","tags":null,"title":"gestión de equipos"},{"body":"","link":"https://opensciencelabs.org/categories/organizaci%C3%B3n/","section":"categories","tags":null,"title":"organización"},{"body":"","link":"https://opensciencelabs.org/tags/figshare/","section":"tags","tags":null,"title":"figshare"},{"body":"","link":"https://opensciencelabs.org/tags/plataforma/","section":"tags","tags":null,"title":"plataforma"},{"body":" ¿Qué es figshare?\nEs un repositorio de acceso abierto en línea en el cual los usuarios pueden poner a disposición todos los resultados de sus investigaciones. Esto de manera que sean citables, compartibles y descubribles. Los resultados pueden incluir cifras, los conjuntos de datos, imágenes y vídeos.\nfigshare fue ideado y desarrollado por Mark Hahnel, se lanzó originalmente en el año 2011. \u0026quot;Hahnel diseñó e implementó esta plataforma como una alternativa propia para organizar, publicar y compartir, los recursos, los productos y los resultados que a partir de su investigación doctoral en biología de células madre, generaba y obtenía de forma complementaría\u0026quot; [https://www.youtube.com/watch?v=yy5vsviuyF4]\nEn el año 2012, fisgshare es relanzado como resultado del respaldo y la asociación que Hahnel logró con la empresa inglesa Digital Science. Desde este momento hasta el día de hoy se ha mantenido en constante actualización, logrando una herramienta bastante amigable y bondadosa en cuanto a sus funcionalidades.\nLas posibilidades que brinda figshare van desde el almacenamiento de tus proyectos hasta la promoción de ellos. Veamos esto detenidamente.\nAlmacenamiento de proyectos: Puedes subir archivos de hasta 5 GB, estos serán visualizados en el navegador. Los archivos no tienen límite en cuanto al formato. Además, tienes 20 GB a disposición para que almacenes tu investigación en privado hasta que decidas hacerla pública.\nOrganización de datos: Los datos en esta plataforma están organizados por categorías y etiquetas que son fáciles de buscar, logrando así que los investigadores encuentren los datos que necesitan más rápido.\nCompartir tu trabajo: con esta plataforma tienes la posibilidad de hacer público tu proyecto, compartir tus archivos y controlar el acceso a tus datos privados. Adicional a esto puedes asignarle un DOI y obtener citaciones por los resultados de tu investigación.\nOpciones de acceso: Actualmente Figshare tiene tres opciones de acceso, un acceso para investigadores, un acceso para instituciones y un acceso para editores. El acceso para investigadores se conoce generalmente como free accounts.\nPara las cuentas de instituciones se le asigna un precio que depende del volumen de la investigación que realiza la institución y de esta modalidad se pueden destacar las siguientes características:\nAsignación de un DOI de marca institucional para los archivos de la investigación. Agrupar el contenido en colecciones Editar todo el contenido antes de que se publique Colocar una marca de agua en los archivos correspondientes a la institución Descartar los archivos que han sido publicados por error Permite alojar grandes cantidades de datos en sus artículos en línea sin que ello afecte a su infraestructura. Se contará con estadísticas públicas sobre todas las vistas, descargas, citas y otras alteraciones de los productos de su institución. Para ver estas y otras características puedes visitar [https://figshare.com/features].\nBlog de figshare [https://figshare.com/blog]: se publican investigaciones y artículos relevantes, sus aspectos generales básicos e información importante. Además de todo lo mencionado, figshare desarrolla productos propios enfocados a ampliar el conocimiento y promover la ciencia abierta.\nProyectos y productos propios de figshare: -“The State of Open Data” es uno de estos proyectos, se ha venido implementando desde 2016, su principal objetivo es \u0026quot;aprender para ayudar a conformar el futuro de los datos abiertos sobre la base de la información y las pruebas reunidas en la comunidad\u0026quot;. Además, se tiene en una sección en la cual se consigue información, análisis, datos y encuestas referentes a 16 disciplinas o sectores en los que se ha implementado la ciencia abierta. Para tener una mejor idea de este proyecto puedes visitar el sitio web [https://stateofopendata.od4d.net/].\n-\u0026quot;The Reproducibility Initiative”, es un proyecto en conjunto con Science Exchange, PLOS y Mendeley, cuyo objetivo es identificar y recompensar la investigación reproducible de alta calidad a través de la validación independiente de resultados experimentales claves. Puedes encontrar más información visita [http://validation.scienceexchange.com/#/reproducibility-initiative]\n-El programa figshare ambassadors, tiene como objetivo involucrar a investigadores, estudiantes y bibliotecarios convencidos del acceso abierto y la ciencia abierta, a promover el uso de la plataforma figshare y sus herramientas, con la intención de hacer más eficiente y abierta los procesos de investigación de sus instituciones. [https://knowledge.figshare.com/ambassadors]\nEn resumen, figshare es una plataforma que brinda la posibilidad de que tus proyectos estén en un sitio seguro, sea visualizado por una gran cantidad de personas interesadas, logre ser citado y si necesitas adjuntar archivos de gran tamaño no exista problema; se puede catalogar como una herramienta que facilita y ayuda al crecimiento del conocimiento.\nAl día de hoy, figshare ha recibido más de 26 millones de page views y más de 7.5 millones de descargas, tiene en su plataforma más de 2 millones artículos, más de 5 mil proyectos, más de 500 mil colecciones y más de 800 mil usuarios que cargan o comparten sus archivos a través de ella. [https://figshare.com/about]\nReferencias: (Sitio oficial defigshare) [https://figshare.com/]\nArtículo: (Figshare… una buena idea) [https://www.infotecarios.com/figshare-una-buena-idea/#.X2P7WpXB9p8]\nArtículo: (Sharing Research Data—New figshare For Institutions)[https://www.against-the-grain.com/2013/09/sharing-research-data-new-figshare-for-institutions-2/]\n","link":"https://opensciencelabs.org/blog/todas-las-posibilidades-que-te-ofrece-utilizar-figshare-en-tus-proyectos/","section":"blog","tags":["figshare","proyectos","plataforma"],"title":"Todas las posibilidades que te ofrece utilizar figshare en tus proyectos"},{"body":" Si posees algún conocimiento sobre conda o visitaste anteriormente nuestro artículo sobre Cómo instalar y comenzar a utilizar Conda (enlace a artículo) donde dimos una breve definición sobre este potente gestor de paquetes y entornos; puedes ahora, con el presente post, nutrirte de más información pues mencionamos algunas características y recomendaciones para que conozcas los usos de conda y puedas usarla de manera eficiente y sin complicaciones.\nSi usas Conda\nPuedes crear y configurar entornos virtuales solo con teclear unos pocos comandos. Te recomendamos crear un entorno virtual para cada proyecto que ejecutes o cada actividad donde los requerimientos sean distintos. Específicamente el comando que permite crear el entorno es conda create --name nombre_entorno python x.x, donde x.x es la versión de python que deseas correr en ese entorno.\nEste gestor analiza tu entorno actual, en lo referente a los paquetes instalados y a las limitaciones de versión de los paquetes que especifiques y analiza la forma de instalar dependencias compatibles. Si esto no es posible, te informa que no puede ejecutar tu petición. Esta es una ventaja muy importante en comparación con otros gestores de paquetes como pip, el cual instala el paquete que especifiques y sus dependencias, sin antes verificar cualquier inconveniente que pueda llegar hasta dañar otros paquetes.\nPuedes abreviar muchas opciones de los comandos que usas con frecuencia las cuales están precedidas por dos guiones (--) a sólo un guión y la primera letra. Por ejemplo, --name y -n, --envs y -e son lo mismo, es decir, si escribes uno u otro se ejecuta la misma acción.\nPara consultar los entornos virtuales que haz creado, ejecuta el comando conda info --envs. Si tienes varios creados, el que aparezca con un asterisco (*) al lado del nombre es el que tienes activado actualmente.\nPara trabajar en cualquiera de los entornos virtuales que tengas disponibles debes primero activarlo. Esto se realiza con el comando conda activate nombre_entorno y cuando necesites salir del entorno ejecuta conda deactivate.\nSi deseas remover un paquete específico del entorno de trabajo actual, ejecuta el comando conda remove nombre_paquete y si deseas eliminar un paquete de otro entorno entonces ejecuta conda remove -n nombre_entorno nombre_paquete.\nPara ver una lista de los paquetes que tienes instalados en el entorno actual ejecuta conda list y para consultar los paquetes instalados en otros entornos teclea conda list -n nombre_entorno. También puedes acceder a la ayuda de los comandos de conda tecleando --help o -h al final del comando. Por ejemplo, para mostrar la ayuda de cómo instalar un paquete ejecuta conda install -h.\nLa documentación oficial de conda proporciona gran variedad de comandos de conda para que puedas manejar paquetes y entornos virtuales, accede a esta información en este enlace. En los enlaces de la página señalada encontrarás ayuda para cada uno de los comandos.\nRecomendamos que accedas a Bioconda, un canal popular de conda que ofrece una gran variedad de distribuciones de software para biología computacional.\nSi te surgen dudas sobre el significado de algunas palabras referentes a lo que es y lo que hace conda, puedes acceder a este Glosario para aclararlas.\nA continuación encontrarás enlaces con información y comandos que te serán de gran ayuda para el manejo de paquetes y entornos virtuales con conda.\nCheat sheets de terceros\nCheat sheets de Continuum Analytics, compañía creadora de conda\nEn OpenScienceLabs te invitamos a indagar y a que comiences a usar conda. Con la ayuda de este post y los recursos que hemos señalado, estamos seguros que sacarás el mayor provecho de conda en tus proyectos.\nReferencias Documentación Conda ","link":"https://opensciencelabs.org/blog/caracteristicas-y-tips-utiles-que-te-ayudaran-sacar-el-maximo-provecho-de-conda/","section":"blog","tags":["conda","empaquetado","paquetes","entorno virtual"],"title":"Características y tips útiles que te ayudarán a sacar el máximo provecho de CONDA"},{"body":"","link":"https://opensciencelabs.org/tags/conda/","section":"tags","tags":null,"title":"conda"},{"body":"","link":"https://opensciencelabs.org/categories/devops/","section":"categories","tags":null,"title":"DevOps"},{"body":"","link":"https://opensciencelabs.org/tags/empaquetado/","section":"tags","tags":null,"title":"empaquetado"},{"body":"","link":"https://opensciencelabs.org/tags/entorno-virtual/","section":"tags","tags":null,"title":"entorno virtual"},{"body":" Conda es un sistema de gestión de entornos y de paquetes que funciona en Windows, Linux y MacOs. Inicialmente se creó para programas Python y está escrito en python, pero puede implementarse para cualquier lenguaje.\nEs de código abierto y está publicado bajo la licencia BSD por Continuum Analytics. Trabaja con \u0026quot;canales\u0026quot;(channels); las ubicaciones de los repositorios en los que busca paquetes. Te permite instalar, ejecutar y actualizar paquetes y sus dependencias de manera rápida. Se utiliza mediante línea de comandos en el Anaconda Prompt o en una ventana de terminal. En lo referente a la gestión de entornos, con conda puedes crear, guardar, cargar y cambiarte de entorno fácilmente en tu ordenador local.\nUn entorno de conda es un directorio con una colección específica de paquetes de conda que has instalado. Puedes activar o desactivar fácilmente los entornos y los demás que tengas no se verán afectados. Con conda también puedes crear entornos virtuales; una herramienta que crea espacios aislados con las dependencias que requieren los diferentes proyectos que tengas.\nConda también es un paquete y está incluido en todas las versiones de Anaconda; una distribución libre y abierta​ de Python y R, Miniconda, una pequeña versión de Anaconda que incluye pocos paquetes en comparación con esta, Anaconda Repository y Anaconda Enterprise. Está disponible también en conda-forge; un canal comunitario.\nInstalando Conda Como mencionamos en líneas anteriores, conda está incluido en todas las versiones de Anaconda y Miniconda. Por tal motivo, para obtenerla debes instalar alguna de ellas o comprar Anaconda Enterprise. Necesitas una computadora con sistema de 32 o 64 bits. Para Miniconda 400MB de espacio en disco y 3GB para descargar e instalar Anaconda.\nElige Anaconda si estás comenzando en conda o python, quieres tener instalados automáticamente más de 7500 paquetes científicos y si cuentas con el espacio suficiente en disco.\nElige Miniconda si estás dispuesto a instalar individualmente el paquete que necesites, cuentas con poco espacio en disco y por eso no puedes instalar Anaconda y/o si deseas un acceso rápido a conda y python.\nA continuación detallamos los pasos a seguir para una instalación regular de acuerdo al sistema operativo.\nDescarga Anaconda o Miniconda según el sistema operativo Puedes descargar Anaconda en este enlace\nPara descargar Miniconda ingresa en este enlace\nPuedes escoger, según el sistema operativo, una versión con un instalador gráfico o instalador por línea de comandos. Si no deseas ingresar comandos en una ventana de terminal, elige el instalador gráfico (Interfaz gráfica de usuario GUI).\nIndependiente de que uses Anaconda o Miniconda y si no estás seguro de la opción a descargar, te recomendamos elegir su versión más reciente. Asimismo, si cuentas con otras instalaciones o paquetes de python, no es necesario desinstalarlas o borrarlas. Solo instala Anaconda o Miniconda normalmente.\nUna vez descargado el instalador debes hacer lo siguiente: En Windows Dirígete a la carpeta donde se encuentra el archivo descargado y haz doble click. Es un archivo .exe.\nSigue las instrucciones.\nEn MacOS Miniconda:\nEn una ventana del terminal ejecute bash Miniconda3-latest-MacOSX-x86_64.sh Anaconda:\nDirígete a la carpeta donde se encuentra el archivo descargado y haz doble click. Es un archivo .pkg. Sigue las instrucciones de las pantallas de instalación\nDebes cerrar y volver a abrir la ventana del terminal para que los cambios se realicen.\nEn Linux En una ventana del terminal ejecuta:\nMiniconda: bash Miniconda3-latest-Linux-x86_64.sh\nAnaconda: bash Anaconda3-latest-Linux-x86_64.sh\nSigue las instrucciones de las pantallas de instalación.\nDebes cerrar y volver a abrir la ventana del terminal para que los cambios se realicen.\nPara todos los casos Acepta los valores por defecto si durante la instalación no estás seguro de alguna configuración. Luego puedes cambiarlos\nPara probar la instalación independientemente del sistema operativo haz lo siguiente:\nAbre una ventana del terminal o Anaconda Prompt (en Windows desde el menú de inicio), luego ejecuta el comando conda list. Si la instalación ha sido exitosa debe aparecer una lista con los paquetes instalados. Actualización de conda Para actualizar conda debes abrir una ventana del terminal o Anaconda Prompt (en Windows desde el menú de inicio), luego navega hasta la carpeta de Anaconda o Miniconda (según el caso) y allí ejecutar el comando conda update conda.\nPrimeros pasos con conda Para que te familiarices, el comando conda es el principal y con él puedes, entre otras cosas, consultar y buscar el índice del paquete que desees, crear nuevos entornos de conda e instalar y actualizar paquetes en los entornos existentes.\nA continuación te presentamos algunos de los comandos de conda que puedes probar inicialmente:\nconda --version Verifica que conda está instalado y funcionando en tu sistema.\nconda list Muestra una lista de los paquetes instalados.\nconda search nombre_paquete Busca un paquete.\nconda install nombre_paquete Instala un paquete.\nconda update nombre_paquete Actualiza un paquete.\nPuedes consultar sobre los argumentos y usos de algunos comandos conda en este enlace. La documentación oficial de conda te ofrece una guía de 20 minutos para iniciarte en conda y probar sus principales características.\nSi necesitas de la gestión de paquetes y entornos, no dudes en usar conda. En un próximo artículo te dejaremos algunos tips para que saques el mayor provecho a trabajar con conda, no te lo pierdas.\nReferencias Documentación oficial Conda ","link":"https://opensciencelabs.org/blog/como-instalar-y-comenzar-utilizar-conda/","section":"blog","tags":["conda","empaquetado","paquetes","gestor","entorno virtual"],"title":"Cómo instalar y comenzar a utilizar Conda"},{"body":"","link":"https://opensciencelabs.org/tags/gestor/","section":"tags","tags":null,"title":"gestor"},{"body":" Hablar de Tensorflow, es hablar de Machine Learning porque es una plataforma que permite y facilita la creación de modelos asociados a algoritmos en los que se configura al equipo involucrado. Esto de manera tal que se obtengan sistemas capaces de construir y entrenar redes neuronales para detectar y descifrar patrones y correlaciones análogos al aprendizaje y razonamiento usados por los humanos.\nTensorflow fue ideado y desarrollado por un equipo de programadores de Google. El 9 de noviembre de 2015 se publicó bajo una licencia de código abierto Apache 2.0.\nCómo comenzar a utilizar Tensorflow Es importante tener en cuenta que antes de instalar y comenzar a utilizar Tensorflow es necesario contar con conocimientos previos de Machine Learning, Codificación, Matemáticas y Estadística; esto permitirá que las tareas de implementación de la plataforma en cualquiera de nuestros proyectos sea más eficiente.\nEn el caso de que no se cuente con conocimiento alguno o si simplemente se quiera ampliar lo que se sabe de estos ámbitos, en el sitio web oficial de Tensorflow se encuentra una página educativa donde está disponible una serie de herramientas ideadas para instruirse.\nAhora bien, para instalar y utilizar Tensorflow tenemos tres opciones: pip, docker y Gooogle Colab. Veamos el procedimiento en cada caso.\nInstalar Tensorflow con pip: Se debe tener un entorno de desarrollo de Python en el sistema o tener instalado Python a través de una de sus distribuciones. Por ejemplo, Anaconda. Si no tienes idea de los entornos que están disponibles te recomendamos que le des un vistazo a la información que Real Python nos brinda acerca de ello en: https://realpython.com/python-ides-code-editors-guide/\nLuego de que tengas Python en tu sistema verifica que este configurado; se requiere la versión de Python entre 3.5 a 3.7 y pip 19.0 o posterior. Para esto puedes ejecutar las siguientes líneas de código y observar las versiones. python3 --version pip3 --version virtualenv --version\nCrear un entorno virtual, este paso es opcional pero se recomienda para trabajar de forma separada de los archivos del sistema y así evitar algún error o actualización que puede alterar el rendimiento y funcionamiento de este. En la página de Tensorflow hay un espacio dedicado a este punto https://www.tensorflow.org/install/pip?lang=python3#2.-create-a-virtual-environment-recommended\nInstalar el paquete de tensorflow con pip, utilizando:\npip install --upgrade pip # Esta línea de código permite actualizar pip\npip install tensorflow# Con esta línea de código instalaremos Tensorflow\nLuego, puedes importar tensorflow como una biblioteca, colocando:\nimport tensorflow as tf\nDocker. Ejecutar un contenedor de Tensorflow. Docker es una plataforma abierta para desarrollar, enviar y ejecutar aplicaciones. Con Docker podemos mantener aislados los programas que estemos ejecutando con los elementos del sistema, aprovechando mejor los recursos lo cual agregaría velocidad y eficiencia al momento de compilar o ejecutar código.\nPara obtener información sobre la instalación de esta plataforma puedes visitar su página web o seguir la guía que nos brindan los desarrolladores de Tensorflow en su página https://www.tensorflow.org/install/docker.\nEn el caso de tener o haber instalado Docker en tu equipo, con las siguientes líneas de código puedes obtener Tensorflow:\ndocker pull tensorflow/tensorflow:latest-py3 # Descarga la imagen estable más reciente de Tensorflow\ndocker run -it -p 8888:8888 tensorflow/tensorflow:latest-py3-jupyter #Inicia un servidor de Jupyter\nEjecutar Tensorflow desde Google Colab. Google Colab: Es una plataforma basada en los cuadernos de Jupyter, la cual permite ejecutar y programar código de Python en tu navegador. No requiere configuración previa, tendrás acceso gratuito a GPUs y puedes compartir fácilmente los archivos que hayas creado.\nSi no conoces sobre esta herramienta puedes ingresar en https://colab.research.google.com/notebooks/welcome.ipynbvisitar y seguir la guía de bienvenida que sus desarrolladores han ideado.\nPara comenzar a utilizar Tensorflow en esta herramienta es necesario que se cree un archivo en esta plataforma, lo cual se puede hacer desde una cuenta de Google Drive en la opción nuevo, luego seleccionando la opción más y finalmente la opción Google colaboratory.\nUna vez creado el archivo se tendrán disponibles celdas en las cuales podemos escribir código de Python. En este caso debemos escribir inicialmente una línea de código que permita instalar a través de pip la versión de Tensorflow que necesitemos, esto sería ejecutando:\n!pip install tensorflow\nLuego podemos verificar la versión mediante\nimport tensorflow as tf\nprint(tf.__version__)\nLo que puedo hacer con Tensorflow Después de escoger la herramienta con la cual se trabajará Tensorflow, debemos tener en cuenta las características del proyecto que se llevará a cabo para de esta forma establecer el tipo, los parámetros y aquellos elementos esenciales sobre el modelo. Sin embargo, si aún no se tiene un proyecto definido y solo se desea empezar a utilizar esta herramienta puedes visitar https://www.tensorflow.org/tutorials; un sitio web donde se presentan algunas guías, blogs, vídeos y otros materiales de ayuda.\nPor otro lado, es importante destacar que Tensorflow es una plataforma que se actualiza constantemente y que en el paso del tiempo ha venido incluyendo nuevas funcionalidades que permiten construir y entrenar modelos de forma tal que el usuario cuente con una interfaz más amigable, la información sobre los procesos y errores es más clara y concisa. Un claro ejemplo de esto es tf.keras, una API que se utiliza para la creación rápida de prototipos, la investigación de vanguardia (estado-del-arte) y en producción.\nEste artículo se puede resumir en que la mejor forma de instruirte sobre esta herramienta de Machine Learning es visitando su página web https://www.tensorflow.org/, allí tienes mucha información y referencias educativas bastante completas.\n","link":"https://opensciencelabs.org/blog/como-instalar-y-comenzar-utilizar-tensorflow/","section":"blog","tags":["tensorflow","código","tensorflow","pip","docker"],"title":"Cómo instalar y comenzar a utilizar Tensorflow"},{"body":"","link":"https://opensciencelabs.org/tags/docker/","section":"tags","tags":null,"title":"docker"},{"body":"","link":"https://opensciencelabs.org/tags/pip/","section":"tags","tags":null,"title":"pip"},{"body":"","link":"https://opensciencelabs.org/tags/tensorflow/","section":"tags","tags":null,"title":"tensorflow"},{"body":"","link":"https://opensciencelabs.org/tags/comunidad/","section":"tags","tags":null,"title":"comunidad"},{"body":"","link":"https://opensciencelabs.org/tags/revisi%C3%B3n/","section":"tags","tags":null,"title":"revisión"},{"body":"","link":"https://opensciencelabs.org/tags/ropensci/","section":"tags","tags":null,"title":"ropensci"},{"body":" Para compartir, almacenar y divulgar de una manera fácil los datos y resultados de las investigaciones, los científicos deben contar con paquetes que lo garanticen. De esta manera, las investigaciones serán compatibles con formatos estandarizados y se logrará, progresivamente, el avance de la ciencia bajo el enfoque de ciencia abierta.\nUna de las comunidades de promoción y desarrollo de software de código abierto que proporciona estas ventajas para los investigadores es rOpenSci. A lo largo de este post conoceremos lo que hace la comunidad, cómo puedes formar parte y estar en armonía con ella, el proceso de revisión y más.\n¿Qué es rOpenSci? rOpenSci es una iniciativa sin fines de lucro fundada en 2011 por Karthik Ram, Scott Chamberlain y Carl Boettiger con la finalidad de promover, enseñar y hacer crecer las mejores prácticas en el desarrollo, uso y revisión por pares de software para el lenguaje R. Todo esto con el objeto de fomentar el uso de la ciencia abierta en las investigaciones.\nrOpenSci es un proyecto patrocinado fiscalmente por NumFOCUS una organización que apoya y promueve la computación científica, innovadora y de código abierto. Consulta el siguiente post de su blog con la presentación del proyecto: Cómo rOpenSci utiliza Code Review para promover la ciencia reproducible.\nrOpenSci, gracias a su mecanismo de revisión por pares y el constante trabajo de los desarrolladores de la comunidad, ha logrado más de 200 paquetes disponibles, alrededor de 500 contribuyentes de código y más de 500 citas en investigaciones, formando un imponente sistema de software abierto para el desarrollo y la revisión por pares (https://ropensci.org/pdfs/2018-08-15_rpharma_ropensci_butland.pdf). Desde estos enlaces puedes conocer tanto el equipo principal, como el de becarios de investigación, alumnos y colaboradores del proyecto.\nLa comunidad de rOpenSci acepta donaciones de individuos, instituciones y corporaciones que apoyen sus actividades. Si deseas hacer una donación al proyecto, accede a este formulario.\nAcerca de los Paquetes de rOpenSci Un paquete rOpenSci es una herramienta de software de R que está siendo o ha sido examinado cuidadosamente (mediante un proceso de revisión por pares), y que ha sido aportado por el personal y miembros de la comunidad.\nCon los paquetes de rOpenSci puedes, entre otras cosas, recopilar y acceder a datos desde varias fuentes y de varios tipos, analizarlos de manera interactiva y realizar visualizaciones de estos. Además, puedes incluir una narrativa en el proceso que permita generar un documento para presentaciones finales, en formatos como Word, Markdown, PDF o LaTeX, que luego puedes compartir.\nExplora los tutoriales, videotutoriales y casos de uso de los paquetes rOpenSci ofrece una documentación diversa, incluyendo tutoriales y videotutoriales que muestran un recorrido detallado acerca de lo que puedes hacer con sus paquetes. Asimismo, presenta casos de Uso con ejemplos de su manejo en situaciones reales.\nInfórmate brevemente sobre la revisión por pares de software en rOpenSci ¿Cómo enviar un paquete a rOpenSci?, y ¿cómo es el proceso de revisión? La comunidad en general puede enviar un paquete para que sea revisado y, los revisores de la comunidad deben garantizar el cumplimiento de ciertos requerimientos internos y un nivel de calidad consistente para que los paquetes sean aceptados. Para lograrlo llevan a cabo un proceso de revisión por pares caracterizado por ser transparente, constructivo y abierto.\nEl proceso es un trabajo voluntario donde intervienen: los editores que gestionan el flujo de entrada de los paquetes y garantizan su progreso; los autores que desarrollan, presentan y realizan mejoras en su paquete; y los revisores (dos por presentación de un paquete) que examinan el código del software y la experiencia del usuario. Dicho proceso se lleva a cabo en el repositorio de GitHub de Revisión de Software, allí notarás que se trata de una conversación continua hasta la aceptación del paquete, donde el autor recibe recomendaciones.\nSi tu colaboración es aceptada, seguirás recibiendo el apoyo de la comunidad en lo referente a temas de mantenimiento y a las actualizaciones de R. Sin embargo, conservarás la propiedad y el control de tu paquete. La comunidad te ofrece promocionarlo en su página web, blog y redes sociales. Cabe destacar, que si tienes un documento de desarrollo este puede ser enviado, luego de la revisión, a la Journal of Open-Source Software (JOSS) para su publicación.\nLa comunidad cuenta con un libro guía que recopila todos los aspectos importantes para el desarrollo, mantenimiento y revisión de los paquetes de rOpenSci, que incluye una guía para los editores, autores y revisores, las políticas de la comunidad, las buenas prácticas para el mantenimiento de los paquetes y otros tópicos de interés. No puedes dejar de leerlo.\nSi deseas enviar un paquete, lo primero que debes hacer es darle un vistazo a la Guía para autores antes de abrir un número de envío en el repositorio de revisión de software.\nÚnete como revisor de paquetes Si deseas ser revisor, puedes proponerte a través de este formulario con información de contacto y áreas de especialización, pero te recomendamos que antes leas la guía para revisores donde se detalla el proceso a seguir.\nLo que debes hacer para estar en sintonía con la comunidad Para unirte y estar al día con la comunidad, además de hacerlo enviando un paquete, siendo editor o revisor, puedes:\nSeguir el proyecto en sus redes sociales, en Twitter como @rOpenSci y promoverlo en las tuyas.\nAcceder y explorar el rOpenSci blog para conocer los paquetes, aprender a utilizarlos o contribuir a su mejora, conocer las mejores prácticas en desarrollo y revisión de software, eventos y otros post de la comunidad.\nSuscribirte a rOpenSci News el boletín informativo de rOpenSci, y recibir actualizaciones semestrales de las actividades de la comunidad en tu correo.\nAsistir a las llamadas de la comunidad rOpenSci community calls. Son llamadas trimestrales para aprender más sobre los desarrollos de rOpenSci y nuevos proyectos. Son gratuitas y abiertas, las llamadas anteriores se encuentran grabadas y disponibles en línea. Si tienes alguna idea para un tema de la llamada comunitaria puedes plasmarlo en el depósito público de ideas.\nPlantear y responder preguntas en el foro de discusión, en Stackoverflow con la etiqueta #ropensci o en Twitter.\nConocer los eventos próximos en la página oficial (https://ropensci.org/events/).\nVisitar otros recursos que te ofrece rOpenSci como charlas y publicaciones sobre la comunidad, la ciencia abierta y la revisión por pares de software de código abierto, de las cuales puedes descargar las presentaciones o ver en línea.\nLa comunidad rOpenSci está abierta a tu participación y a la de cualquier persona. Si usas el lenguaje R, unirte a ella es una buena oportunidad. Puedes darle un vistazo a nuestro post sobre pyOpenSci: un promotor de la ciencia abierta si tu lenguaje de programación es Python; y tus aspiraciones son las de desarrollar un paquete, ser editor, revisor, o seguir a esta comunidad.\nReferencias rOpenSci\nMejor ciencia con rOpenSci\nrOpenSci: permitiendo la investigación abierta y reproducible\n","link":"https://opensciencelabs.org/blog/te-contamos-sobre-la-comunidad-ropensci/","section":"blog","tags":["comunidad","ropensci","paquetes","revisión"],"title":"Te contamos sobre la comunidad rOpenSci"},{"body":" A lo largo de un proyecto de investigación suelen experimentarse dificultades en cualquiera de sus fases: desarrollo, su divulgación, promoción, en la publicación de los datos de forma abierta, en su catalogación o en su disposición de forma abierta para ser consultado en cualquier investigación. En cualquiera de estos casos, Dataverse1 es una solución que promete no solamente incorporar al flujo de trabajo métodos rápidos para asegurar que los datos cumplan los principios FAIR2, sino también ofrece un espacio donde alojarlos organizados en conjuntos, agrupando metadatos y codigo clasificados con su propio numero DOI, en repositorios llamados 'Dataversos'.\nDataverse es un proyecto que ya cuenta con apoyo de una cantidad de universidades y instituciones prestigiosas alrededor del mundo. Por ejemplo, la universidad Harvard destaca por su repositorio Dataverse público3 en el cual yace una enorme cantidad de conjuntos de datos (incluyendo metadatos, código y documentación) en todo tipo de áreas y, además está libre para el uso en investigaciones tanto dentro como fuera de la comunidad Harvard. Estos datos pueden ser accedidos bajo políticas de acceso abierto y términos de uso establecidos por cada equipo científico, permitiendo la réplica y reutilización del trabajo alojado en el sitio. Por lo tanto, es una iniciativa bastante atractiva cuando se desea difundir el trabajo realizado, ya que hace que tus datos sean visibles mediante el uso de motores de busqueda y manejadores de referencias.\nPara entender por qué ha ganado tanta tracción este proyecto, es importante primero saber de qué se trata exactamente, y cómo se llevó a cabo.\nQue es Dataverse? Dataverse es una aplicación web de código abierto para 'compartir, preservar, citar, explorar, y analizar datos de investigación'. Cuenta con una multitud de características para cumplir con este objetivo: al subir los archivos a la plataforma, estos son almacenados y preservados de manera que permanezcan iguales al día en que se subieron. También permite organización por 'carpetas' mediante los llamados dataversos, haciéndote propietario de la plataforma en la que subes los datos y enlazándolos, de esta forma, de forma permanente a tu usuario, al tiempo que permite integrar de forma continua tus publicaciones y los datos que estas utilizan. Todo esto con el propósito fundamental de asegurar que tus datos te sean acreditados, estando, al mismo tiempo, alojados y preservados por años por venir.\nSu nombre viene del hecho que Dataverse funciona mediante un repositorio (la instalación de software) que a su vez aloja archivos virtuales llamados dataversos. Los dataversos se componen de conjuntos de datos, y los conjuntos de datos tienen metadatos descriptivos, archivos, documentación, código, y demás. Si el usuario quisiera, puede incluir otr databerso dentro de ellos. Al publicar los conjuntos de datos, se le asigna una citación formal académica y un identificador DOI asociado a ellos, para que la utilices a la hora de escribir artículos en tus redes o paginas web.\nDataverse, por lo tanto, cuenta con varias APIs abiertas (de búsqueda, acceso y depósito de archivos) para darle un grado mayor de interoperabilidad y permitir una integración más limpia y ligera dentro de el esquema de trabajo de cualquier investigador, archivista o editor.\nQuien usa Dataverse? Además del repositorio de Harvard anteriormente mencionado, en la pagina principal del sitio web de Dataverse se encuentra un mapamundi en el que se señalan las instalaciones públicas de repositorios Dataverse, con mayor concentración de éstos en Norte America y Europa, aunque se ven varias también en America Latina, Africa y Asia. Algunas de estas estan pensadas no solamente para uso local, sino también para países y regiones vecinas, como el ACSS Dataverse4 de Lebanon, el cual contiene conjuntos de datos producidos en paises árabes. Además, a pesar de limitaciones respecto al envío de archivos, muchos de estos sitios permiten acceder los dataversos de forma gratuita sin importar que seas investigador o parte de la institución o comunidad en cuestión.\nAl incentivar a los investigadores a usar una plataforma abierta para publicar y compartir los datos que ellos mismos utilizan, se hace práctica la distribución y publicación de estos bajo una licencia abierta que permita su acceso y replicación entre terceros. Esta es una forma algo indirecta, pero aun así posiblemente eficaz para lograr que se realice y presente una ciencia realmente abierta mediante el uso de aplicaciones abiertas y eficientes en su realización, sin modificar o añadir pasos innecesarios en su práctica. Mención aparte merece el hecho de tener una gran utilidad para los propios investigadores, ya que permite asegurar su acreditación adecuada en publicaciones que contengan su trabajo.\nEs posible que en el futuro este tipo de práctica se hagan comunes, y que haya una multitud de repositorios de aplicaciones como Dataverse alrededor del mundo, que albergen el conjunto del trabajo científico realizado en las regiones donde estén localizados. De esta manera, existiría la posiblidad de que las conclusiones de los investigadores y instituciones sean realmente juzgadas, criticadas y revisadas también por ciudadanos comunes, haciendo que cualquier tipo de decisión política que dependa del trabajo científico, dependa también de los aportes de estos.\n","link":"https://opensciencelabs.org/blog/dataverse-y-su-potencial-para-proyectos-de-ciencia-abierta/","section":"blog","tags":["datosverse","datos","repositorios"],"title":"Dataverse y su potencial para proyectos de ciencia abierta"},{"body":"","link":"https://opensciencelabs.org/tags/datosverse/","section":"tags","tags":null,"title":"datosverse"},{"body":"","link":"https://opensciencelabs.org/tags/repositorios/","section":"tags","tags":null,"title":"repositorios"},{"body":"","link":"https://opensciencelabs.org/tags/pyopensci/","section":"tags","tags":null,"title":"pyopensci"},{"body":" Las distintas disciplinas que abarca la ciencia abierta trabajan de manera conjunta; tal es el caso del código abierto, la investigación abierta y reproducible y los datos abiertos. En el presente artículo tratamos sobre pyOpenSci, un proyecto al servicio de la ciencia, desarrollado bajo el enfoque de estas disciplinas. Si eres un programador, quieres desarrollar (o estás desarrollando) algún paquete científico con Python y que sea aceptado por una gran comunidad de pythonistas, entonces aquí está lo que necesitas saber para lograrlo.\n¿Qué es pyOpenSci? pyOpenSci, también conocido como pyOpenScience, es un proyecto encargado de promover la ciencia abierta mediante el apoyo al desarrollo, la revisión por pares y la publicación abierta de paquetes científicos escritos en Python que cuenten con una buena documentación y estén probados previamente. Estos paquetes son utilizados para recopilar, descargar y transformar datos científicos con una metodología de trabajo abierta y reproducible.\nEl modelo de trabajo del proyecto está basado en la comunidad rOpenSci. pyOpenSci no trabaja solo, tiene una fuerte vinculación con la Journal of Open Source Software (JOSS), una revista que fomenta la revisión por pares, la aceptación y la publicación de software de código abierto. Por tanto, estas dos comunidades pueden verse como complementarias entre sí. El enfoque en el proceso de revisión de pyOpenSci es más práctico que el de la JOSS. Con pyOpenSci los autores pueden publicar sus paquetes con un DOI (Digital Object Identifier) de manera que puedan ser citados y encontrados por los buscadores de artículos científicos.\nEn este momento (noviembre 2022), pyOpenSci es un proyecto patrocinado fiscalmente por Community Initiatives, razón por la cual se ha reanudado la revisión del software desde septiembre de 2022.\nInicios de pyOpenSci, un relato de su fundador El proyecto pyOpenSci surgió por el pythonista Steve Moss, el cual en el post Facilitating Open Science with Python, publicado en el blog de rOpenSci en mayo del 2013, manifiesta las razones de ¿Por qué Python?, ¿Por qué pyOpenSci? donde textualmente dice: \u0026quot;quería, ante todo, facilitar la mejora del campo científico, permitiendo y promoviendo la apertura y el intercambio dentro y entre las comunidades científicas. Creo que solo es posible que la ciencia progrese si se hace completamente transparente\u0026quot; (traducción propia al español). De allí es donde se fundamentan los ideales de pyOpenSci.\nEl proyecto pretende mejorar y facilitar la apertura de la investigación científica. Para ese momento Steve Moss tenía la esperanza de poder incentivar a los investigadores a utilizar pyOpenSci para desarrollar, compartir y comprometerse con sus estrategias y así hacer posible la ciencia abierta. Para esto esperaba poder ofrecer talleres, sesiones de formación, consultoría y apoyo y que pyOpenSci participara en actividades de divulgación dentro de las comunidades. Algo que también expresa en su artículo.\n¿Cómo puedes contribuir a pyOpenSci? Puedes involucrarte en este proyecto de distintas maneras, a continuación te las presentamos:\nSúmate al foro comunitario. Un espacio donde se discuten los temas de interés y se publican los anuncios de nuevas reuniones.\nEnvía un paquete. Hazlo para apoyar a la comunidad científica de Python en general y a la de pyOpenSci en específico.\nPuedes ser un revisor de paquetes.\nAyuda con la infraestructura técnica. Tanto el sitio oficial del proyecto como los otros sitios web, por ejemplo, necesitan mantenimiento y desarrollo.\nParticipa activamente en la divulgación de pyOpenSci. Comenta a tus amigos y colegas, haz mención del proyecto en eventos abiertos y en tus redes sociales. !Transmite la información para hacer crecer esta comunidad!\nColaboradores Según el fundador de pyOpenSci, para colaborar se necesita lo siguiente: \u0026quot;Además de un amor por Python, uno debería tener un amor por ser abierto y transparente sobre los temas que les apasionan\u0026quot;. Esto lo expresó en su post para la comunidad rOpenSci en 2013 (mencionado anteriormente). Donde resalta que, para ese momento, solo era él en pyOpenSci y hasta la actualidad más de 30 personas han colaborado con el proyecto, conformando una comunidad diversa de personas con un fin común: ofrecer un lugar práctico en torno al software científico en Python y donde se promuevan las buenas prácticas de ciencia abierta.\nAquí te mencionamos algunas personas que han contribuido y son miembros activos de pyOpenSci: Leah Wasser, Chris Holdraf, Max Joseph, Ivan Ogasawara miembro del Consejo Directivo de nuestra plataforma Open Science Labs.\nPaquetes pyOpenSci La comunidad pyOpenSci es la encargada de desarrollar, presentar, revisar y promover los paquetes de software científico en Python. Al ser una comunidad abierta, cualquiera puede enviar un paquete para su revisión. Puedes conocer los paquetes que se encuentran actualmente en revisión accediendo a este repositorio GitHub y los aceptados aquí.\nAlgunos de los paquetes aprobados hasta ahora por pyOpenSci son:\nLectura, desplazamiento temporal y la escritura de datos de sensores devicely\nExploración y visualización de datos espaciales earthpy.\nDiapositivas de Jupyter Notebooks con Nbless.\nValidación de las estructuras de datos manejadas por pandas con Pandera.\nDatos geoquímicos pyrolite.\nIntegrar conjuntos de datos multimétricos OpenOmics\nPasemos ahora a conocer algunos de los sitios y recursos técnicos que mantiene el proyecto (además de las reuniones y el foro).\npyOpenSci blog En este blog se abordan distintos tópicos, entre ellos:\nEventos y actividades planificadas.\nPaquetes que han pasado por el proceso de revisión.\nDesafíos de pyOpenSci en la enorme comunidad de Python.\nOtros recursos y sitios relacionados Organización pyOpenSci Github. Contiene el repositorio de revisión de software y otros.\npyOpenSci cookiecutter es una plantilla que facilita el empaquetado del código Python.\nGuía de desarrollo de paquetes y Guía de revisión por pares con información para los autores y revisores de los paquetes, que incluye todo el proceso. Es lo primero que debes leer si estás interesado en enviar un paquete a pyOpenSci.\nRepositorio de Gobernanza de pyOpenSci. Donde se discuten la dirección y el alcance de pyOpenSci. También ofrece notas de las reuniones de la comunidad.\nLa comunidad pyOpenSci está abierta para que envíes un paquete, te conviertas en revisor, ayudes a difundir sus actividades y buenas prácticas o para que participes en los foros donde tomarán en cuenta tus intervenciones. De esta manera, estarás contribuyendo con la comunidad científica de Python.\nReferencias Web site del Proyecto\nWeb site de Steve Moss (fundador de pyOpenSci)\nFacilitating Open Science with Python\npyOpenSci Promoting Open Source Python Software To Support Open Reproducible Science\n","link":"https://opensciencelabs.org/blog/pyopensci-un-promotor-de-la-ciencia-abierta/","section":"blog","tags":["pyopensci"],"title":"pyOpenSci: un promotor de la ciencia abierta"},{"body":"","link":"https://opensciencelabs.org/categories/revisi%C3%B3n-abierta-por-pares/","section":"categories","tags":null,"title":"revisión abierta por pares"},{"body":"","link":"https://opensciencelabs.org/tags/ciencia-ciudadana/","section":"tags","tags":null,"title":"ciencia ciudadana"},{"body":"","link":"https://opensciencelabs.org/tags/covid19/","section":"tags","tags":null,"title":"covid19"},{"body":"","link":"https://opensciencelabs.org/tags/laboratorios-sociales/","section":"tags","tags":null,"title":"laboratorios sociales"},{"body":" Frente a la pandemia ocasionada por la enfermedad COVID-19 se han desarrollado en todo el mundo, distintas prácticas de ciencia abierta para hacerle frente. Una de ellas son los Laboratorios Sociales donde los integrantes desarrollan y difunden actividades virtuales respecto a este tema. Recordemos que los laboratorios sociales son espacios donde cualquier ciudadano puede participar, colaborando con otros, compartiendo sus conocimientos, ideas y experiencias con el propósito de generar proyectos que ofrezcan propuestas o soluciones para mejorar situaciones diversas.\nEn este post mencionamos algunos laboratorios sociales y los proyectos que han desarrollado continuamente con respecto al manejo del COVID-19 y observaremos el trabajo desempeñado en conjunto de algunos de ellos.\nFrenaLaCurva FrenaLaCurva es un referente en cuanto a plataformas que desarrollan y ofrecen iniciativas para el manejo del COVID-19, mediante Laboratorios Ciudadanos Distribuidos con el fin de detectar buenas ideas y personas interesadas en ayudar a llevarlas a cabo, mediante la experimentación, colaboración e innovación ciudadana para afrontar la situación de la pandemia. La plataforma cuenta con la participación de más de 10 países, entre ellos Brasil, Argentina, Colombia, Uruguay, Alemania.\nAlgunas iniciativas de los Laboratorios Ciudadanos Distribuidos de FrenaLaCurva son:\nRed Comunitaria para la Atención alimentaria A Coruña\n#yaVoyXti, app colaborativa de solidaridad en tiempos de coronavirus\nDiario literario de un confinamiento\nTodas estas iniciativas y otras desarrolladas por esta plataforma ayudan a la comunidad en su cotidianidad frente a a pandemia, brindándoles espacios para que interactúen y se sientan acompañados. Puedes consultar aquí toda la información sobre los proyectos.\nMIT MediaLab Los MediaLab son tipos de laboratorios sociales, y el Instituto de Tecnología de Masachussets (MIT) cuenta con uno. Bajo este ámbito el MIT MediaLab está dedicado a los proyectos de investigación en la convergencia del diseño, la multimedia y la tecnología. Ofrece varios recursos y proyectos para el manejo del COVID-19 como instituto de investigación. Entre ellos se encuentran:\nCentro de Información COVID-19 Ofrece las últimas actualizaciones, orientación y recursos para ayudar a apoyarle durante la pandemia.\nProyecto sobre comunidades resilientes y COVID-19 Es un proyecto de la mano con el grupo City Science para abordar la resiliencia.\nObservatorio COVID-19 Este proyecto es una colaboración del MIT con el Banco Mundial y se refiere al seguimiento mundial de la evolución en tiempo real del COVID-19 mediante la cuantificación del distanciamiento social y el impacto económico.\nPandemic Response CoLab El propósito del proyecto es:\nIdentificar los problemas clave relacionados con COVID-19\nDesarrollar soluciones a estos problemas\nReclutar personas y recursos para implementar estas soluciones\nEl proyecto ofrece un dashboard, el Pandemic Response Data Dashboard que recopila datos fiables y oportunos para ayudar a la comunidad científica a encontrar las soluciones más impactantes a la pandemia.\nMediaLab UGR y LabIN Granada MediaLab UGR es un laboratorio social de la Universidad de Granada que, entre otras cosas, promueve convocatorias abiertas para la presentación de propuestas y la participación en el desarrollo colaborativo de proyectos para la Universidad y la sociedad en general.\nPor su parte, LabIN Granada es un laboratorio social nacido en 2007 para Granada, y en este momento de aislamiento social, funciona como una herramienta para conectarnos desde la solidaridad y la creatividad.\nEstos laboratorios, en ocasiones, trabajan en conjunto en la planificación y desarrollo de proyectos para el bienestar social. Uno de ellos es la iniciativa LabIN #UGRenCasa, un espacio de encuentro para la comunidad universitaria y la ciudadanía durante el confinamiento con el fin de proponer ideas para vivir mejor y compartir experiencias sobre esta situación y qué podemos aprender de ello para el futuro.\nMediaLab Prado La actividad de MediaLab Prado se estructura en grupos de trabajo, convocatorias abiertas para la producción de proyectos, investigación colaborativa y comunidades de aprendizaje en torno a temas muy diversos [https://www.medialab-prado.es]. MediaLab Prado está constituido por varios laboratorios, uno de ellos el InCiLab un laboratorio de innovación ciudadana.\nUna de las iniciativas de InCiLab frente al COVID-19 son los Laboratorios Bibliotecarios en confinamiento bajo la tutela del Ministerio de Cultura y Deporte de España. Se trata de un espacio de encuentro para reflexionar sobre el impacto que tendrá la pandemia en las bibliotecas y proponer soluciones a nuevos retos.\nContinuemos con otro laboratorio y algunos de sus proyectos:\nBID Lab Es el laboratorio de innovación del Grupo Banco Interamericano del Desarrollo (BID). Se encarga de movilizar financiamiento, conocimiento y conexiones para impulsar la innovación y promover la inclusión en América Latina y el Caribe [https://bidlab.org/es/].\nBID Lab ofrece un sitio web RESPONDIENDO AL COVID-19 donde se presentan proyectos que abordan los efectos sanitarios y económicos del COVID-19. Algunas de esas iniciativas se muestran a continuación:\nCOVID-19 Mapa de Innovadores de América Latina y el Caribe El mapa muestra los innovadores, emprendedores y startups de América Latina y el Caribe, que proponen soluciones para moderar los desafíos ocasionados por el COVID-19.\nCONECTOR Digital COVID-19 Es un punto de encuentro y colaboración para apoyar a las empresas, emprendedores y ciudadanos de América Latina y el Caribe con recursos de innovaciones digitales, colaboración para potenciar el impacto de sus soluciones, el intercambio de ideas, experiencias e información de valor durante el tiempo de confinamiento.\nCivicLytics- Escucha ciudadana para no dejar a nadie atrás CivicLytics es un observatorio que busca entender las percepciones y preocupaciones de los ciudadanos de América Latina y el Caribe respecto a la pandemia, mediante el uso de inteligencia artificial. Este proyecto es apoyado por el BID Lab.\n!Aislados pero unidos! El trabajo conjunto entre laboratorios sociales para manejar la COVID-19 se evidencia en varias situaciones. Por ejemplo, el MediaLab UGR se unió a FrenaLaCurva como laboratorio participante, puedes ver la noticia aquí.\nTambién Medialab Prado se suma a la iniciativa de FrenaLaCurva: Desafíos Comunes. Festival de innovación abierta Frena la Curva, accede a la noticia desde este link. Desafíos comunes es una convocatoria para iniciativas vecinales, proyectos de emprendimiento e innovación social, y experiencias colaborativas desde el sector público.\nEstos son algunos laboratorios sociales que han estado trabajando en el manejo del COVID-19 con información breve sobre sus proyectos, anímate a acceder a sus sitios web y obtén más detalles.\n!Anímate!\nComo ciudadano, investigador, emprendedor o simplemente amante de las buenas prácticas de ciencia abierta, no te quedes atrás y participa o crea un proyecto durante este tiempo de aislamiento y distanciamiento social. En OpenScienceLabs te animamos a que no lo dejes para después, puedes comenzar ahora.\nReferencias FrenaLaCurva\nMIT MediaLab\nMediaLab UGR\nLabIN Granada\nMediaLab Prado\nBID Lab\nsocialab\n","link":"https://opensciencelabs.org/blog/los-laboratorios-sociales-y-el-manejo-del-covid-19/","section":"blog","tags":["laboratorios sociales","covid19","ciencia ciudadana"],"title":"Los laboratorios sociales y el manejo del COVID-19"},{"body":"","link":"https://opensciencelabs.org/tags/manual/","section":"tags","tags":null,"title":"manual"},{"body":" ¿Qué es realmente la ciencia abierta? A pesar de que parece una idea simple, su implementación puede concurrir en todo tipo de preguntas y problemas posteriores sin una definición clara de los permisos de uso sobre resultados o metodologías, concedidos tanto a los investigadores como a los lectores y posteriores usuarios de la investigación, y de qué es lo que se busca lograr con este tipo de práctica de investigación.\nLa ciencia abierta plantea cuestiones en el ámbito legal e institucional, por lo que deben declararse previamente de manera formal las normas de publicación o de uso, tanto de los datos utilizados como del artículo o conclusiones resultantes. Es por esto que tanto los miembros del equipo de investigación como las instituciones que financian y publican estas deben tener una idea clara de cuáles són los fundamentos en los cuales se basa la ciencia abierta y a qué principios se han de ajustar.\nPara este propósito existe una variedad de recursos en linea a través de los cuales se pueden aprender los fundamentos de las prácticas de la ciencia abierta. Mucha de esta información ya está lo suficientemente abreviada y resumida, de manera tal que cualquiera, aún sin experiencia previa en el tema pueda fácilmente entenderlo sin mucho problema en poco tiempo, exigiendo sólo el querer hacerlo. Entonces, ¿cuáles son exactamente estos sitios desde los que las personas se pueden educar acerca de los principios de la ciencia abierta?\nManual de Capacitación de Ciencia Abierta1 En el febrero de 2018, 14 autores en la Biblioteca Nacional Alemana de Ciencia y Tecnología se reunieron y trabajaron juntos con el propósito de crear un manual gratuito y abierto, mediante el cual se buscaría capacitar y educar a las personas acerca de las prácticas y principios de la ciencia abierta, publicado por GitBook en internet y libre para el uso de cualquiera. El resultado fue el manual de capacitación anteriormente mencionado, el cual se produjo como resultado de un proyecto financiado por la Unión Europea llamado FOSTER Plus, cuyo propósito principal era convertir la ciencia abierta en un estándar dentro de la comunidad científica.\nA pesar de que en este manual se habla también de las filosofias y teorias de las cuales surgieron los movimientos de conocimiento abierto, el foco está principalmente en la formas y métodos con las cuales se realiza la ciencia abierta. Por lo tanto, el manual también actúa como una herramienta para educar a aquellos que deseen difundir y enseñar pautas acerca de las herramientas disponibles para la realización de papers de acceso abierto, investigación reproducible, y políticas de ciencia abierta, entre otros.\nOpen Definition2 La Open Definition, tal como su nombre se indica, trata simplemente de dar una definición clara y a fondo de lo que significa que un conocimiento sea \u0026quot;abierto\u0026quot;. Es un documento que fue creado por la Open Knowledge Foundation, el cual está escrito principalmente con la creación de licencias de acceso libre de datos, métodos, publicaciones y demás. Esta definición de libre se deriva y es sinónima con aquella usada en el mundo del software, particularmente de la Open Source Definition. A pesar de que trata de ser un documento legal, es bastante conciso, corto y fácil de entender.\nPor lo tanto, se trata de un documento bastante importante a la hora de crear y analizar licencias de acceso abierto y los permisos y privilegios que éstas conceden tanto a los investigadores como a los lectores o usuarios de la investigación. Aclara temas de los cuales no se suele hablar mucho, tales como la necesidad de que los archivos utilizados estén en formatos que no posean restricción algunas, que se permita también la distribución del trabajo tanto junto como separado de sus componentes constituyentes, entre otros.\nOpen Science Knowledge Base3 Esta lista se trata de un recopilatorio de recursos y enlaces a literatura, cursos, videos, y demás donde se explican en detalle una multitud de temas relacionados con la ciencia abierta. Funciona como una lista desde la cual todos los interesados en el tema pueden indagar más a fondo si lo consideran necesario, con enlaces a artículos donde se explica la investigación reproducible, la replicabilidad, el conocimiento abierto, de manera breve y corta o extensa y detallada, tal como el usuario lo desee. A la vez, actúa como un curso donde se da un programa educativo para que cualquiera pueda aprender de ciencia abierta desde 0, desde responder preguntas tales como '¿cuales són los problemas que abarca la ciencia abierta?' hasta enseñar lugares donde puedes realizar preguntas como ésta y buscar recursos adicionales, como por ejemplo, acerca de cómo enseñar ciencia abierta.\nOpen Data Handbook4 También realizado por la Open Knowledge Foundation, éste es un proyecto que actua como una introducción a la apertura de datos, principalmente en cuanto al estatus legal y social de estos se refiere, y cuáles técnicas son adecuadas para la distribución o uso de datos que han sido liberados para el público. Se explica tanto el propósito de esforzarse en utilizar tecnologías contemporáneas para publicar datos de forma abierta, cuáles requisitos se deben cumplir en términos de disponibilidad, interoperabilidad y permisos de redistribución, para que un conjunto de datos se considere abierto, como las herramientas, métodos y servicios se pueden utilizar para liberar datos al público.\nEn el sitio del Open Data Handbook también se pueden encontrar recursos5 creados por la comunidad, todos relacionados a temas de datos abiertos (privacidad, políticas, estándares, derecho a la información, etc), donde se han compartido artículos y portales relacionados al tema, algunos también preparados con principantes en mente.\n","link":"https://opensciencelabs.org/blog/te-ensenamos-lugares-para-aprender-los-fundamentos-de-la-ciencia-abierta/","section":"blog","tags":["datos","manual"],"title":"Te enseñamos 4 lugares para aprender los fundamentos de la ciencia abierta"},{"body":"","link":"https://opensciencelabs.org/tags/automatizaci%C3%B3n/","section":"tags","tags":null,"title":"automatización"},{"body":" ¿Qué es Bash?\nEs un shell, o intérprete de lenguaje de comandos, para el sistema operativo GNU. Su nombre es un acrónimo de \u0026quot;Bourne-Again SHell\u0026quot;, un juego de palabras sobre Stephen Bourne, el autor del antepasado directo del actual shell de Unix sh, que apareció en la séptima edición de la versión de Bell Labs Research de Unix.\nEl shell también es conocido como terminal; una interfaz entre el usuario y el propio sistema operativo. Podemos acceder a él a través del menú o una combinación teclas. Linux proporciona por defecto seis terminales de este tipo, de Control+Alt+F1 a Control+Alt+F6. Si queremos volver al modo gráfico lo hacemos con Alt+F7 (estos atajos pueden variar según la distribución).\nEs importante destacar que el sistema operativo GNU proporciona otros shell sin embargo, Bash es el shell por defecto. Este, al igual que otros programas de GNU, es bastante portátil. Actualmente funciona en casi todas las versiones de Unix y otros sistemas operativos como Mac OS X Tiger. También se ha llevado a Microsoft Windows por el proyecto Cygwin.\nAhora bien, cuando desde una distribución Linux abrimos o activamos un terminal se indica que estamos en nuestro home mediante el signo ~.Veremos en pantalla algo similar a:\nEl home es el sitio donde se pueden aplicar inicialmente las tareas.\nUn par de comandos que nos brindan ayuda o referencias en Bash son man e info, ideales cuando se tienen dudas acerca de uno o varios comandos.\nman muestra la información del manual de bash en el sistema sobre el comando o página indicado.\ninfo permite consultar la información que se almacena en archivos INFO (archivos de formato Texinfo) de algún comando o software.\nPara utilizar estos comandos solo es necesario escribirlos seguido de un espacio y la palabra de la cual tenemos duda. Por ejemplo si tecleamos info bash o man bash, tenemos la posibilidad de leer un texto sobre lo que es bash y sus características principales.\nCrear, eliminar y editar carpetas o directorios Entre las tareas que podemos realizar con bash están crear, eliminar y editar carpetas o directorios. Algunos de los comandos asociados a estas son:\npwd nos indica el directorio en el que estamos actualmente. Si probamos este comando en el home obtendremos algo similar a\nls nos permite ver la lista de los directorios, carpetas y archivos contenidos en el sitio o carpeta en la que estemos. ls -a nos muestra todos los archivos incluyendo los ocultos.\nSi queremos movernos por las carpetas el comando cd seguido de la dirección a la que se desea ir nos permitirá realizar esta tarea. De modo que cd / te llevara a la raíz, cd ~ al home ( cd solo hace lo mismo), cd /usr/doc te lleva al directorio de documentación del sistema.\nSi quieres crear una carpeta (o varias) lo puedes hacer en tu home, usando mkdir y el nombre de la carpeta que quieres crear, luego entra en ella con cd.\nPara borrar una carpeta escribe rmdir seguido por un espacio y el nombre, pero la carpeta tiene que estar vacía y contar con permiso para borrarla.\nMover, renombrar y eliminar archivos o ficheros El comando mv, permite dos operaciones. Cambiar un fichero de sitio, para lo cual es necesario que se tenga permiso de escritura sobre ese fichero y el lugar de destino. Se utiliza simplemente indicando mv nombre_origen ruta_destino.\nCon este comando también es posible mover directorios, o todos los ficheros de un directorio.\nLa otra operación que se puede realizar con mv es el cambio de nombre, así basta con indicar el nombre de un fichero o directorio, y luego su nuevo nombre.\nLos comandos cat, more y less sirven para mostrar el contenido de ficheros de texto.\nEl comando rm se utiliza para borrar ficheros. Es importante destacar que estos ficheros no se envían a una papelera así que NO SE PUEDEN RECUPERAR UNA VEZ BORRADOS.\nOtro comando útil es cp sirve para copiar ficheros. En el proceso de copia intervienen tres elementos: lo que se copia, la ruta de origen y la ruta de destino. La ruta de origen se especifica junto con lo que se quiere copiar.\nDe la misma manera que se copian, se borran o se mueven ficheros, se puede hacer lo mismo con los directorios. Hay que tener en cuenta que un directorio puede contener muchos ficheros y, además, otros directorios que, a su vez, pueden contener más ficheros y directorios. Por tanto, si se quiere copiar un fichero completo, con todo lo que tiene dentro, hay que indicarlo con la opción -R. A esto último se suele llamar “copiar de forma recursiva”.\nOtro comando que puede ser util es rm -rf nombre_del_directorio, borra el directorio y todo lo que contiene (lo que se elimina no se puede recuperar).\nComodines Recordemos que Bash es el interprete de comandos, el programa que intenta comprender lo que tu dices y lo ejecuta, este nos permite utilizar comodines a la hora de escribir un nombre de fichero o directorio. Además la tecla tab permite completar rutas o algún comando a la hora de escribir. Por ejemplo, escribe /ho y pulsa tab verás cómo aparece /home/).\nLos principales comodines son *, ? y los corchetes [].\nEl asterisco sustituye a cualquier grupo de letras.\nEl signo de interrogación ? sólo vale para una letra.\nLos corchetes valen por un conjunto definido de letras.\nDebes tener en cuenta que son muy importantes las mayúsculas y la minúsculas al momento de escribir tus comandos, porque el intérprete es sensible a ellas. Esto trae como consecuencia la posibilidad de tener dos ficheros que se llamen igual, por ejemplo proyectos y Proyectos, uno tiene mayúsculas y otro no.\nEn resumén, tenemos que Bash nos permite realizar diversas tareas asociadas a directorio y ficheros. Existen distintos comandos que pueden ser bastante útiles y si tenemos cualquier duda podremos recurrir rápidamente a un manual o documento de ayuda.\nPuedes consultar más de los comandos en https://ss64.com/bash/index.html\nReferencias Manual Práctico de Linux con ejercicios por Luis José Sánchez González. Manual de Linux por Álvaro Alea Fdz. EcuRed-Terminal EcuRed-Bash\n","link":"https://opensciencelabs.org/blog/automatizacion-de-tareas-via-bash/","section":"blog","tags":["bash","automatización"],"title":"Automatización de tareas vía bash"},{"body":"","link":"https://opensciencelabs.org/tags/bash/","section":"tags","tags":null,"title":"bash"},{"body":"","link":"https://opensciencelabs.org/tags/bokeh/","section":"tags","tags":null,"title":"bokeh"},{"body":"","link":"https://opensciencelabs.org/tags/matplotlib/","section":"tags","tags":null,"title":"matplotlib"},{"body":"","link":"https://opensciencelabs.org/tags/scipy/","section":"tags","tags":null,"title":"scipy"},{"body":"","link":"https://opensciencelabs.org/tags/seaborn/","section":"tags","tags":null,"title":"seaborn"},{"body":" Un proyecto de ciencia abierta, así como cualquier otro, requiere de una evaluación previa para determinar lo que se necesita hacer y cómo debe llevarse a cabo. En el caso de ciencia abierta, debemos tener en cuenta que, por su alcance e impacto en la comunidad científica y sociedad en general, es vital estudiar las herramientas que se utilizarán porque de ellas depende la obtención de resultados óptimos, visualmente atractivos y lo suficientemente informativos.\nAntes de continuar, recordemos del artículo ¿Qué es la ciencia abierta?, que la ciencia abierta es un movimiento, una manera de ver y hacer ciencia, que busca crear una cultura donde la información de todo el proceso de investigación científica, ya sean los datos, protocolos, cuadernos de laboratorio, resultados obtenidos en las diferentes etapas de este proceso, sean gratuitos y de libre acceso. De esta manera, todas las personas involucradas en el proceso de investigación, ya sean los propios científicos, instituciones de investigación y financiamiento, y público en general, pueden contribuir y colaborar con el esfuerzo de investigación. Con esto se garantiza que el trabajo científico sea abierto e inclusivo, donde el investigador se dé cuenta que poner a libre disposición sus trabajos le garantizan, entre otras cosas, el aumento del impacto y difusión de sus investigaciones.\nAllí también se menciona que la ciencia abierta es una forma de producir conocimiento científico, promoviendo la comunicación y acceso efectivo del contenido de las investigaciones científicas en todas las áreas (instrumentos de trabajo, resultados intermedios y finales) mediante la digitalización y las bondades del internet.\nCuando elaboramos un proyecto bajo la modalidad de ciencia abierta, por lo general analizamos, describimos y descubrimos información que está contenida en datos, lo cual se hace aplicando métodos estadísticos u otros similares. Estos se pueden complementar con una o varias visualizaciones o gráficos que permitirán, tanto a los analistas como a los lectores, tener una visión más general de lo que las medidas numéricas o palabras describen. Además, una visualización logra presentar resultados estéticamente más atractivos y captar la atención en puntos donde se requiera un mayor enfoque.\nPara tener esto último un poco más claro, representémoslo en un ejemplo. Supongamos que estamos estudiando las enfermedades en un período de tiempo dado y en una región específica, y tenemos la información que corresponde a la edad, sexo y la enfermedad que presentan los pacientes atendidos en los centros hospitalarios de ese período.\nEntonces podemos considerar la estadística descriptiva como una de las técnicas ideales, en este caso se calcularían estadísticos como la media para la edad, la proporción para el sexo y el tipo de enfermedad. A su vez, podemos hacer cruces de información a través de tablas de contingencia y a partir de estas elaborar gráficos que complementarán esta información. Estos gráficos mostrarán, de forma sintetizada, lo que los datos revelan y resultará más fácil hacer comparaciones. Además los colores y las áreas de las figuras trazadas captarán la atención de lo que verdaderamente se requiere para la toma de decisiones. Todo ello es una clara y simple noción de lo que una visualización puede ayudar.\nA continuación veamos cinco bibliotecas o librerías de Python que puedes implementar en tu proyecto de ciencia abierta:\npandas: Es una biblioteca que permite realizar tareas de manejo y análisis de datos de forma rápida y eficiente. Se complementa con la biblioteca de visualización Matplotlib. Puedes consultar más información en https://pandas.pydata.org/.\nSciPy: Es uno de los paquetes centrales que componen la pila de SciPy. Proporciona muchas rutinas numéricas eficientes y fáciles de usar, como las rutinas de integración numérica, interpolación, optimización, álgebra lineal y estadística. Esta descripción se encuentra disponible en https://www.scipy.org/scipylib/index.html.\nMatplotlib: es una de las primeras y más populares bibliotecas de visualización de Python. En su página web podemos encontrar una corta descripción de ella: Matplotlib es una biblioteca muy completa para crear visualizaciones estáticas, animadas e interactivas en Python. Con esta biblioteca se pueden generar gráficos de barras, histogramas, espectros de potencia, stemplots, scatterplots, gráficos de error, gráficos circulares y muchos otros.\nEs uno de los métodos más simples para las representaciones básicas, está diseñada con la filosofía de que deberías generar un gráfico simple con pocas líneas de código, o simplemente una. Además, se complementa muy bien con otras bibliotecas de análisis de datos, tal es el caso mencionado líneas arriba con pandas.\nSeaborn: es una biblioteca de visualización basada en Matplotlib, permite hacer gráficos estadísticos visualmente atractivos, posee estilos predeterminados y paletas de colores que están diseñados para obtener resultados más estéticos y modernos. Podemos obtener gráficos de barras, histogramas, circulares, gráficos de error, entre otros.\nPodemos encontrar más información de esta biblioteca en su página web.\nBokeh: Es una biblioteca de visualización que permite crear tanto gráficos sencillos como especializados, dashboards y gráficos orientados a la web. Los resultados de las visualizaciones constan de elegancia y son estéticamente atractivos, los gráficos son muy versátiles. Es posible consultar más información acerca de esta biblioteca en su página web.\nTodas estas bibliotecas son de código abierto y cuentan con un soporte en la web, existen foros y varios canales de información sobre ellas. No son las únicas que puedes incluir en tu proyecto, hay muchas opciones más, te invitamos a que explores y pruebes estas herramientas.\nEn nuestro artículo Herramientas de visualización en Python puedes encontrar otras bibliotecas o librerías que te pueden interesar.\n","link":"https://opensciencelabs.org/blog/te-mostramos-cinco-librerias-en-python-para-tu-proximo-proyecto-de-ciencia-abierta/","section":"blog","tags":["datos","visualización de datos","pandas","scipy","matplotlib","seaborn","bokeh"],"title":"Te mostramos cinco librerías en Python para tu próximo proyecto de ciencia abierta"},{"body":"","link":"https://opensciencelabs.org/tags/herramientas/","section":"tags","tags":null,"title":"herramientas"},{"body":" En uno de nuestros artículos, específicamente 10 razones para usar Python en tu próximo proyecto de investigación, se da un recorrido por las ventajas que brinda el lenguaje de programación Python, de allí podemos extraer algunas de sus características tales como:\nPython es un lenguaje de alto nivel, es decir, es un lenguaje de programación muy intuitivo, diseñado de forma tal que el código escrito sea fácil de leer y entender. Con pocas líneas de código se pueden hacer diversas actividades. Es multiplataforma, indicando que se puede ejecutar en distintos sistemas operativos, como: Windows, Linux o Mac OS. Existe una gran cantidad de recursos y apoyo disponibles sobre este lenguaje, a través de grupos de consulta y foros de discusión. Posee un número importante de bibliotecas que reciben mantenimiento y apoyo regular por parte de desarrolladores y usuarios. Estas bibliotecas son utilizadas en diversos campos como la estadística y la ciencia de datos. Tenemos entonces que Python es un lenguaje con características ideales para llevar a cabo proyectos en muchas áreas, cuenta con elementos que lo hacen potente para manipular grandes cantidades de datos y se han desarrollado herramientas que posibilitan, facilitan y hacen su uso más dinámico. En este artículo nos enfocaremos principalmente en describir algunas de las herramientas de visualización sobre este lenguaje; cuando nos referimos a visualización se hace alusión al hecho de ver, observar o captar a través de un gráfico lo que está sucediendo y no vemos a simple vista en los datos.\nUna de las principales herramientas de visualización son las bibliotecas destinadas a ello. Las bibliotecas de visualización son estructuras de código formalmente distribuidas de manera tal que la podemos descargar y utilizar en nuestros proyectos en el que empleamos Python. Las principales ventajas de estas bibliotecas reside en el ahorro de tiempo y el uso de pocas líneas de código al momento de programar. Al ser bibliotecas de visualización nos permiten crear, mostrar y editar uno o varios gráficos a la vez. Recuerda que, en algunos textos encontraremos la palabra librería en vez de biblioteca, se pudiesen usar como sinónimos.\nAlgunas de las bibliotecas más populares en Python para este caso son:\nmatplotlib: Es una biblioteca de visualización que permite realizar visualizaciones estáticas, animadas e interactivas en Python. Con ella se pueden generar gráficos de barras, histogramas, espectros de potencia, stemplots, scatterplots, gráficos de error, gráficos circulares y muchos otros. En su sitio oficial de Internet hay una serie de tutoriales y ejemplos de lo que podemos hacer con ella.\nseaborn: Al igual que matplotlib, es una biblioteca que brinda grandes opciones para realizar gráficos. De hecho, esta biblioteca está basada en matplotlib. La diferencia principal se encuentra en sus estilos y paletas de colores que son más estéticos y visualmente atractivos.\nBokeh: Es una biblioteca de visualización muy completa porque permite hacer cualquier tipo de diagrama gráfico. Es ideal para presentaciones basadas en la web, proporciona la construcción de gráficos elegantes y versátiles de forma concisa. Una de las ventajas importantes de esta biblioteca con respecto a las demás es su capacidad para tener un alto rendimiento ante grandes cantidades de datos. Sus elementos se pueden clasificar en tres grupos importantes:\n1- Gráficos rápidos, son aquellos que se pueden realizar con pocas líneas de código. 2 3- Especialidades de matplotlib, gráficos que modifican y mejoran los gráficos de matplotlib. 4 5- Dirigido a desarrolladores e ingenieros de software. Plotly: Es una herramienta de visualización en línea que ha desarrollado bibliotecas tanto para Python como para R. Es la opción más útil y fácil para crear visualizaciones altamente interactivas en la web (dashboard).\nPygal: Al igual que las bibliotecas que hemos descrito anteriormente Pygal permite realizar cualquier gráfico con pocas líneas de código, esta tiene la particularidad de estar principalmente orientada a la creación de gráficos en formato SVG, lo cual indica que cualquiera de nuestros resultados puede ser editado en un editor de imágenes e imprimirlos en una resolución de muy alta calidad.\nGgplot: Es un conjunto de métodos para graficar basado en GGplot2 de R y la gramática de los gráficos. Los resultados se generan rápidamente y con pocas líneas de código.\nAltair: es una biblioteca de visualización estadística para Python, basada en Vega y Vega-Lite (gramáticas de visualización). Permite construir una amplia gama de visualizaciones rápidamente.\nDe esta forma te dejamos la referencia de algunas de las herramientas de visualización de Python, pero hay otras muchas y puedes conseguir más información en la web. Debes tener en cuenta que a diario podemos encontrar nuevas alternativas y actualizaciones importantes de cada una de ellas. Para hacer uso de las bibliotecas podemos recurrir a interfaces de visualización como Jupyter Notebook, Zeppelin Notebook, Google Colab, entre otras.\n","link":"https://opensciencelabs.org/blog/herramientas-de-visualizacion-en-python/","section":"blog","tags":["visualización de datos","bibliotecas","código","herramientas"],"title":"Herramientas de visualización en Python"},{"body":" Al transcurrir los años se han presentado pandemias que han azotado y puesto en alerta al mundo. Por tal motivo, la manera como las personas, instituciones y gobiernos lo han manejado resulta de suma importancia ya sea para prevenir errores cometidos, tomar medidas similares o reinventarse acciones en el tema. Justo es aquí donde entra en juego la ciencia abierta. Tal vez te preguntarás ¿Cuál es el papel de la ciencia abierta en todo esto? Pues las distintas disciplinas que abarca, como el acceso y los datos abiertos, han permitido producir conocimiento científico para combatir estas pandemias, por ejemplo, para realizar un diagnóstico temprano, en la gestión de la producción de vacunas, o para predecir niveles de propagación de las enfermedades y generar soluciones tecnológicas.\nEn este artículo te presentamos algunas iniciativas de ciencia abierta que han permitido reducir y controlar el impacto de estas enfermedades, la COVID-19, el Zika, la gripe, el dengue, el SARS (Síndrome respiratorio agudo grave) y el MERS (Síndrome respiratorio de Oriente Medio), dejando aprendizajes y avances en este ámbito.\n¿Por qué la Ciencia Abierta? En la actual pandemia de la COVID-19 el acceso a información, la difusión de datos y el uso de código abierto, aceleraron las investigaciones haciendo posible que en pocas semanas se obtuvieran avances significativos, en comparación con aquellos probablemente obtenidos si la información no estuviera abierta. El mejor ejemplo está en el proceso de secuenciación de su genoma, que se logró en solo 11 días publicándose abiertamente, permitiendo conocer sobre formas de transmisión y posibles métodos de detección. Se encuentran disponibles decenas de portales de investigación, revistas y otras herramientas de acceso abierto con información sobre la COVID-19 y su causante, el virus SARS-COV2. Te presentamos algunos en el apartado de referencias.\nAlgunas de esas investigaciones sobre el coronavirus se publicaron de manera abierta antes de tener la revisión por pares, para acelerar los tiempos de difusión del conocimiento. Este tipo de prácticas ya había sido implementada durante las pandemias de SARS en 2003, de gripe AH1N1 en 2009 y el Zika en la década de los 50, pero la evolución de las Tecnologías de Información y Comunicación (TIC) en estos años ha permitido que se implementen con mayor fuerza. De igual forma, la pandemia del Zika estuvo influenciada por el acceso abierto, aunque en menor medida que la COVID-19. Se publicaron en abierto resultados de investigaciones, por ejemplo, la reseñada en Proceedings of the National Academy of Sciences, [este artículo](https://www.elsevier.es/es-revista-revista-colombiana-anestesiologia-341-articulo-zika-una-pandemia-progreso-un-S0120334716300235 y otro publicado en Elsevier.\nComo todavía no hay cura para la fiebre del Zika, el desarrollo de vacunas y la terapia contra el virus es relevante. Sin embargo, en un artículo del 2016 sobre colaboración abierta en respuesta al Zika, se expone la falta de un sistema eficaz para compartir datos e información y hace referencia a una convocatoria para investigadores publicada por la Organización Mundial de la Salud (OMS) en 2015. Actualmente, más de 30 organizaciones han ratificado la declaración de consenso de la OMS para compartir datos del zika.\nPara minimizar la falta de información, El Banco Interamericano de Desarrollo (BID), el Governance Lab y asociados gubernamentales de algunos países de América del Sur colaboraron para llevar a cabo conferencias bajo el nombre de Smarter Crowdsourcing (Colaboración abierta inteligente) buscando especialistas para impulsar una respuesta colaborativa ante la crisis del Zika.\nLos datos juegan un rol importante en el tratamiento de las pandemias, y su procesamiento es fundamental para mantenernos informados. El desarrollo de tableros de monitoreo de casos de COVID-19, mapas con datos en tiempo real, informes dinámicos y otras visualizaciones nos han permitido conocer sobre la propagación del virus. Asimismo con datos de buena calidad, la ciencia de datos puede ser una poderosa herramienta para realizar predicciones sobre la evolución de la enfermedad COVID-19 o incluso para buscar un posible tratamiento. La Universidad de Zaragoza diseña un mapa que predice los nuevos contagios por coronavirus. Asimismo, la compañía de biotecnología AbCellera está empleando un modelo de Machine learning para desarrollar terapias basadas en anticuerpos de pacientes que se han recuperado de la enfermedad.\nModelos predictivos de este tipo también se emplearon en la pandemia del Zika. Uno de ellos desarrollado por el Consejo Nacional de Investigaciones Científicas y Técnicas CONICET en Argentina junto con Ecuador y Colombia en 2019. La investigación incluyó la captura de mosquitos adultos y su análisis genético con la finalidad de aplicar dichos modelos para conocer probabilidades de brotes en áreas particulares y así evaluar posibles acciones preventivas. De igual forma, estos modelos estuvieron presentes en la pandemia de gripe AH1N1, donde un estudio de investigadores de la Escuela Médica de Harvard determinaron que el uso de la Wikipedia y así el empleo de big data, son capaces de predecir con precisión la llegada de los brotes de gripe en EEUU (http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1003581). Puedes consultar información abierta sobre la influenza y las pandemias de gripe, como la gripe aviar y la AH1N1 aquí y también sobre fuentes de información acerca de la gripe aviar en este enlace.\nLos datos abiertos son tomados para desarrollar metodologías que hagan más accesible la información a cualquier persona. De esta manera Google y UNICEF trabajaron en el desarrollo de un panel de control abierto al público sobre el zika, para analizar grandes cantidades de datos, así como para visualizar y predecir brotes potenciales de enfermedades, puedes encontrar información en este enlace.\nLos avances tecnológicos y la influencia de las TIC han cerrado la brecha de la desinformación, aunque en ocasiones su uso hace que se divulgue información poco certera. En este artículo se presenta la influencia de las TIC durante la pandemia de la gripe. Donde algunas iniciativas fueron llevar a cabo cursos virtuales y conferencias durante la pandemia, fue una iniciativa desarrollada por la Organización Panamericana de Salud usando el programa Elluminate que en la actualidad se comercializa bajo el nombre de Blackboard Collaborate. En la actual pandemia de COVID-19 se ha hecho inevitable el amplio uso de estas tecnologías que permiten el teletrabajo y la investigación colaborativa empleando herramientas como Git, redes sociales como Whatsapp, han ayudado a mantenernos comunicados y trabajando.\nOtro aspecto importante es la investigación colaborativa, por ejemplo, en proyectos de código abierto o repositorios de datos. En la pandemia de gripe AH1N1 en 2009 se creó un repositorio en la plataforma colaborativa GitHub acerca de la gripe AH1N1 en Londres. Otros repositorios en esta plataforma referentes a información y proyectos sobre pandemias son: Repositorio de datos sobre los brotes del zika y en https://github.com/cdcepi/zika, el proyecto en GitHub de la app Española Open Coronavirus, que busca tener cuarentenas selectivas en lugar de masivas en España.\nFrente al COVID-19 se han desarrollado proyectos de código abierto,por ejemplo, el proyecto Ushahidi, que proporciona, entre otras cosas, mapas de infectados y lugares donde pueden suministrarse alimentos. Otro iniciativa es eCALLER EPIDEMIAS que cuenta con un despliegue de aplicaciones para el diagnóstico y monitorización. Otra iniciativa han sido hackatones que reúnen a las personas para usar sus habilidades y ayudar a combatir los problemas con la pandemia desarrollando proyectos de tecnología. Uno de ellos, el Hack Quarantine desarrollado, el Debian biohackatone en 2020 y CodeTheCurve. Algunas instituciones tecnológicas han creado fondos para financiar proyectos de código abierto en combate al COVID-19 como el de Mozila.\nLas pandemias del SARS en 2003 y el MERS en 2012, fueron causadas por tipos distintos de coronavirus. Las investigaciones realizadas en la pandemia del SARS influyen ahora en relación al nuevo tipo de coronavirus SARS COV-2 causante de la enfermedad COVID-19, puedes consultar este artículo para más información. Algunos trabajos en acceso abierto puedes consultarlos aquí y en este enlace. Asimismo, se realizaron comparaciones de como el coronavirus SARS-COV2 supera los casos del SARS de 2003 para Enero 2020 y otras investigaciones relacionadas y comparando los 3 tipos de coronavirus causantes de estas pandemias (SARS, MERS y COVID-19), puedes consultar información aquí.\nLas investigaciones iniciadas sobre los coronavirus del SARS y el MERS sirvieron para conocer sobre estos virus y que los científicos e investigadores se dieran una idea de lo que sería el nuevo coronavirus SARS Cov-2. El conocimiento y los datos abiertos relacionados a las anteriores pandemias, permiten que se hagan investigaciones como la de este artículo donde comparan la letalidad del COVID-19, el SARS, MERS y la gripe.\nEl Dengue ha sido otra pandemia para la cual se han llevado a cabo proyectos como un Documento de trabajo sobre datos abiertos del dengue por parte de la Iniciativa Latinoamericana por los Datos Abiertos y el Open Data que presentan mapas de riesgo y de incidencia dinámicos para 18 países de la región de las Américas de la OMS. También está [\u0026quot;DengueNet\u0026quot;](http://ghdx.healthdata.org/record/who-denguenet], el sistema central de gestión de datos de la OMS para la vigilancia epidemiológica y virológica mundial del dengue y la fiebre hemorrágica del dengue. Puedes visitar en este enlace otros sitios de acceso abierto a información sobre el dengue.\nCabe resaltar que la era tecnológica, los avances y los nuevos usos de las TIC afectan y mejoran la forma en la que las personas acceden a la información sobre salud. Esto ha sido fundamental para la ciencia abierta y podemos observarlo si comparamos las iniciativas actuales frente al COVID-19 con las surgidas frente a otras pandemias.\nLo que sabemos hasta ahora De todas las iniciativas de ciencia abierta que se han desarrollado en torno a las pandemias, hemos aprendido a divulgar datos e información, mantenernos actualizados y reconocer información veraz, como la proporcionada por la OMS, a trabajar de forma colaborativa con personas de distintos lugares en el mundo, tomar conciencia de nuestro papel protagónico en el cumplimiento de medidas sanitarias, a hacer uso de herramientas digitales para mantenernos informados y publicar información importante, a tomar decisiones personales y colectivas en base a datos abiertos y herramientas de acceso abierto, en fin, poner en práctica y a disposición nuestras capacidades para generar proyectos que creen soluciones y todos se beneficien de ellas. Asimismo formar parte como usuarios o beneficiarios de esos proyectos y hacer que la práctica de la ciencia abierta sea cada vez más adaptada en la cotidianidad de las personas. También nos han permitido reconocer los avances tecnológicos para la investigación, eliminar las barreras entre investigadores y los ciudadanos de todo el mundo para que, con ayuda de los datos e información disponible, podamos comparar las acciones que se han llevado a cabo y reconocer que la ciencia abierta tiene un rol importante en el ámbito de la salud. Finalmente, debemos decir que las pandemias han hecho que los gobiernos conozcan y actúen de manera rápida y eficiente ante cualquier pandemia y esto ha sido posible, con el transcurrir de los años, gracias a las buenas prácticas de ciencia abierta.\nReferencias Coronavirus: Recursos y conocimiento abierto para colaborar en la respuesta a la pandemia.\nFortaleciendo la respuesta ante el Zika mediante la colaboración abierta.\nAlgunas plataformas de acceso abierto sobre el COVID-19 y el SARS-COV2:\nLiteratura mundial sobre la enfermedad COVID-19 de la OMS\nCanal de noticias de la OMS\nStatista en Español\nDatos del Banco Mundial\nCenter for Control and Prevention of Disease\nEBSCO Medical\nRepositorio de Investigación de Elsevier. En particular este repositorio contiene artículos sobre COVID-19, SARS y MERS, las dos últimas fueron pandemias desarrolladas en la primera década del siglo XXI.\nCentro de Información de Coronavirus de Elsevier\nCentro de Recursos sobre el Coronavirus de The Lancet\nPágina de Investigación de Coronavirus y Enfermedades Infecciosas de la SSRN\nNature Research\nTaylor \u0026amp; Francis\nNew England Journal of Medicine\nLa Universidad de Chile ofrece una web donde guarda enlaces a sitios de acceso abierto sobre información e investigaciones acerca del COVID-19. Visítala en este enlace.\n","link":"https://opensciencelabs.org/blog/que-hemos-aprendido-gracias-la-ciencia-abierta-del-manejo-de-pandemias/","section":"blog","tags":["pandemias","covid19"],"title":"¿Qué hemos aprendido, gracias a la ciencia abierta, del manejo de pandemias?"},{"body":"","link":"https://opensciencelabs.org/tags/pandemias/","section":"tags","tags":null,"title":"pandemias"},{"body":"","link":"https://opensciencelabs.org/tags/citas/","section":"tags","tags":null,"title":"citas"},{"body":"","link":"https://opensciencelabs.org/tags/metadatos/","section":"tags","tags":null,"title":"metadatos"},{"body":"","link":"https://opensciencelabs.org/tags/referencias/","section":"tags","tags":null,"title":"referencias"},{"body":" En el proceso de escritura de un artículo científico, o documentación de un proyecto, siempre se busca optimizar el uso del tiempo dedicado a la transcripción y elaboración de los documentos y presentaciones del trabajo, así como en tareas como la elaboración de citas y referencias para artículos entre otros. Aunque el uso de herramientas de procesamiento de texto facilita bastante la tarea de compartir y escribir el trabajo, aun así se suele tener que configurar manualmente cosas tales como indices, código insertado dentro del texto, formulas matemáticas… y citas. Esto se complica un poco más pues, dependiendo de la forma en la que estés publicando tu artículo, todas estas tareas pueden tener formatos muy distintos.\nEn el caso de las citas y referencias, existe una variedad nada despreciable de estándares dependiendo, entre otras cosas de si se deben colocar al final de la página, al final del documento o después del texto citado y, además, en que formato escogido para presentarlas, en que orden se deben introducir cada uno de sus elementos, entre otros. Esto se puede tornar bastante tedioso, en especial si tienes un gran numero de citas y referencias que colocar, si provienen de una variedad de formatos y lugares diferentes, si la información es incompleta, por ejemplo en año o nombres completos de autores, si cuentan o no con metadatos adecuados, entre otros. Simplemente esta tarea de buscar, ordenar y insertar estos datos puede tomar bastante tiempo si no se utilizan las herramientas o programas adecuados.\n¿Nunca te has preguntado si podrías simplemente añadir las citas en cuanto las ves en un sitio o en un documento? O, simplemente, ¿si podrías automatizar la búsqueda de metadatos por Internet de alguna forma, saltando de largo todo este tedioso procedimiento? A pesar de que existen varias alternativas, una de las aplicaciones más llamativas en cuanto a la organización de fuentes de investigación se refiere, es Zotero. Esta aplicación es un completo manejador de referencias que se conecta directamente con tu navegador, mediante una extensión, para descargar archivos y organizarlos de forma automática y directa, al tiempo que se integra también con tu editor de texto preferido. Zotero además permite organizar citas, referencias, fuentes y archivos, pues tiene la capacidad de guardar información extraída desde sitios web, capturando tanto el origen de los datos como su año, autor, DOI, entre otros.\n¿Como funciona Zotero? Zotero es una aplicación disponible tanto para teléfono como para tu ordenador, que se conecta a tu navegador mediante una extensión disponible para instalar desde su página web. Sin importar cuál navegador utilices (ya sea, Firefox, Chrome, o Safari), o mediante un marcador (Zotero Bookmarklet) que guarda elementos en Zotero en cuanto lo cargas. Actúa como un organizador y manejador de archivos y otros elementos como libros, artículos, reportes, manuscritos, sonidos guardados, casos, entre otros, y está principalmente orientado a guardar y citar referencias bibliográficas. Por ello, presta especial atención al almacenamiento de metadatos referentes a éstos, permitiendo su clasificación en conjuntos que llama «colecciones», para organizarlos según tema, proyecto o cualquier otro criterio que establezcas, permitiéndote etiquetarlos, añadir notas o sub-ítems, entre otros.\nLa conexión de Zotero al navegador, te permite añadir cualquier archivo que estés visualizando directamente a tu colección. Al hacer click en la extensión de Zotero, te permitirá guardar el sitio web, archivo o documento que estés viendo en el momento. Si se trata de una imagen, sonido o video, el botón derecho del ratón te permitirá integrarlo inmediatamente en tu colección de Zotero como un elemento. Además, existen traductores diseñados para extraer los metadatos de sitios web particulares, en especial aquellos de uso popular y aquellos relacionados con la investigación científica, incluyendo catálogos de librerías, bases de datos, sitios de noticias y catálogos de tiendas, entre otros.\n¿Como se utiliza Zotero? Zotero requiere ser instalado en tu ordenador antes de poder ser utilizado. Es software multiplataforma y de código abierto, así que funcionará en tu sistema operativo sin problema alguno. Después de esto, ya está listo para usar. Si deseas integrarlo a tu navegador, necesitarás instalar la extensión adecuada, para disfrutar de las funcionalidades adicionales. La interfaz funciona como un organizador de archivos cualquiera, con un árbol de carpetas a tu izquierda (las colecciones), los ítems dentro de estas colecciones a tu izquierda, y los metadatos de estos ítems a tu derecha.\nAñadir nuevos ítems es muy sencillo: simplemente se crea una nueva colección, con el botón derecho del ratón en la sección de la derecha, y en esta colección puedes añadir ítems de distintos tipo mediante un botón ubicado en la zona central de la barra superior. Al seleccionar ítems dentro de la colección, puedes empezar a llenar metadatos en la sección derecha. Cuando agregas archivos de tipo .pdf a Zotero, este intentará automáticamente buscar los metadatos correspondientes mediante Internet, y si añades artículos a Zotero mediante la varita mágica (con su identificador DOI, ISBN o similar), este automáticamente lo clasificará y buscará título, autores, año de publicación y demás datos e información relevantes sobre el documento.\nUtilizar Zotero es una cuestión muy sencilla, no requiere de practica y cualquier duda que tengas respecto a las particularidades de su funcionamiento se pueden resolver mediante una busqueda en el manual de éste. Sin duda se trata de una herramienta muy útil que te ayudara a acelerar tu trabajo de muchas maneras, ya sea simplemente para organizar tu material de estudio o para hacer citaciones en tus artículos mediante complementos que conecten con Zotero para tu procesador de texto favorito.\n","link":"https://opensciencelabs.org/blog/si-pensado-en-como-automatizar-la-construccion-de-citas-en-tu-proyecto-te-contamos-como-hacerlo-posible/","section":"blog","tags":["proyectos","citas","referencias","zotero","metadatos"],"title":"Si has pensado en cómo automatizar la construcción de citas en tu proyecto, te contamos cómo hacerlo posible."},{"body":"","link":"https://opensciencelabs.org/tags/zotero/","section":"tags","tags":null,"title":"zotero"},{"body":" Si trabajamos en una empresa o institución pública o simplemente queremos ver el comportamiento de nuestros datos, podemos pensar en realizar uno o varios gráficos. Los gráficos son representaciones visuales de los datos que nos permiten comprenderlos, compararlos, analizarlos y describirlos de forma tal que se tenga una noción más clara de lo que ocurre con ellos.\nEn este artículo nos centraremos en los dashboards que son representaciones gráficas de los datos. Como representaciones de gráficos, pueden estar conformadas por una o varias visualizaciones con la particularidad de ser o no interactivos. Los dashboards son utilizados principalmente para ver y evaluar la calidad de un negocio o el cambio de algunos valores específicos a través del tiempo. También permite observar el comportamiento de alguna variable y sugerir estudios más profundos en relación a lo que sucede.\nYa te habíamos mostrado, en el artículo Te hablamos del uso de dashboards para visualización de datos de tu próximo proyecto. En ese artículo, definimos los dashboards como:\nLos dashboards son herramientas de manejo de información que se vinculan entre sí a través de APIs, servicios, librerías y código de una manera dinámica por 'debajo' de la interfaces de usuarios, es decir, mostrando los resultados de esta interacción en una interfaz web o aplicación móvil, a través de gráficos y visualizaciones que al instante presentan los llamados indicadores de rendimiento (Key Performance Indicators KPI por sus siglas en inglés), o cualquier otro tipo de indicadores, acerca de un negocio, proceso, departamento, sitio web, o servidor. Prácticamente cualquier cosa que necesite ser monitorizada de forma constante puede utilizar los dashboards. Debido a su naturaleza como frontend, son completamente personalizables para cualquier propósito al que los quieras aplicar, sólo hace falta crear los scripts necesarios para hacerlo.\nAhora, ¿Qué es lo primordial para elaborar un dashboard?\nPara elaborar dashboards son necesarios los datos, estos serán la materia prima que permitirá crearlos. Debemos tener en cuenta que los datos puedan almacenar la información que deseamos extraer o contabilizar. Una vez que se tengan disponibles los datos se debe tener claro cuáles son las variables o valores que se desean estudiar y así trazar un plan en el que se definan los tipos de gráficos que serán presentados en los dashboards.\nPor otro lado, se deben definir las herramientas que utilizaremos para su elaboración. De estas herramientas existen varias: desde una hoja de cálculo hasta aplicaciones de software especializado. En el caso de software libre y código abierto, existen bibliotecas que permiten crear dashboards de manera rápida y sin muchas líneas de código. Por mencionar algunas están Bokeh y Plotly que son librerías de código abierto para Python. En la sección frameworks y librerías diseñadas para dashboards del artículo Te hablamos del uso de dashboards para visualización de datos de tu próximo proyecto encontrarás una descripción un poco más amplia de las herramientas que se pueden emplear para esta elaboración.\n¿Qué es la integridad en los datos? y ¿cuál es su importancia en los dashboards?\nLa integridad en los datos se refiere a su fiabilidad, es decir, a que la información que muestran sea exacta, completa, homogénea, sólida y coherente. Al tener integridad en los datos es muy probable que la información que se obtenga a través de estos sea verídica y muestre la realidad.\nPor ello, es de gran importancia que los datos involucrados en la creación de los dashboards tengan integridad. Permitiendo de esta manera presentar gráficos claros, sin sesgos o alteraciones, se evitarían posibles problemas de interpretación y la toma decisiones basadas en esta información es más confiable.\nOtro aspecto que brinda la integridad de los datos en los dashboards es la facilidad para agrupar la información y la segmentación de lo que puede o no ser relevante.\nTengamos en cuenta que la integridad de los datos se ve alterada en el momento en que un valor en el conjunto de los datos ha sido modificado por equivocación, se ingresa uno o varios datos erróneos o si simplemente fue alterado por alguna circunstancia asociada al proceso de su obtención. Para prevenir esto es importante la supervisión del proceso de obtención de los datos así como su correcta depuración o pre-procesamiento.\nEn resumen tenemos que los dashboards son una excelente herramienta para describir los procesos que ocurren con los datos, pero para ello es vital que estos últimos sean tales que contengan la mayor información, sean fiables de manera que cuenten con integridad para así lograr el objetivo de describir y tener mayor visión de lo que en verdad ocurre.\nLos dashboards son clave en la visualización de datos. Debemos ser consientes de que un dato puede ser simplemente un valor, pero descubrir lo que este significa puede causar impacto, mover o cambiar procesos cuando se requiera, en una en un proyecto, en organización, en una comunidad o hasta en un país.\n","link":"https://opensciencelabs.org/blog/la-importancia-de-la-integridad-en-los-datos-manejados-en-los-dashboards/","section":"blog","tags":["datos","dashboard","herramientas","código"],"title":"La importancia de la integridad en los datos manejados en los dashboards"},{"body":"","link":"https://opensciencelabs.org/tags/free-software/","section":"tags","tags":null,"title":"free software"},{"body":"","link":"https://opensciencelabs.org/tags/licencia/","section":"tags","tags":null,"title":"licencia"},{"body":" ¿Cómo proteger tus proyectos, tu código y tu labor si dejas que cualquiera con acceso a Internet la acceda y utilice tal como desee? En GitHub están alojados millones de proyectos cuyo código es reutilizado de cualquier manera y en proyectos de cualquier tipo, sin que el programador pueda controlarlo. ¿Cómo podría un desarrollador promedio resguardarse de un posible abuso, para tomar medidas de seguridad, o para evitar que otro se beneficie de su labor sin saberlo? Es aquí donde, en el desarrollo de software, entran las licencias de software, y es aquí donde, por múltiples razones (transparencia, reproductibilidad, libertad de acceso, mayor eficacia durante el desarrollo, entre otras), nos interesan sobre todo aquellas licencias de código abierto, ya que hacen posible el desarrollo de muchas prácticas de la ciencia abierta.\nEstablecer una licencia para los productos de tu investigación, permite hacer saber a otras personas qué es lo que pueden (o no) hacer con tu trabajo, y divulgar las pautas bajo las cuales se puede interactuar con la investigación y el equipo que la desarrolla. Por lo tanto, es imperativo para cualquier institución o individuo que sea parte de una comunidad de ciencia abierta, conocer a fondo las licencias más apropiadas y utilizadas por más personas, y cuáles son sus restricciones y aplicación según qué tipo de proyectos beneficien más, las comunidades que apoyan a estas licencias entre otros aspectos muy importantes sobre el licenciamiento de proyectos de ciencia abierta, además de tener en mente cómo se va a usar la investigación realizada en el futuro, ya sea si ésta se va a usar para fines lucrativos o si se espera que los demás utilicen licencias similares al reproducirla, modificarla y/o utilizarla en el futuro.\n¿Qué tipos de licencias existen?\nEn el mundo del software libre, por lo general, se entiende que toda licencia abierta permite tanto el libre acceso y uso del software, como su distribución y modificación. En términos mas detallados, las licencias de software libre, en términos generales, establecen la condición de que los desarrollos se adecúen a los diez criterios establecidos por la Open Source Definition (o similares, como aquellos que propone la Free Software Foundation). Estos criterios protegen tanto el derecho de los usuarios de modificar, ya sea mediante parches o modificación directa del código desarrollado, y redistribuir el software, como el del autor de proteger la integridad de su labor. Por supuesto, una licencia puede exigir restricciones adicionales de parte del usuario, como en el caso de una licencia copyleft, que requiere que los proyectos derivados utilicen la misma licencia que el trabajo original, contrastado con las licencias \u0026quot;permisivas\u0026quot;, que no tienen este requerimiento.\nCuales son las licencias mas utilizadas?\nEn proyectos de ciencia abierta y en muchos otros espacios, las artes, el desarrollo de software, la divulgación de noticias y información, así como prácticamente cualquier ámbito que utilice el derecho de autor, existe un movimiento que agrupa un conjunto de licencias que van ganando progresivamente adeptos. Con una comunidad activa, sin duda porque también involucra directamente políticas y proyectos relacionados con el apoyo y promulgación de la ciencia abierta, es la licencia Creative Commons. A pesar de que esta inicialmente se aplicaba en la esfera de las artes, desde el 2005 esta organización se empezó a involucrar en proyectos científicos, mediante el programa Science Commons.\nEstas licencias permite a quien las utilice, escoger entre cuatro \u0026quot;condiciones de licencia\u0026quot;. Las modalidades de licencias Creative Commons dependen de: si se debe siempre acreditar al creador original (CC BY), si siempre se debe usar la misma licencia al redistribuir y modificar el trabajo (CC BY-SA), si es únicamente para uso sin fines de lucro (CC BY-NC), o si no se permiten trabajos derivativos (CC BY-ND). Utilizar una licencia CC BY es una opción para la publicación de investigaciones científicas financiadas por el público, para las cuales se espera que sea libremente reutilizable y accesible para cualquiera, o forme parte del programa de libre acceso de algunos gobiernos, como el del Reino Unido.\nUna de las licencias en las cuales probablemente estén publicados programas que, directa o indirectamente, utilizas a diario es la licencia GNU GPL v3.0. Esta es un tipo de licencia copyleft que \u0026quot;garantiza tu libertad para compartir y cambiar todas las versiones de un programa-para asegurarse que sigue siendo software libre para todos los usuarios\u0026quot;. Esto lo hace ideal para mantener la integridad de tu software sin necesidad de hacerlo propietario. Esta es usada en una variedad de programas, tales como GIMP, WordPress, Audacity, el kernel de Linux, entre otros. Diametralmente opuesta a ésta es la licencia BSD, la cual apunta a imponer un mínimo de restricciones en el uso y redistribución del software, siendo minimalista y concisa en su aplicación. Por supuesto, esta es usada en las distribuciones BSD de Linux, ya que forman parte de la misma organización.\nLa licencia que en el 2015 era la mas utilizada en Github, es la licencia MIT, cuyo nombre está tomado de la institución donde se creó. Principalmente se caracteriza por ser una licencia permisiva y compatible con bastantes otras licencias. A pesar de ser una licencia de software libre, permite a los desarrolladores re-licenciar sus programas para que sean propietarios si estos son publicados bajo la licencia MIT, aunque por supuesto, también se podrían reintegrar en una licencia como la GPL con igual facilidad. Si has usado alguna distribución de Linux, ya has utilizado un programa publicado bajo la licencia MIT: el sistema de ventanas X. Publicado también bajo la misma licencia esta node.js, un framework de dashboards de los cuales se derivaron muchos mas.\nFinalmente, queremos recordarte que la decisión de escoger una licencia depende de cuales restricciones sean absolutamente necesarias para tu proyecto, y intentar permitir la mayor cantidad de libertades sin sacrificar la integridad y metas de tu trabajo. De la licencia utilizada pueden surgir problemas legales o de seguridad, por lo que es importante revisar con calma cual es la mejor opción y tener claro junto a todos los miembros del equipo bajo que términos se esta trabajando.\n","link":"https://opensciencelabs.org/blog/te-hablamos-de-las-licencias-mas-utilizadas-en-proyectos-de-ciencia-abierta/","section":"blog","tags":["licencia","proyectos","free software"],"title":"Te hablamos de las licencias mas utilizadas en proyectos de ciencia abierta"},{"body":" Para hacer reproducible una investigación y que ésta pueda ser verificada a largo plazo, debes contar con un registro donde tomes nota de todos los pasos realizados durante este proceso, lo cual servirá, al mismo tiempo, para que tu proyecto sea comprensible por personas ajenas a él y así puedan desarrollar algún interés sobre el mismo. A todo el proceso de registro de esa información se le conoce como Documentación.\nLa documentación es una buena práctica de la investigación y es de suma importancia en cualquier proyecto de ciencia abierta. Si no documentamos, al pasar el tiempo las personas tendrán que comenzar de cero y terminarán sin entender el contenido de nuestro proyecto. Además, estando bajo los estándares de la ciencia abierta, el «no documentar» sería una falta grave a sus principios.\nDe una manera un poco formal, podemos decir que la documentación es un proceso o una práctica que consiste en registrar y/o informar sobre la ejecución de ciertas tareas en algún tema determinado. La documentación de un proyecto se fundamenta, en última instancia, en la realización de varios documentos explicativos que van a depender del alcance y la temática del proyecto en desarrollo.\nEn cualquier proyecto de ciencia abierta que desarrolles o participes, debes tener presente la importancia de contar con una buena documentación que respalde e informe las labores durante todo el proceso, es decir, un registro de actividades, herramientas y recursos que comprende desde la conceptualización del proyecto, planificación, recolección de los datos, herramientas computacionales y recursos utilizados, la metodología del procesamiento de los datos, los resultados, cuadernos de investigación y otros. Esto quiere decir que, en general, debes documentar toda la metodología utilizada en el desarrollo del proyecto, es decir, la manera cómo se va a realizar cada paso dentro de la misma, incluyendo los resultados.\nEn lo que respecta a los datos, es necesaria información descriptiva de los conjuntos de datos utilizados, el código informático resultante de su procesamiento estadístico (puedes usar Jupyter para juntar el código informático con texto), las pautas de la gestión de datos (o propiamente un Plan de Gestión de datos) donde se reflejen la normativa para hacer que el proyecto se lleve a cabo bajo los estándares de la ciencia abierta (plataformas de acceso abierto empleadas para la disponibilidad de los datos, licencia utilizada, entre otras). En pocas palabras te recomendamos el registro de toda la información referente a la investigación para lograr, además, que los datos de investigación cumplan los principios FAIR, es decir, sean localizables, accesibles, interoperables y reutilizables.\nEl proceso de documentación generalmente lo lleva a cabo solo una persona y lo comparte con las demás, o se reparten esta tarea entre varios miembros del proyecto. Sea cual sea la persona que lo hace, los documentos varían a lo largo del tiempo y como deben estar compartidos, te recomendamos usar cualquier opción para el control de versiones con Git para centralizar la información, implementando también otra herramienta para la gestión de los documentos como Sphinx.\nLa documentación de un proyecto de ciencia abierta, en general, debe estar estructurada de la siguiente manera: una introducción de todos los apartados de la documentación y que sirva como una visión general de todo el contenido incluyendo el problema, enfoque, objetivos, requisitos y producto final. Debe incluir un desglose de las funciones que cada persona tiene dentro del proyecto y las tareas que debe realizar para cumplir los objetivos propuestos, con fechas tentativas de entrega de resultados para llevar un control efectivo de las tareas y sus datos de contacto. Asimismo debe incorporarse en el documento información referente a las herramientas informáticas utilizadas en el proyecto, el tipo de licencia asignada al proyecto, el lugar donde se guardarán los datos (según corresponda) del proyecto, siempre cumpliendo con los principios de la ciencia abierta. Y no debes olvidar incluir toda la información referente a los conjuntos de datos, código informático generado y los resultados obtenidos.\nLa documentación no sólo es importante para la reproducibilidad sino que también aumenta la probabilidad que las personas ajenas al proyecto puedan entenderlo, interesarse en él y, además, realizar aportes. Si, por ejemplo, se está ejecutando un proyecto de desarrollo, la documentación del código es muy importante para que, pasado el tiempo, el mismo equipo de desarrollo pueda recordar lo que hicieron en algún momento o intentar replicar el código escrito por otros. Información adicional sobre la documentación en este tipo de proyectos puedes consultarla en este post sobre Documentación con Sphinx y Python.\nA continuación, te dejamos tips y comentarios adicionales que consideramos pueden ser útiles para elaborar la documentación de tu proyecto de ciencia abierta:\nSi estás en un proyecto y no has comenzado a documentarlo te recomendamos que empieces pronto, la documentación aunque es un proceso que requiere dedicación y tiempo, al final te ahorrará muchos inconvenientes.\nResulta más fácil documentar el material de un proyecto, si se hace en correspondencia con cada etapa del proceso.\nSi necesitas hacer visible tu proyecto, en muchas ocasiones, es una buena práctica documentar en inglés, debido a la gran cantidad de investigaciones y organismos financiadores que se encuentran en países de habla inglesa.\nAl momento de documentar debes usar un lenguaje claro y comprensible. El documento final debe ser lo suficientemente extenso para especificar todas las características del proyecto pero también contar con la mayor precisión posible.\nCuando documentes, todo debe estar detallado, no deben existir las obviedades. Cosas que para ti son obvias, no lo son para los demás.\nLos documentos deben estar escritos empleando un lenguaje adecuado para las personas que lo utilizarán.\nLa documentación puede incluir todos los gráficos, bosquejos y esquemas que ayuden a complementar la información.\nEn líneas generales, la documentación te ayudará a organizar las tareas, delegar funciones, establecer fechas y tener un control sobre la metodología, recursos y resultados antes, durante y después de la finalización del proyecto. Asimismo servirá de soporte, permitirá su trascendencia en el tiempo y facilitará su reproducción o replicación En OpenScienceLabs te animamos a que comiences a documentar tu proyecto y que tomes en cuenta esta buena práctica para futuros desafíos.\nReferencias Manual de Capacitación sobre Ciencia abierta Guía de expertos en Gestión de Datos 5 reglas básicas y 5 pasos para documentar tu proyecto web\n","link":"https://opensciencelabs.org/blog/como-documentar-tu-proyecto-de-ciencia-abierta/","section":"blog","tags":["proyectos","documentación"],"title":"¿Cómo documentar tu proyecto de ciencia abierta?"},{"body":"","link":"https://opensciencelabs.org/tags/documentaci%C3%B3n/","section":"tags","tags":null,"title":"documentación"},{"body":" La enfermedad COVID-19 causada por el coronavirus SARS-CoV-2 actualmente es una pandemia mundial. Por tal motivo su prevención resulta sumamente importante, y para esto es indispensable nuestra participación activa como ciudadanos. El rápido aumento de casos de COVID-19 ha llevado a personas de distintos lugares a organizarse en proyectos de ciencia e inteligencia colectiva o ciudadana para enfrentar esta enfermedad. Puedes consultar más información sobre ciencia ciudadana en nuestro artículo Qué es ciencia ciudadana (enlace a artículo queescienciaciudadana).\nEn este post mencionamos algunas iniciativas de ciencia e inteligencia ciudadana que se han desarrollado en distintas partes del mundo, relacionados con la atención al COVID-19:\nFrena la curva Es una plataforma ciudadana desarrollada para canalizar y organizar la energía social y la resiliencia cívica ante el Covid-19. Nació como una iniciativa del Gobierno de Aragón y luego se convirtió en una plataforma ciudadana donde participan gran cantidad de voluntarios, activistas, emprendedores, empresas, organizaciones y laboratorios públicos de innovación abierta provenientes de España y Latinoamérica.\nFrena la curva se originó como una respuesta de la sociedad civil sirviendo de complemento a las medidas gubernamentales. En esta plataforma los ciudadanos aprenden, comparten consejos y ayudan a otros a prevenir la enfermedad. Conoce más en https://frenalacurva.net/.\nAlgunos proyectos en Barcelona-España Barcelona desde casa Este proyecto nace de la rápida organización de la ciudadanía, agrupa distintas iniciativas en cuatro ámbitos: cuidados colectivos y apoyo mutuo, cultura, recursos educativos y para hacer deporte en casa. Algunas de ellas son: fondo documental de las bibliotecas, equipamientos culturales y festivales literarios, foro de experiencias y emociones, compartir ejercicios para hacer en casa, juegos, recetas de cocina y otras actividades.\nBarcelona desde casa ofrece también recursos digitales en abierto para que las personas puedan acceder durante los días de aislamiento, busca ser compartida con la familia, amigos y/o vecinos. La iniciativa estará activa mientras duren el período de excepcionalidad y las medidas de aislamiento en España.\nBarcelona Cultura Es una plataforma digital accesible desde https://www.barcelona.cat/barcelonacultura/es, donde se muestran y difunden actividades que mantienen presente el tejido cultural y el\nespíritu de los equipamientos públicos y privados de la ciudad, así como las iniciativas culturales individuales. Aquí se observan actividades donde se informa sobre museos, recursos literarios, blibliotecas, entre otras.\nProyecto Radars Es una iniciativa comunitaria que tiene como propósito mejorar la calidad de vida de las personas mayores, ofreciéndoles soluciones para una parte de sus necesidades cotidianas. Los voluntarios son personas que no forman parte de colectivos de riesgo y prestan apoyo en actividades como: llevarles los alimentos cuando van a comprar, sacar la basura, pasear perros, entre otras. Si deseas consultar más información, visita https://ajuntament.barcelona.cat/serveissocials/ca/canal/projecte-daccio-comunitaria-radars.\nCovid-19 SG Es una web que muestra información de Singapur sobre los casos de infección, la calle donde vive y trabaja la persona infectada, el hospital al que ingresa, el tiempo promedio de recuperación, entre otros detalles. Es una iniciativa del gobierno el cual ha adoptado el enfoque abierto sobre los datos oficiales de las infecciones y manifiesta que esta es la mejor manera de ayudar a las personas a tomar decisiones y controlarse frente al Covid-19. Puedes acceder a esta información en https://co.vid19.sg/.\nMinería en redes sociales Ciudadanos de China y Hong Kong actúan ante la información poco fiable sobre el Covid-19. Estas personas han estado archivando y traduciendo datos de relatos personales de las redes sociales (Weibo, WeChat y Douban) desde China para crear crónicas de testimonios de los afectados, antes de que sean censurados por el gobierno, ya que no hay prensa libre. Luego de seleccionada y contrastada la información con fuentes oficiales o noticias creíbles, proceden a traducirlas o subtitularlas al inglés y las publican en plataformas como Imgur, Reddit, Twitter y YouTube.\nTambién han creado grupos de WhatsApp y Telegran para mantener comunicadas a las personas ante la desconfianza de las fuentes oficiales. Otras personas han desarrollado un mapa en vivo del virus, junto con los titulares de las principales fuentes de noticias. Accede a información más completa en https://www.technologyreview.com/2020/02/02/349163/coronavirus-china-wuhan-hong-kong-misinformation-censorship/.\nJuego de rompecabezas La Universidad de Washington adoptó un enfoque innovador para combatir el Covid-19. Creó un juego de rompecabezas en el cuál el jugador debe construir una proteína que pueda bloquear el virus para que no se filtre en las células humanas, lo puede jugar cualquier persona, científicos y público en general. Las ideas generadas por el juego que se consideren mejor fundamentadas, serán probadas y posiblemente fabricadas por el Instituto de Diseño de Proteínas de esta Universidad. Más información en: https://www.geekwire.com/2020/university-washington-coronavirus-puzzle-game-aims-crowdsource-cure/\nChatbot Carina Es un asistente virtual basado en inteligencia artificial, desarrollado en España por la empresa 1MillionBot para atender a millones de personas sobre inquietudes acerca del Covid-19. Aparte de España, otros países como Colombia, Chile o Guatemala se han unido a Carina para fomentar la difusión de información sobre coronavirus. El chatbot contesta preguntas básicas y algunas especializadas con respecto a contagio, síntomas, prevención y medidas derivadas de la alarma del gobierno.\nCarina está a disposición de cualquier organismo público y entidades que lo soliciten para contar con ella en sus páginas web o servicios de información. La base de datos que maneja Carina está basada en información de la Organización Mundial de la Salud (OMS), el Ministerio de Sanidad y normativas gubernamentales, el Center For Disease, Control and Prevention, artículos científicos e información de artículos de prensa certificados. Encontrarás información adicional sobre Carina en https://1millionbot.com/chatbot-coronavirus/\nOpenWHO Es una plataforma interactiva de la OMS que proporciona cursos en línea a las personas que trabajan o se preparan para trabajar en epidemias, pandemias y emergencias sanitarias. La plataforma cuenta, entre otros, con un canal llamado COVID-19 que brinda recursos de aprendizaje para los profesionales de la salud, los responsables de la adopción de decisiones y el público en general sobre esta enfermedad. Encuéntralo en https://openwho.org/channels/covid-19.\nDe acuerdo a la evolución de la enfermedad la plataforma actualizará los cursos, los cuales están disponibles en varios idiomas en el canal de idiomas nacionales de COVID-19 en la misma plataforma.\nAyuda Innovadora a la Respiración (AIRE) Es un foro Español donde los participantes recopilan información, en forma colectiva, en búsqueda de alternativas de código abierto, fáciles de fabricar y baratas para desarrollar sistemas de ventilación en pacientes con COVID-19. El proyecto surge como una actividad solidaria totalmente desinteresada y es similar a otras ideas como Open Source Ventilator.\nAl foro se han ido incorporando muchos voluntarios, como ingenieros, fabricantes, emprendedores y médicos. Encuentra más información en https://foro.coronavirusmakers.org/.\nFinalmente, destacamos que la ciencia e inteligencia ciudadana está siendo un gran método para luchar contra el COVID-19, empleándose en todo el mundo por comunidades y gobiernos para dar respuesta a esta situación. Te animamos a que seas partícipe de cualquier proyecto de ciencia ciudadana en tu comunidad, o te permitas emprender uno propio.\nReferencias Proyecto Frena la Curva\nDecidim Barcelona\nBarcelona Cultura\nProyecto Radars\nCovid-SG\nJuego de rompecabezas Universidad de Washington\nChatbot Carina\nOpenWHO\nAIRE\n","link":"https://opensciencelabs.org/blog/algunos-proyectos-de-ciencia-e-inteligencia-ciudadana-para-atender-la-pandemia-del-covid-19/","section":"blog","tags":["covid19","proyectos","ciencia ciudadana"],"title":"Algunos proyectos de ciencia e inteligencia ciudadana para atender la pandemia del COVID-19"},{"body":"","link":"https://opensciencelabs.org/tags/ggmap/","section":"tags","tags":null,"title":"ggmap"},{"body":" Sin duda, los datos deben considerarse como la materia prima para cualquier proyecto de ciencia abierta, pues todos se basan en el manejo de datos de distintos tipos. Para entender esos datos debe realizarse una inspección visual de su comportamiento. Esto se conoce como Visualización de Datos, que consiste en generar representaciones gráficas de las variables que componen un conjunto de datos para obtener información fácilmente interpretable de lo que ellos nos quieren decir y así, poder comunicarla de una manera asertiva.\nLa visualización es un método de exploración de datos que muestra, de una mirada, algunas cosas que de otra forma hubiese sido muy difícil observar. Por tanto, se suele realizar al comienzo de cualquier análisis estadístico formal o para la presentación de resultados en informes descriptivos de datos. La visualización de datos se ve grandemente influenciada por su calidad y capacidades de las herramientas computacionales y software estadísticos utilizados para ello. Es aquí donde la decisión del analista de datos por escoger entre uno u otro lenguaje de programación y/o paquete estadístico es sumamente importante.\nEn esta oportunidad, te hablamos de las capacidades para la visualización de datos que posee el Lenguaje estadístico R.\nR es fundamentalmente un lenguaje de análisis estadístico y, por tanto, tiene en su librería \u0026quot;base\u0026quot; soporte incorporado para gráficos. Otras funcionalidades avanzadas se incorporan mediante la instalación de paquetes encontrados en https://cran.r-project.org y son generados por una gran comunidad activa de desarrolladores de R. Puedes acceder a más información que te proporcionamos acerca de R en nuestro artículo ¿Qué es el Lenguaje R y cómo puede ayudarte en tus proyectos?.\nR posee una Galería de gráficos, esto es una colección de gráficos hechos en R, cuyos ejemplos están basados mayormente en el uso de tidyverse y ggplot2. En ella se muestran cientos de gráficos con su código reproducible disponible. Cualquier persona puede sugerir un gráfico o informar de errores.\nEn cuanto a la parte de generación de gráficos, en R existen dos motores gráficos, esto se trata de una serie de funciones que permiten realizar manipulaciones gráficas básicas: como: trazar líneas, dibujar puntos, curvas, entre otros elementos. Estas funciones no son manejadas directamente por los usuarios, si no utiliza funciones de alto nivel (como la función plot). Estos motores son: \u0026quot;El motor tradicional o base de R\u0026quot; y \u0026quot;El motor grid\u0026quot;.\nLas funciones básicas de R para gráficos como, plot, hist, boxplot y otras, están desarrolladas bajo el motor tradicional de R. No obstante, para construir otro tipo de gráficos no es suficientemente adecuada. Por tal motivo, Paul Murrell desarrolló el motor grid.\nAlgunas consideraciones sobre el motor tradicional de R En su paquete base R cuenta con varias funciones para la producción de gráficas, la mayoría de las cuales se encuentran en el paquete graphics. Algunas de las funciones son:\nplot() por defecto realiza un diagrama de dispersión. Si se cambia el argumento type, permite realizar, por ejemplo, gráficos de líneas o series de tiempo, entre otras.\nhist() para un histograma.\nbarplot() permite hacer un gráfico de barras.\nboxplot() para un diagrama de caja y bigotes.\npie() o piechart() gráfico circular o de sectores.\nPara todos los gráficos que se pueden hacer bajo el motor tradicional de R, se pueden fijar múltiples elementos, algunos son: márgenes, espacios, títulos, colores, tipos de marcadores, grosor de líneas. Además de los gráficos mencionados anteriormente, también se pueden realizar gráficos de coordenadas polares, eventos, pirámides de edades, matrices de dispersión, gráficos de independencia y de estrellas, realizar combinaciones de gráficos, colocar curvas a histogramas, efectos de sombreado. También se pueden obtener gráficos para representar la salida de un modelo estadístico como: regresión lineal simple, análisis de componentes principales, series de tiempo, cartas o diagramas de control.\nEsos gráficos pueden ser almacenados para su posterior reutilización en cualquier tipo de documento. Para lo cual se usa el paquete base grDevices que permite aplicar funciones de dispositivos gráficos como pdf() y png().\nA continuación daremos una descripción breve sobre algunos paquetes útiles para la visualización de datos en R.\nlattice El paquete fue escrito por Deepayan Sarkar con el objetivo de mejorar los gráficos básicos de R, proporcionando mejores valores por defecto y tiene la capacidad de mostrar, de una manera fácil, las relaciones multivariantes. Está desarrollado bajo el motor gráfico grid. Con este paquete puedes realizar los gráficos trellis, que describen situaciones complejas (mayormente multivariantes) como la relación entre variables condicionada a una o más variables, representándolo en un sólo gráfico organizado en paneles. Además, tiene la funcionalidad para generar gráficos en 3D, puedes consultar la documentación de este paquete para más información.\nggplot2 Es un paquete apoyado en el motor grid. Fue desarrollado por Hardley Wickham como una implementación de como una implementación de la metodología de visualización de datos llamada The Grammar of Graphics cuya idea consiste en especificar de manera independiente las componentes del gráfico y luego combinarlas. Es un paquete ampliamente difundido y utilizado en la actualidad por los analistas de datos. Mantiene una estética elegante y profesional. Este paquete viene incluido dentro de tidyverse que engloba un conjunto de paquetes para ciencia de datos. Se pueden realizar gráficos interactivos y animados.\nBásicamente, los componentes del paquete son: Estéticas (color, forma de un punto, relleno, entre otras), Capas (o geoms en el paquete) por ejemplo, geom_point, geom_line, geom_histogram, geom_bar, geom_boxplot, Facetas y Temas, referentes a aspectos estéticos, por ejemplo, ejes, etiquetas, colores de fondo, tamaño de los márgenes y otros. Puedes consultar más sobre este poderoso paquete en su página web.\nggmap Permite la representación de información georreferenciada, tiene la misma arquitectura que ggplot2. Ggmap permite añadir a los gráficos de ggplot2, una capa cartográfica adicional para lo cual usa recursos disponibles en la web a través de APIs de Google y otros. Puedes encontrar más información en la documentación de ggmap.\nplotly Con plotly puedes realizar gráficos interactivos y dinámicos de calidad de publicación, sumamente útiles para los resultados que se difunden a través de Internet. Permite hacer gráficos de líneas, dispersión, área, barras, error, cajas, histogramas, mapas térmicos, subgráficos, de múltiples ejes y gráficos 3D. Es gratuito y de código abierto con licencia del MIT, puedes ver la fuente, informar de los problemas o contribuir en GitHub. Funciona sin conexión y no requiere ningún registro de cuenta. Más información en https://plot.ly/r/.\nshiny Es una herramienta que permite crear aplicaciones web interactivas de una manera fácil, con esto los usuarios interactúan con sus datos sin tener que manipular el código, para lo cual solo hace falta conocimiento de R y no HTML, por ejemplo. Por medio de este paquete se pueden construir y personalizar fácilmente interfaces gráficas sobre páginas web mediante pocas líneas de código. El paquete proporciona varias aplicaciones de ejemplo que puedes usar para aprender sus principios básicos. Consulta más información en (enlace a documentación o sitio web de shiny).\nOtros paquetes El paquete rgl con el que se realizan gráficos interactivos en 3D. Se pueden representar incluso formas geométricas en 3D.\nExisten librerías en R para poder conectar y explorar los datos desde Google Analytics: googleAuthR y googleAnalyticsR. Para utilizarlas se necesitan en una el token Google Analytics, y en la otra, habilitar Google Cloud y su API, respectivamente.\nPaquete ellipse y scatterplot3d poseen varias funciones para realizar gráficos básicos y en 3D respectivamente.\nR es muy potente para el análisis estadístico, puedes probar con distintos paquetes y adoptar el que cumpla tus necesidades y expectativas. Esperamos que este repaso por algunos de ellos te haya motivado a indagar un poco más sobre la importancia de la visualización de los datos y la potencia de R para hacerlo.\nReferencias R para profesionales de los datos: una introducción. Gil Carlos. Abril 2018.\nGráficos Estadísticos con R. Correa Juan y González Nelfi. Universidad Nacional de Colombia, Sede Medellín. 2002.\nR Users Group Ecuador.\n","link":"https://opensciencelabs.org/blog/herramientas-de-visualizacion-en-r/","section":"blog","tags":["datos","visualización de datos","lattice","ggplot2","tidyverse","ggmap","plotly","shiny"],"title":"Herramientas de visualización en R"},{"body":"","link":"https://opensciencelabs.org/tags/lattice/","section":"tags","tags":null,"title":"lattice"},{"body":"","link":"https://opensciencelabs.org/tags/plotly/","section":"tags","tags":null,"title":"plotly"},{"body":"","link":"https://opensciencelabs.org/tags/shiny/","section":"tags","tags":null,"title":"shiny"},{"body":"","link":"https://opensciencelabs.org/tags/tidyverse/","section":"tags","tags":null,"title":"tidyverse"},{"body":" Al realizar una investigación estamos sujetos a distintos panoramas en los cuales nuestro criterio tiene un papel muy importante, porque de ello va a depender cosas tales como la difusión, edición y evaluación del proyecto. De acuerdo con esto, los trabajos de investigación han venido adoptando esquemas formales y estructuras de manera tal que se conviertan en estándares para todos. Al principio, para lograr esto, se recurría al asesoramiento de editores que por lo general estaban adscritos a una revista específica.\nCon el paso del tiempo y la inclusión en la sociedad de distintas herramientas tales como la Internet, han surgido nuevas maneras para que el investigador o grupo de trabajo publiquen los resultados finales, una de ellas es la publicación bajo acceso abierto. Este enfoque logra que los proyectos estén disponibles de forma libre y gratuita, en Internet o cualquier otro medio. Además se permite copiar, utilizar o distribuir el contenido de nuestras investigaciones. Cosa que puede no ocurrir bajo otro enfoque, donde las limitaciones son mayores y los costos de la investigación tienen una alta probabilidad de aumentar. Asimismo, se cuenta con personas profesionales dedicadas a editar o algún software que estandariza el contenido de manera gratuita o a un costo más bajo en comparación a la forma inicial de las publicaciones.\nEn España, por ejemplo, cuando se desea difundir bajo acceso abierto contamos con dos opciones: ruta verde (repositorios) y ruta dorada (revistas doradas y revistas híbridas). La ruta verde implica el depósito y difusión en acceso abierto de resultados de investigación en repositorios (institucionales, como DIGITAL.CSIC, temáticos, como arXiv, o generalistas como Zenodo). La ruta dorada hace referencia a la publicación de artículos revisados por pares en revistas de acceso abierto [https://digital.csic.es/dc/accesoAbierto.jsp].\n¿Cómo se organiza el acceso abierto? El acceso abierto tiene varios principios que permiten que se pueda llevar a cabo de la mejor manera. Comencemos dándole un vistazo al principio de promover el conocimiento.\nLa promoción del conocimiento consiste en lograr que más personas reciban el mensaje de la investigación, de manera que se fortalezca la relación entre el bienestar de la población y el conocimiento científico.\n¿Cómo lo podemos aplicar? A través de actividades, incentivos y difusión de la información en distintos medios con un lenguaje que todos manejen. Además de ello, podemos incluir la estrategia de proporcionar herramientas y asistencia a los académicos para depositar sus artículos revisados por pares en repositorios electrónicos abiertos. Este proceso también se fundamenta en los distintos recursos tangibles o intangibles que se pueden impartir, estos recursos son principalmente revistas y repositorios.\nOtro principio es la integración de diferentes disciplinas tanto en las investigaciones como de manera individual en repositorios. Esto implicaría que los archivos publicados estén claramente definidos por el tipo de disciplina(s) que abarcan. Para aplicarlo se recomienda utilizar etiquetas que representen con certeza los temas que son tratados en la investigación. A su vez se tienen algunas investigaciones hechas bajo la ayuda de varios profesionales de distintas áreas.\nEl respeto de los derechos de autor y otras herramientas para garantizar el acceso abierto permanente a todos los artículos que se publican, son otros principios que se deben tener muy presentes porque aseguran que los elementos del Acceso Abierto estén en orden y complementen un buen trabajo. Para aplicar esto se conocen algunos casos en los que se tienen prácticas de autoarchivo: los investigadores depositan y difunden documentos en repositorios institucionales o temáticos. Y como resultado de la segunda estrategia, hemos visto la creación de revistas de acceso abierto que brindan acceso gratuito a los lectores y permiten la reutilización de sus contenidos con muy pocas restricciones.\nEl acceso abierto debe brindar, en un contexto general, información para que logre exponer grandes investigaciones así como, cultivar el conocimiento en la sociedad a través del tiempo e incentivar el proceso de investigación futuro. Las herramientas son brindadas por distintas organizaciones y equipos de trabajo. Casos que lo demuestran son los diferentes repositorios como:\nACS (American Chemical Association) arXiv BioMed Central Cambridge University Press Copernicus Publications F1000Research Frontiers IntechOpen Knowledge Unlatched MDPI Open Library of Humanities Oxford University Press PeerJ. Pensoft Publishers PLOS ONE PNAS Royal Society of Chemistry (RSC) SCOAP3 Springer Open Que brindan opciones para que los investigadores puedan hacer visibles sus resultados.\nReferencias:\nhttp://bibliotecas.csic.es/publicacion-en-acceso-abierto\nDIGITAL.CSIC Ciencia Abierta\nUniversidad de Jaén\nUCRIndex\nManifiesto de Ciencia Abierta y Colaborativa\n","link":"https://opensciencelabs.org/blog/como-aplicar-los-principios-de-acceso-abierto-en-tus-investigaciones/","section":"blog","tags":["open science"],"title":"¿Cómo aplicar los principios de acceso abierto en tus investigaciones?"},{"body":"","link":"https://opensciencelabs.org/tags/open-science/","section":"tags","tags":null,"title":"open science"},{"body":"","link":"https://opensciencelabs.org/tags/salud/","section":"tags","tags":null,"title":"salud"},{"body":" El covid-19 es un virus que emergió en Wuhan, China a finales del año 2019, este virus ha generado desde entonces una gran alarma internacional. Se trata de una infección respiratoria que comienza con fiebre y tos seca y que, al cabo de cerca de una semana, puede provocar falta de aire. La vía principal de transmisión del virus es a través de pequeñas gotas que se producen cuando una persona infectada tose o estornuda [https://www.isglobal.org/coronavirus]. También se transmite al tocarse ojos, nariz o boca tras tocar superficies contaminadas. Este virus se ha extendido y el número de países en los que sus ciudadanos se han contagiado incrementó masivamente en los últimos días.\nPara el 11 de marzo de 2020 la Organización Mundial de la Salud ha declarado el brote del virus como una pandemia global. En un artículo de la revista Nature [https://www.nature.com/articles/d41586-020-00154-w] se tienen cifras significativas que dan un panorama más claro de lo que está sucediendo, se menciona que el virus se encuentra en más de 100 países, ha infectado a unas 120.000 personas, matando a más de 4.000 de ellas.\nPor esta razón, los científicos han venido realizando un esfuerzo continuo para estudiar el virus y conseguir la cura. De manera que cada uno de los avances de sus investigaciones están siendo publicados en revistas o repositorios de acceso abierto. La particularidad de esto es la omisión de las revisiones preprint de los artículos y/o archivos involucrados para agilizar el proceso de publicación. Algunos repositorios y editoriales conocidos han prestado sus espacios para publicar los avances a pesar de esta condición.\nAunque podemos pensar que los artículos publicados en abierto no son tan fiables por la falta de la revisión, es importante tener en cuenta que, sin embargo, al tener una cantidad importante de personas (científicos, médicos, profesionales de las salud, politicos, entre otros) al pendiente de lo que ocurre, la validación de los archivos se hace entre los lectores y estudiosos del área, y que cualquier sugerencia o comentario se realiza en la plataforma o se envían directamente a los autores.\nAdemás de ello, tal y como es descrito en el articulo \u0026quot;El coronavirus empuja a la ciencia a compartir\u0026quot; se ha dispuesto a la comunidad internacional secuencias genéticas del coronavirus en tiempo real. Una acción similar que funcionó para monitorear el brote de SARS o los inicios de la gripe A. La idea de esta práctica es evaluar la situación y guiar las acciones políticas. De forma tal que el control de la pandemia se realiza bajo un proceso colaborativo que, al complementarlo con la iniciativa de tener repositorios de acceso abierto para los resultados, logra que la sociedad en general y la comunidad científica en particular, consigan puntos de referencia e información clave en cortos periodos de tiempo.\nEntre los repositorios más difundidos con datos y artículos sobre el covid-19 están:\n-medRxiv: es un servidor gratuito de archivo y distribución en línea para manuscritos completos pero no publicados (preprints) en las ciencias médicas, clínicas y de la salud relacionadas. Los preprints son informes preliminares de trabajos que no han sido revisados por pares.\nAlmacena y permite acceso a más de 300 artículos acerca del coronavirus. https://www.medrxiv.org/search/Coronavirus\nBioRxiv: es un repositorio preprint de acceso abierto para las ciencias biológicas cofundado por John Inglis y Richard Sever en noviembre de 2013. Está alojado en el Laboratorio Cold Spring Harbor. Fuente:Wikipedia Hay alrededor de 400 artículos disponibles en este repositorio sobre el coronavirus. https://www.biorxiv.org/search/Coronavirus\nTambién revistas como Nature [https://www.nature.com/search?q=coronavirus], Cell [https://www.cell.com/action/doSearch?searchType=quick\u0026amp;searchText=coronavirus\u0026amp;searchScope=fullSite\u0026amp;occurrences=all\u0026amp;code=cell-site] o The Lancet [https://www.thelancet.com/action/doSearch?searchType=quick\u0026amp;searchText=coronavirus\u0026amp;searchScope=fullSite\u0026amp;occurrences=all\u0026amp;code=lancet-site] e instituciones como la Academia de Ciencias Médicas británica o los Institutos Nacionales de Salud de EE UU han decidido publicar sus estudios y artículos de forma libre. Por ejemplo: National Center for Biotechnology Information, U.S. National Library of Medicine[https://pubmed.ncbi.nlm.nih.gov/?term=COVID19%20or%20SARSCov2\u0026amp;sort=date]\nA continuación veamos unos datos sobre el Codvid-19 que nos pueden ser útiles.\nRecomendaciones para prevenir el COVID-19 Mantener distancia de al menos un metro entre usted y cualquier persona con tos o que estornude. Lavarse frecuentemente las manos con agua y jabón. Evitar tocarse la cara, ojos y boca. Al toser o estornudar cubre boca y nariz usando la parte inferior del codo o con un pañuelo. Quedate en casa cuando estes enfermo. Limpia y desinfecta los objetos con mayor contacto. Evita compartir platos, vasos u otros artículos de uso personal. No es necesario el uso rutinario de mascarilla, se recomienda que las empleen aquellas personas con síntomas. Algunas estadísticas sobre el COVID-19 (16/03/2020) El número de casos confirmados es 167.414 El número de muertes alcanzó las 6.507 personas La tasa de mortalidad es de 2,2% LA cantidad de países infectados es de 139 El número de personas recuperadas es de 77.783 Fuente:\nhttps://www.isglobal.org/coronavirus https://es.statista.com/temas/5901/el-coronavirus-de-wuhan/ Hay otros artículos interesantes que puedes revisar tal como: https://medium.com/@tomaspueyo/coronavirus-act-today-or-people-will-die-f4d3d9cd99ca en el cual se expresan datos relevantes del virus. Y aplicaciones que muestran la distribución geográfica del virus https://arcg.is/918mf\nReferencias: Periódico global: El país\nMaterial informativo de la Universidad Central de Venezuela, Facultad de Medicina\nPortal Regional de la BVS\n","link":"https://opensciencelabs.org/blog/te-mostramos-algunos-repositorios-con-datos-sobre-el-covid-19/","section":"blog","tags":["repositorios","datos","salud","covid19"],"title":"Te mostramos algunos repositorios con datos sobre el COVID-19"},{"body":" Muchas veces ocurre que, a pesar de que te has tomado el tiempo para analizar y modelar un problema, escribir código, depurarlo y asegurarte de que todo funcione bien, necesitas simplificar y compartimentar los datos y la salida de tu programa para que puedas presentar tu trabajo y que este sea entendido, usualmente mediante un informe y/o una visualización de lo realizado. Las herramientas comúnmente usadas para este propósito tienen varias dificultades: suelen ser estáticas (tal como las diapositivas o los informes escritos), ser diseñadas en mente solo para gente con conocimiento técnico, o permitir solo el uso de ciertos lenguajes de programación o librerías.\nAquí es donde entran en juego los dashboards. Estas son herramientas de manejo de información que se vinculan entre sí a través de APIs, servicios, librerías y código de una manera dinámica por 'debajo' de la interfaces de usuarios, es decir, mostrando los resultados de esta interacción en una interfaz web o aplicación móvil, a través de gráficos y visualizaciones que al instante presentan los llamados indicadores de rendimiento (Key Performance Indicators KPI por sus siglas en inglés), o cualquier otro tipo de indicadores, acerca de un negocio, proceso, departamento, sitio web, o servidor. Prácticamente cualquier cosa que necesite ser monitorizada de forma constante puede utilizar los dashboards. Debido a su naturaleza como frontend, son completamente personalizables para cualquier propósito al que los quieras aplicar, sólo hace falta crear los scripts necesarios para hacerlo.\n¿Por qué utilizar un dashboard?\nLa principal razón de su popularidad radica en que ofrecen una plataforma central de monitoreo, y a través de ella se puede observar minuto a minuto el rendimiento de cualquier cosa. El backend (comúnmente alojado en un servidor de forma separada de la interfaz del usuario), recibirá también los datos de entrada y se encarga de realizar el análisis en tiempo real. El backend también transmite los resultados a la aplicación web o móvil, lo que constituye de cara al usuario el dashboard como tal, permitiendo a los usuarios conocer el estado actual del servicio de forma instantánea. Un dashboard requiere, por lo tanto, de una red por debajo que grabe, maneje y suba los datos para el análisis que se mostrará en el dashboard. El dashboard permite no solamente la realización del análisis sino también su modificación, ya sea para verlo de maneras distintas o con más detalle, para ajustar los periodos de recolección de datos, o quizás para explorar las predicciones realizadas por el backend.\nEl dashboard, por lo tanto, intenta responder preguntas acerca de tu negocio o servicio al instante, mediante análisis rápido y presentación de la información en un sitio web. Se construye a partir de aquellas preguntas que se realizan con bastante frecuencia en el manejo de un servicio, tales como: ¿Estará el servidor funcionando? ¿Cuáles son las principales entradas de dinero? ¿Cuál contenido es el que suelen revisar nuestros usuarios con más frecuencia? ¿Cuánto contenido/trabajo se ha realizado en una semana?, entre otras. Para responderlas, se centra en presentar de forma clara datos operacionales, con tablas, gráficos de líneas o barras, medidores, en un diseño sencillo que utiliza elementos y símbolos comunes e intuitivos.\nFrameworks y librerias diseñadas para dashboards\nUn framework es una plataforma reutilizable útil en el desarrollo de aplicaciones de software de forma que sirve de soporte como base para el desarrollo de nuevas aplicaciones. El framework que ha ganado mayor difusión recientemente, quizás debido a que se construyó a partir de otros que han habido antes (tales como React.js, Plotly.js, o Flask), es Dash, un framework de Python principalmente diseñado para crear aplicaciones web orientadas a la visualización de datos. La idea general esta en vincular una interfaz gráfica alrededor de tu código Python de una forma rápida y sencilla, renderizando esta en un navegador web apoyándose en Javascript y HTML, sin necesitar que el usuario utilice estos lenguajes. Cuenta con paquetes en pip, y una galería de ejemplos, además de ser completamente código abierto y usar la licencia MIT. La popularidad de Dash también se debe a que el código escrito para este framework es bastante compacto (aquí hay una aplicación que muestra una variedad de gráficas en 43 líneas), y tiene bastante capacidad de personalización estética para quién lo desee, mediante CSS.\nPor supuesto, hay también bastantes otras opciones. Está Shiny, que es un paquete de R que permite la creación de aplicaciones web directamente desde R, ya sea alojándolas directamente en un sitio web o integrándolas en documentos R Markdown, que también soporta el uso de temas CSS y Javascript. Shiny también tiene una comunidad bastante dedicada y activa. También esta Cube.js, un framework de código abierto diseñado desde abajo para análisis inteligente accesible instantáneamente desde un sitio web. O JDash, o Mozaïk.Todo es cuestión de utilizar el que mas se acerque a tus necesidades.\nLos dashboards son una herramienta bastante poderosa. Con un proceso automatizado de subida y recolecta de datos por debajo, y un diseño funcional, sencillo y bien pensado, pueden volverse un instrumento muy importante para presentar tu proyecto y/o desarrollarlo en grupo, y en áreas de marketing, o negocios son prácticamente indispensables. Si tienes dificultades con cuestiones de coordinación de equipos, monitoreo de proyectos o manejo de finanzas, ¿por qué no probarlos? [1]: https://dash.plot.ly/ \u0026quot;Dash\u0026quot; [2]: https://dash-gallery.plotly.host/Portal/ \u0026quot;Dash App Gallery\u0026quot; [3]: https://gist.github.com/chriddyp/3d2454905d8f01886d651f207e2419f0 \u0026quot;Hello World Dash app\u0026quot; [4]: https://shiny.rstudio.com/ \u0026quot;R Shiny\u0026quot; [5]: https://shiny.rstudio.com/gallery/#user-showcase \u0026quot;R Shine | User Showcase\u0026quot; [6]: https://cube.dev/ \u0026quot;Cube.js\u0026quot; [7]: http://jdash.io/ \u0026quot;JDash\u0026quot; [8]: http://mozaik.rocks/ \u0026quot;Mozaïk\u0026quot;\n","link":"https://opensciencelabs.org/blog/te-hablamos-del-uso-de-dashboards-para-visualizacion-de-datos-de-tu-proximo-proyecto/","section":"blog","tags":["visualización de datos","proyectos","datos","código","dashboard","framework"],"title":"Te hablamos del uso de dashboards para visualización de datos de tu próximo proyecto"},{"body":" Los avances en la ciencia están fuertemente relacionados con la reproducibilidad en las investigaciones. Resulta muy importante lograr que otras personas puedan reproducir nuestros trabajos. ¡Imagínate la aceptación que tendría una investigación si todos los intentos posteriores de ratificar los resultados fracasan!\nDe acuerdo con estudios y encuestas online, como la realizada por la revista internacional semanal sobre ciencia Nature acerca de la reproducibilidad en la investigación, más del 70% de los 1576 investigadores participantes en la encuesta, no han podido reproducir las investigaciones de otros científicos, y más del 50% han fallado en la reproducción de sus propios experimentos. De allí que el tema de la reproducibilidad es considerado como uno de los principales retos de los científicos y de las revistas que publican dichas investigaciones, en especial para garantizar su veracidad. Otro resultado relevante de dicho estudio, es que el 52% de los investigadores encuestados respondieron afirmativamente a la consideración de que, hoy día, hay una significativa crisis de reproducibilidad actual.\nDe manera general, consideramos a una investigación como reproducible, si el desarrollo conceptual de la misma tiene adjunto y abierto el código informático con la documentación mínima necesaria e instrucciones que permitan repetir los cálculos realizados para obtener los resultados en el documento, es decir, que pueda ser reproducida a partir de los datos originales. Asimismo, permite auditar el procedimiento de cálculo y los métodos estadísticos empleados. Este concepto debe diferenciarse del término replicabilidad, que se refiere a la posibilidad de repetir el mismo estudio con la información proporcionada en la investigación pero con nuevos datos.\nBajo el enfoque de código abierto y reproducibilidad en las investigaciones, lo que se quiere hacer es que las herramientas implementadas en la investigación y el código generado para el procesamiento de los datos (para aquellas investigaciones que lo generen), sea \u0026quot;abierto\u0026quot; para cualquiera que esté interesado en reproducir nuestra investigación. Recordemos que uno de los principios de la investigación reproducible, mencionado en nuestro artículo ¿Cuáles son los principios de la investigación reproducible?, es la metodología abierta que, básicamente, busca compartir el procedimiento llevado a cabo antes, durante y después de la investigación, lo cual da confianza a la hora de compartir los resultados y también anima a revisar los pasos de tu investigación y permite a otros verificarlo.\nOtro aspecto valioso a tomar en cuenta si la investigación tiene código y queremos que sea reproducible, es la documentación. Como lo mencionamos en nuestro artículo sobre Documentación de código abierto, este es un factor muy importante a la hora de crear proyectos accesibles e inclusivos y también debe considerarse como un aspecto importante para hacer reproducible el proyecto de código abierto. Junto con la documentación resulta necesario listar los requerimientos para la ejecución del código, donde se incluya la especificación de las plataformas para que funcione el código, las versiones de paquetes o dependencias que se requieran para la interpretación y usabilidad del código a mediano y largo plazo, todo esto garantiza el principio de transparencia de una investigación reproducible que contiene código.\nPara que un proyecto de código abierto sea reproducible, también debe estar depositado en un repositorio de acceso abierto bajo plataformas como GitLab o GitHub, las cuales permiten llevar un control de versiones sobre las actualizaciones y cambios que se realizan al cabo del tiempo en el proyecto, para que cualquiera pueda conocer su trayecto y pueda o no, colaborar en él. Como lo mencionamos en nuestro artículo sobre código abierto una de las comunidades más grandes de código abierto a nivel internacional es GitHub, que nos permite crear y consultar repositorios sobre investigaciones previas, pudiendo necesitar reproducir alguna de ellas o alojar nuestro proyecto para que sea reproducible y colaborativo.\nBajo el mismo enfoque, la utilización de cuadernos de Jupyter, por ejemplo, es altamente recomendado porque permite en un mismo espacio, hacer el análisis y a la vez mostrar comentarios sobre los pasos del experimento. La decisión de implementar o no una herramienta, depende de la decisión del investigador, no obstante bajo el pensamiento de ciencia abierta, se debe buscar en la medida de lo posible, que dichas herramientas se encuentren bajo los estándares de esta \u0026quot;forma de hacer ciencia\u0026quot;.\nOtro concepto que se maneja en el ámbito de código abierto e investigación reproducible es el de Software de investigación abierto o Software de investigación de Código Abierto, que según el Manual de capacitación sobre ciencia abierta de la FOSTER se refiere al uso y desarrollo de software para el análisis, la simulación y la visualización cuyo código fuente completo está disponible, compartiéndose con una licencia que perita su redistribución y modificación. Mediante la implementación de este tipo de software, se garantiza la reproducibilidad en la investigación, poniendo a disposición de cualquiera los datos junto con el código generado en la investigación y permitiendo también la reutilización de este software para otras investigaciones.\nSi haces que tu investigación sea reproducible, poniendo en práctica los elementos que te hemos mencionado en este post, aumentará la probabilidad de aceptación de investigadores, harás que tu código pueda ser ejecutado por otras personas en tareas repetitivas, reducirás el riesgo de errores, facilitarás la colaboración de otros investigadores, la detección de errores y la revisión. Si publicas el código, facilitas la comprensión del artículo y evita malas interpretaciones, aumentarás el impacto de las publicaciones: citas, reconocimiento, reutilización, coautorías, y ahorrarás tiempo y esfuerzo al reutilizar código en otros proyectos.\nGarantiza que tu investigación sea reproducible, no formes parte de la crisis actual de reproducibilidad. ¡Haz la diferencia!\nReferencias Ciencia reproducible, qué, por qué, cómo\nManual de capacitación sobre ciencia abierta de la FOSTER\nNature, reproducibilidad\n","link":"https://opensciencelabs.org/blog/como-aplicar-la-investigacion-reproducible-proyectos-de-codigo-abierto/","section":"blog","tags":["código","reproducibilidad"],"title":"¿Cómo aplicar la investigación reproducible a proyectos de código abierto?"},{"body":"","link":"https://opensciencelabs.org/tags/reproducibilidad/","section":"tags","tags":null,"title":"reproducibilidad"},{"body":" Muchos científicos emplean la creación de software cuando desarollan sus investigaciones, usando herramientas tales como scripts y simulaciones, personalizadas y adaptadas a sus necesidades. En los casos en que no es así, igual la mayoría termina empleando analísis computacional de alguna manera, con software prediseñado para graficar, realizar calculos elementales, visualizar estadísticas o datos que luego se mostrarán dentro de la presentación de su investigación. Sea como sea, lo cierto es que cada vez el rol del desarrolador y el del científico estan más relacionados, exigiendo que estas dos disciplinas se vinculen de forma más estrecha.\nLo que hace esto mucho más interesante es el hecho de que el desarrollo de software está íntimamente involucrado en múltiples áreas de investigación, no sólo porque se utiliza como herramienta, si no de que este desarrollo en sí y los resultados que ofrece pueden traducirse en un problema a abarcar por un estudio. Este es un acercamiento utilizado frecuentemente en papers que tratan temas tales como simulaciones computacionales de procesos químicos variados, aplicaciones posibles de algoritmos de inteligencia artificial y comportamiento de esta en ámbitos particulares, problemas de lógica, y muchos otros más, involucrando una inmensa cantidad de ramas de la ciencia e incluso fuera de esta!\nSi tienes un proyecto de desarrollo de software cualquiera relacionado con la ciencia, así sea nada más una herramienta creada durante tu investigación, quizás sea oportuno buscar la forma de publicarlo, posiblemente adjunto a un paper mas extenso. Hay muchas razones por las cuales lo deberias hacer, independientemente del propósito principal de tu trabajo (divulgación del conocimiento, estandares de reprodubilidad, dejar que los demas aprendan de tu trabajo, etc.), y la labor requerida es prácticamente nula si ya te has tomado el tiempo de escribir y documentar mínimamente tu codígo. Inclusive si consideras que tu código no es lo suficientemente bonito como para publicarse, le podría servir a alguien, así sea nada más para verificar tu investigación.\nDocumentación del proceso de desarrollo Para mostrar posibles usos de tu software, dar a conocer el razonamiento de tus meétodos, y ayudar a entender por qué tu código funciona, es muy importante que, preferiblemente durante el proceso de desarrollo, te tomes el tiempo de escribir de forma rigurosa una documentación que describa con profundidad tanto los pasos que has tomado a lo largo del proyecto, como por qué has pensado que esa ha sido la mejor forma de llevar a cabo tus metas. Esto implica decir con exactitud cuáles herramientas, lenguajes de programación, librerias, scripts, etc., has utilizado, así como dar un recuento de los problemas, tanto conceptuales como prácticos, encontrados durante el desarrollo, trazando un marco de referencia para el funcionamiento de tu código, y por supuesto, mencionar fundamentos de tu investigación, estudios y artículos anteriores escritos sobre problemas relacionados con el tema.\nEl uso de diagramas o esquemas para representar el modelado analítico de los problemas en cuestión o para ilustrar de una forma mas abstracta o intuitiva el funcionamiento del programa, es bastante útil a la hora de ayudar a otros entender como funciona, y es importante si piensas luego presentar tu trabajo en ámbitos menos formales.\nVisualización de resultados Como extensión de lo que se dijo antes, puedes pensar en formas en las cuales se puede visualizar tu código, ya sea mediante una simulación en tiempo real, visualizaciones de estadísticas creadas con herramientas como R Studio, creación de interfaces gráficas u otros métodos, siempre teniendo las particularidades de tu investigación en mente. Con esto logras un mayor grado de accesibilidad y se te hace más fácil divulgar el fruto de tus labores, presentando tus conclusiones de una forma más atractiva sin perder credibilidad. Además, si presentas tu código dentro de un notebook con Jupyter o una herramienta similar, puedes hacer que tus lectores interactúen con tu código de una manera directa, sin mucha complicación, ejecutándolo en tiempo real desde una interfaz web y generando gráficas de manera inmediata.\nPublicación de datos y codigo junto al paper Además de subir tu código junto a tu artículo en repositorios de Git o Docker, puedes usar sitios como IEEE DataPort 1 para subir bases de datos para que cualquiera pueda acceder a ellos de una forma sencilla, siendo los conjuntos de datos asignados un DOI para identificarlos rápidamente. Por lo general, subirlos a un archivo de datos de investigación te proveerá con referencias y identificadores persistentes, sin importar que luego actualices los archivos subidos. Si no es así, puedes usar Zenodo2 o Figshare3 para crear una copia permanente y citable, con un identificador DOI, de la versión actual de tu repositorio. Agregar las citas al propio software es también una opción.\nRecuerda además siempre revisar con cuidado los lineamientos del journal para el cual estes pensando escribir, teniendo en cuenta como les será mas fácil acceder y reproducir tu código. Si subes tu código y datos para que puedan ser vistos por cualquiera, deberías también declarar abiertamente sus términos de uso, licencias y demás.\n","link":"https://opensciencelabs.org/blog/como-presentar-tu-codigo-como-un-articulo-cientifico/","section":"blog","tags":["artículos","publicación","código","herramientas"],"title":"¿Cómo presentar tu código como un artículo científico?"},{"body":"","link":"https://opensciencelabs.org/tags/art%C3%ADculos/","section":"tags","tags":null,"title":"artículos"},{"body":"","link":"https://opensciencelabs.org/tags/publicaci%C3%B3n/","section":"tags","tags":null,"title":"publicación"},{"body":" Las investigaciones son esenciales en el avance tecnológico y social porque nos permiten encontrar respuestas a muchas dudas e hipótesis que surgen diariamente, así como encontrar soluciones a acontecimientos que lo requieran. Por ello, cuando se menciona el término investigación abierta, se hace alusión a aquella investigación que toma en cuenta los elementos de la ciencia abierta.\nEn el blog NeoScientia se menciona que la investigación abierta impulsa la apertura al público de las investigaciones de forma libre y gratuita. Lo cual consiste en que se publiquen las metodologías, procesos y datos obtenidos por resultados directos o derivados, fomentando con ello la colaboración entre profesionales. En este sentido, la investigación abierta abre horizontes en los cuales se expone una mayor cantidad de información, la difusión de los proyectos es mayor y se cuenta con más apoyo al tener una serie de personas trabajando en un mismo proyecto.\nEs aquí cuando nos podemos preguntar acerca de las herramientas e instrumentos que lo harán posible y que debemos manejar para trabajar en un proyecto de investigación abierta, teniendo en cuenta que se necesitan espacios en donde se comparta y difunda la información, preferiblemente a través de la web, para que su acceso sea a nivel universal. Por ello, el acceso a los datos de las investigaciones abiertas debe ser fácil y seguro, así como la edición de los archivos involucrados debe estar monitoreada de manera que no se pierdan aspectos vitales.\nDe acuerdo con lo anterior, una herramienta necesaria son los repositorios, que son una especie de depósito de archivos digitales. Su objetivo es organizar, almacenar, preservar y difundir, en modo de acceso abierto (Open Access), la producción intelectual resultante de la actividad académica, científica, social o según sea el tema de la investigación. Cuando se cuenta con un repositorio se tendrá un espacio en el cual más personas pueden acceder a lo que se ha logrado con las investigaciones y, a su vez, estas personas formarán un ambiente colaborativo en donde se validarán y discutirán los resultados, se construirán también nuevos aportes y se dispondrá de más información.\nUna de las herramientas más difundidas en el manejo de repositorios es Git. Cuando trabajamos en conjunto para lograr un objetivo, debemos contar con un mecanismo mediante el cual la mayoría trabajen a la vez. Si estamos cerca y el número de personas en la investigación es pequeño, este proceso puede resultar fácil y los resultados se pueden trabajar en un mismo archivo sin que pase desapercibido algún cambio. Mientras que, si estamos trabajando a distancia y con un numeroso grupo de personas resultará difícil verificar los cambios y editar en un solo documento.\nPara solucionar este problema, podemos recurrir al control de versiones. En nuestro artículo Investigación Colaborativa con Git se menciona que el control de versiones nos permite almacenar todos los cambios que ocurren durante el proceso de avance hasta que es alcanzado el objetivo final y si algún miembro del equipo hace cambios durante el proceso y conformación final del proyecto, estos quedarán registrados junto con la información asociada a ellos. Logrando así que elementos vitales de las investigaciones no se pierdan fácilmente, debido a cualquier confusión o error. Lo que ocurre en tus documentos estará respaldado. Por todo ello es que afirmamos que una herramienta potente para el control de versiones es Git.\nEn un contexto más amplio tenemos que, al realizar investigaciones abiertas, se deben manejar adecuadamente los repositorios para obtener una mayor cantidad de información disponible y, a su vez, contribuir para que sea más abundante. Además, si se combina esto con el control de versiones se tiene una retroalimentación continua donde personas con distintos puntos de vista pueden colaborar. La combinación de estas herramientas tendrá como resultado la existencia de más elementos disponibles a nivel informativo, divulgativo y experimental en distintas áreas y lo más importante, de manera segmentada. Es destacable mencionar que los manejadores de repositorios tienen un motor de búsqueda, lo cual nos permite acceder a lo que necesitamos de manera eficiente. Por otro lado, con el control de versiones podemos tener versiones certificadas y actualizadas de la información.\nExisten repositorios remotos, que combinan las funcionalidades de un repositorio con el control de versiones. De manera general, un repositorio remoto es una versión de un proyecto en específico que se encuentra alojado en internet. Estos repositorios pueden tener permisos especiales de manera que todos o algunos de los miembros del equipo de trabajo pueden editar. Esta edición será compartida para cada uno. Esto se logra a partir de la gestión de repositorios remotos lo cual podemos hacer con Git, implicando conocer cómo añadir repositorios nuevos, eliminar aquellos que ya no son válidos, gestionar ramas remotas e indicar si están bajo seguimiento o no, y otras cosas más. Te invitamos a revisar nuestro artículo Git de 0 a 100 en diez sencillos pasos.\nReferencias Biblioteca de la Universidad de Extremadura\nOficina de conocimiento abierto\nBlog Neoscientia\n","link":"https://opensciencelabs.org/blog/la-investigacion-abierta-el-manejo-de-repositorios-y-control-de-versiones/","section":"blog","tags":["versionado","repositorios"],"title":"La investigación abierta, el manejo de repositorios y control de versiones"},{"body":" Cada vez es más común leer o escuchar sobre datos abiertos, pero puede que no sepamos del todo lo que esto significa. Por ello, vamos a revisar inicialmente este concepto.\nLos datos abiertos son aquellos que no sólo están disponibles a cualquier persona (liberados) sino que también están disponibles en distintos formatos, de manera que pueden ser recibidos y procesados por una computadora. Además de ello, los datos abiertos se disponen bajo una licencia 'abierta', es decir, que mínimo permita su uso, modificación, y reproducción universal (sin restricción en cuanto a quien lo puede ver), y que según sea apropiado, permita además uso comercial.\nEsto deriva en tres particularidades que los datos deben cumplir para que sean abiertos, tal como es expresado en https://ceweb.br/guias/dados-abertos/es/capitulo-2/.\nDisponibilidad y acceso: los datos deben estar disponibles de manera integral y en una forma en que no genere costos exhorbitantes para la parte interesada en copiarlos. El escenario más favorable es poner los datos a disposición para que sean descargados a través de Internet. Asimismo, los datos deben ofrecerse en un formato conveniente y modificable.\nReutilización y redistribución: los datos deben ponerse a disposición bajo términos de uso que permitan su reutilización y redistribución, e incluso que permitan su mezcla y entrecruzamiento con otros obtenidos de distintas bases.\nParticipación universal: cualquier persona debe poder usar, reutilizar y redistribuir los datos. No debe existir ningún tipo de discriminación contra campos de actuación, individuos o grupos. Por ejemplo, restricciones \u0026quot;no comerciales\u0026quot; que impidieren el uso \u0026quot;comercial\u0026quot; de los datos, o bien restricciones de utilización para determinados fines específicos (por ejemplo, sólo para averiguación personal), no están permitidas.\nCon lo anterior tenemos una noción más clara de lo que significa que los datos estén o sean abiertos. Existen diversos repositorios y páginas web que nos permiten acceder a datos abiertos. Por ejemplo, si estamos interesados en estudiar los cultivos de Colombia podemos ingresar al sitio web en el que se publican datos del gobierno Colombiano (https://www.datos.gov.co); allí encontraremos una gama de conjuntos de datos referentes al tema, si escogemos uno en específico, veremos sus detalles y si deseamos tener la data en un directorio de nuestro equipo tenemos la opción de descargarlo en formato csv.\nOtra página web que nos brinda una serie de conjuntos de datos es la correspondiente al gobierno de España (https://datos.gob.es), donde podemos acceder a datos que abarcan el ámbito social, estos datos los podemos descargar en diversos formatos como csv o JSON.\nAhora, si nos planteamos realizar proyectos en los cuales se tenga como materia de estudio datos que no sean de adquisición propia, sino provenientes de otras fuentes, específicamente datos abiertos, no debemos olvidar que:\nLos datos abiertos poseen una documentación, esta permite que se tenga una mejor noción de los datos, su contenido y estructura. Además de que en ella se menciona la procedencia, las técnicas utilizadas para su obtención y los metadatos. Estos últimos son datos de los datos, permiten describir los datos de manera detallada.\nTodos los elementos de acceso abierto tienen la particularidad de que se muestra de manera explícita sus propietarios, autores y las personas involucradas en el trabajo, es importante que si utilizamos o reutilizamos alguno de sus trabajos no pasemos desapercibidos estos nombres y los mencionemos en nuestros proyectos. Además, si tenemos cualquier duda sobre los datos y no encontramos información en la documentación, podemos contactarlos.\nLos conjuntos datos poseen una estructura predeterminada que puede ser descargada en distintos formatos, lo debemos tener en cuenta para realizar un análisis óptimo. Esto es porque muchas veces nuestro equipo está configurado de alguna manera en específico y los archivos son leídos de manera equivocada. Por ejemplo, descargamos un archivo csv delimitado por comas y tenemos configurado en nuestro equipo la aplicación para la lectura de los datos con separador decimal coma(,). Entonces resulta que en la aplicación se mostrarán los datos de las columnas en una única columna. Para solucionar esto se puede cambiar la configuración o indicarle en el proceso de lectura el tipo de separador.\nLos datos abiertos pueden reutilizarse, si hacemos esto de manera que unamos uno o más conjuntos de datos debemos tener cuidado y verificar que la estructura de los datos sea la misma. Esto evitaría que la información se confunda obteniendo una mezcla homogénea de los datos.\nLos resultados obtenidos según sea el carácter de la investigación debieren ser compartidos a través de un paper o artículo científico, de manera que vaya de la mano con el acceso abierto. Esto permitirá una retroalimentación constante y si es el caso, brindaría otro enfoque para el análisis de estos datos.\nEn resumen, los datos abiertos son una iniciativa que permite a los investigadores y ciudadanos en general tener una visión más amplia y sustentada de lo que ocurre a su alrededor, proponer maneras de analizar y contrastar datos y resultados. ¡Por eso te animamos a que consideres el uso de datos abiertos en tus próximos proyectos!\n","link":"https://opensciencelabs.org/blog/cinco-cosas-que-no-debes-olvidar-al-trabajar-con-datos-abiertos/","section":"blog","tags":["datos"],"title":"Cinco cosas que no debes olvidar al trabajar con datos abiertos"},{"body":" Con mucha frecuencia, los proyectos de código abierto suelen prestar poca atención al tema de documentación. De hecho, es tan común que la encuesta Open Source Survey (realizada por Github, involucrando tanto académicos, como a trabajadores en la industria de computación, como colaboradores independientes) reportó que al menos 93% de los encuestados, creían que la documentación incompleta o sin actualizar era uno de los problemas más agravantes dentro de la esfera del software libre. En la misma encuesta, 60% de los participantes admitían también contribuir a la documentación de sus proyectos con muy poca frecuencia.\nIndependientemente del tipo de proyecto en el que participes o de su objetivo, la documentación es un factor muy importante a la hora de crear proyectos accesibles e inclusivos, en el sentido que facilita en gran medida tanto su utilización como la colaboración entre personas que no estén activamente involucradas en su desarrollo. Establecer de forma clara términos de uso del código, manuales o guías permite a tus usuarios ser autosuficientes y dar sugerencias mucho más útiles y profundas, además de que puede ser el factor clave para que alguien se vuelva un colaborador o que termine ignorando tu proyecto. Tal como dice Write The Docs | Why Write Docs?:\nSi la gente no sabe que tu proyecto existe, no lo usarán. Si la gente no sabe como instalar tu código, no lo usarán. Si la gente no puede entender como usar tu código, no lo usarán. Fuera de cuestiones de colaboración o facilidad de lectura, es obvio también que el código se hace progresivamente más difícil de entender y recordar conforme el proyecto avanza y se hace más extenso, por lo que la documentación se vuelve una herramienta de supervivencia, especialmente si no pretendes trabajar en el código con frecuencia. Algo que puede ocurrirte con más frecuencia de la que esperas, es estar en la situación donde quieres continuar un proyecto de hace meses, pero no entiendes absolutamente nada de lo que hace el código.\nPor estas razones (¡y muchas otras!) la documentación de tu trabajo es imperativa. Sin embargo, es común que durante el proceso de documentación, utilicemos destrezas que no suelen aprenderse en trabajos relacionados con software, por lo que los lineamientos que se deben seguir para llevar a cabo una buena documentación pueden no estar muy claros. Entonces, ¿qué es lo que hace una buena documentación de código abierto?\nAccesibilidad A la hora de escribir tu documentación, tienes que tener en cuenta que la van a leer tanto usuarios como desarrolladores, y que por lo general van a querer acceder a la información de la forma más rápida y completa posible. El uso de hipervínculos y tablas de contenidos ayuda bastante, permitiéndote reutilizar otras documentaciones abiertas, a la vez que puedes mantener la información ordenada y concisa, ayudando a los usuarios encontrar los términos o datos que necesitan de la forma más rápida y sencilla posible. Por esta razón, también es recomendado poner ciertos datos que van a buscar la mayoría de los interesados en un primer momento, tales como: la licencia que utilices, la meta del proyecto, ejemplos de uso, lista de tareas por realizar, etc.\nComunicación con tus usuarios Puede sonar obvio, pero la documentación, al final del día, está pensada para que la lean tus usuarios. Si está dentro de la posibilidad, es bastante beneficioso agregar canales por los cuales puedan consultar y hasta contribuir otros desarrolladores: pull requests, tus cuentas en redes sociales, acceso al rastreamiento de problemas, FAQs, entre otros. Para este fin puedes usar ciertas convenciones como el archivo CONTRIBUTING.md, el cual especifica normas de conducta, como se prefiere que se comuniquen los usuarios, y las responsabilidades de los administradores del repositorio.\nTambién podemos añadir que contribuir a la documentación de cualquier repositorio es una forma fácil y relativamente sencilla de apoyar un proyecto, sin involucrarse demasiado. Este es uno de los ámbitos donde cualquiera puede aportar perspectivas relevantes, sin importar demasiado su trasfondo o habilidades particulares.\nGuías concisas y ejemplos sencillos Sín importar el tipo de programa que estés desarrollando, facilitará bastante su uso si das algunos ejemplos de cómo se utiliza en un contexto cotidiano, con una guía paso a paso o una pequeña sección en su manual específicamente para principiantes, con algunos comandos y funciones cruciales para el uso más básico de tu código. Te puede resultar útil el empleo de capturas de pantallas, incluir configuración de texto inteligente (con bloques de código, resaltamiento de sintaxis, etcétera), acompañados de párrafos de texto concisos, escritos con lenguaje simple y sin entrar mucho en terminología específica.\nSiempre recomendamos que si necesitas ayuda en cuanto a cómo escribir documentación, ¡solo hace falta revisar lo que ya han escrito otros! Ya sea para aprender ciertos modos de escritura que son comunes dentro de esta práctica, para aprender de los errores que cometen los demás, o simplemente para situarte en el lugar de alguien que esté chequeando tu código por primera vez. Leer lo que han escrito los demás con el enfoque de aprender es una buena estrategia. Prácticamente, todas las distribuciones de Linux incluyen el comando man que te permite ver información sobre varios comandos de bash, y muchos repositorios de Github tienen por lo menos un archivo README.md, visto en cuanto entras a su página, cuyo objetivo es mostrar el principal propósito y uso del proyecto. Es solo cuestión de revisar un poco para encontrar una enorme variedad de ejemplos.\nReferencias Open Source Survey\nWrite The Docs | Why Write Docs\n","link":"https://opensciencelabs.org/blog/si-ya-usas-codigo-abierto-te-contamos-como-puedes-sacarle-mayor-provecho-tu-documentacion-para-tus-articulos-y-publicaciones/","section":"blog","tags":["documentación","código","proyectos","artículos"],"title":"Si ya usas código abierto, te contamos cómo puedes sacarle mayor provecho a tu documentación (para tus artículos y publicaciones)"},{"body":" La competitividad y los deseos de superación a nivel personal, profesional y laboral impulsan los deseos individuales por aprender continuamente para afianzar nuestros conocimientos, aptitudes y habilidades. En muchos casos, el aprendizaje demanda la adquisición o fortalecimiento de capacidades y destrezas, para las cuales el proceso de mentoría nos brinda una buena oportunidad para lograrlo. En el presente artículo proporcionamos una definición de mentoría, te daremos un paseo por algunos programas actuales de mentoría y al final reflexionamos sobre las bondades de este proceso en proyectos de ciencia abierta.\nEl término mentor proviene de la novela “La Odisea”, escrita por el poeta griego Homero. Mentor era un amigo de confianza de Odiseo y lo ayudó a aconsejar a su hijo Telémaco. De allí, se conoce como mentor la persona que enseña, aconseja, guía, apoyar y ayuda en el desarrollo y crecimiento de otra persona invirtiendo tiempo y conocimientos para ello.\nAunque la palabra Mentoría no se encuentra en el Diccionario de la Real Academia Española, hoy por hoy se utiliza para definir el proceso de aprendizaje mediante el cual una persona con mayor experiencia (mentor) transmite sus conocimientos, experiencias, información y técnicas a otra (aprendiz) con la finalidad de desarrollar o afianzar en él, destrezas para el logro de los objetivos propuestos ya sea a nivel académico, profesional o personal.\nLa mentoría también puede utilizarse como una estrategia de aprendizaje que consiste en brindar consejo y un ejemplo constructivo a los participantes con el fin de ayudarles a alcanzar su potencial MENTOR. Se espera en un largo plazo que las personas que participan en las mentorías puedan poner en práctica las habilidades y conocimientos que adquirieron en su proceso de aprendizaje en aspectos de su vida personal, profesional y laboral.\nEs importante mencionar que aunque haya programas establecidos que conduzcan el proceso de la mentoría, en realidad, ninguna mentoría debería ser igual a otra: los intereses particulares e intercambios interpersonales definen cada proceso de guía y acompañamiento, donde la confianza y aceptación son aspectos fundamentales.\nUn buen mentor debe ser una persona que sirva de guía al alumno prestándole la ayuda adecuada, disponiendo de tiempo de dedicación, contando con conocimientos suficientes sobre los desafíos que los aprendices enfrentan, debe tener alta capacidad de comunicar esa experiencia y la predisposición para hacerlo, así como un interés en contribuir al desarrollo del participante.\nLas mentorías pueden ser pagas o gratuitas, presenciales u online. A este último tipo se le conoce como e-mentoría, telementoría o mentoría online, y se plantea como respuesta a las limitaciones de espacio y tiempo que pueden presentarse en las mentorías presenciales. La mentoría online, se basa en la implementación de las Tecnologías de comunicación e información (TIC's) y la comunicación mediada por ordenador (CMO) como el uso de e-mail, sistemas de conferencia por ordenador, redes sociales como WhatsApp para llevar a cabo las mentorías. Este tipo de mentoría se benefician de conservar un registro de la interacción con su mentor.\nExisten figuras públicas que alcanzaron el éxito con el acompañamiento de un mentor, por ejemplo, el CEO de Facebook, Mark Zuckerberg tuvo como mentor a Steve Jobs, ex CEO de Apple y el cofundador de Microsoft, Bill Gates tuvo como mentor a El CEO de Berkshire Hathaway, Warren Buffett, otras personalidades en este enlace.\n¿Cómo ayudan las mentorías a los proyectos de ciencia abierta? Veamos algunos argumentos de cómo las mentorías pueden ayudarte si desarrollas (o así lo deseas) proyectos de ciencia abierta.\nComo se dijo en nuestro artículo, la ciencia abierta (enlace al artículo ciencia_abierta) está compuesta por varias disciplinas, entre ellas: el acceso abierto, datos abiertos, código abierto, investigación abierta y reproducible, ciencia ciudadana, ciencia de datos, entre otros. El \u0026quot;hacer\u0026quot; ciencia abierta se está practicando cada vez más, de ahí la importancia de encontrar un mentor para ayudarte a desarrollar y potenciar buenas prácticas, para aprender o especializarte en el manejo de algunas herramientas que necesitarás para desenvolverte en este apasionante mundo de la ciencia abierta.\nCon la ayuda de un mentor y un plan estratégico puedes garantizar, en buena medida, un logro de tus objetivos, cerrando la brecha entre las aplicaciones teóricas y prácticas de todos los componentes de esta forma de hacer ciencia. El objetivo principal de las mentorías en ciencia abierta es educar a los científicos sobre las bondades de hacer abierta la ciencia que practican.\nSin embargo, debes tomar en cuenta que el éxito de tu proyecto depende exclusivamente de tí como investigador aunque la ayuda de un mentor, sin duda, aumenta la probabilidad de éxito.\nDebido a la rigurosidad en el planteamiento y desarrollo de procesos de investigación, se hace cada vez más necesario la ayuda y acompañamiento de investigadores con conocimientos afianzados y que se encuentren en la disposición de ayudar a otros investigadores. En ocasiones puedes sentir que tu trabajo en el proyecto no fluye, que cada vez son más los inconvenientes que se te presentan y que solo con leer libros y consultando la web, no sientes el avance. En estas situaciones te sería de gran ayuda contar con un mentor.\nUn mentor en proyectos de ciencia abierta debe ser un embajador de la práctica, la formación y la educación de la Ciencia Abierta en proyectos y comunidades. De acuerdo con el enfoque de ciencia abierta que estés trabajando o quieras comenzar a manejar puedes encontrar una gran variedad de perfiles de los posibles mentores.\nSi participas en una mentoría en investigación abierta, por ejemplo, el mentor contribuye a tu desarrollo técnico en cuanto a métodos, instrucciones, pensamiento creativo, requisitos académicos, habilidades de comunicación, gestión y apertura de los datos y divulgación de los resultados. Un tema interesante que puedes tratar con tu mentor es la preparación para el mercado laboral, él puede darte sugerencias sobre ello, permitiéndote establecer contactos con personas que se desarrollen en el mismo campo de investigación y aportándote una nueva perspectiva del panorama de todo lo que puedes lograr en la disciplina en la cual te desempeñes. Lo mismo ocurre si participas en mentorías sobre cualquier otro componente de la ciencia abierta, por ejemplo, mentorías sobre \u0026quot;cómo abrir los datos\u0026quot;, plataformas de control de versiones e investigación reproducible, gestión de datos, código abierto, ciencia de datos.\nPuedes encontrar distintos programas y personas que brindan mentorías, muchas de esas son pagas y tienen un plan de trabajo establecido. A continuación te presentamos algunas plataformas e iniciativas de programas de mentorías:\nMENTOR-Sociedad Nacional de Mentoría Centro Nacional de mentoría Acamica Red de Mentores UANL Red de Mentores de Madrid WINN Women in the news Networs Programa de mentorías de la Universidad Complutense de Madrid Programa de mentorías de la Universidad de la Frontera Open Life Science Neoscientia Encontrar mentores en ciencia de datos Y en openScienceLabs te brindamos un programa de mentorías sobre algunos temas de ciencia abierta que puedes consutar en enlace.\nReferencias MENTOR-Sociedad Nacional de Mentoría Neoscientia El mentoring como herramienta de motivación y retención del talento Mentoría en educación superior, la experiencia en un programa extracurricular ","link":"https://opensciencelabs.org/blog/que-son-las-mentorias-y-como-potencian-los-proyectos-de-ciencia-abierta/","section":"blog","tags":["proyectos"],"title":"¿Qué son las mentorías y cómo potencian los proyectos de ciencia abierta?"},{"body":"","link":"https://opensciencelabs.org/categories/mentor%C3%ADas/","section":"categories","tags":null,"title":"mentorías"},{"body":"","link":"https://opensciencelabs.org/tags/basura/","section":"tags","tags":null,"title":"basura"},{"body":" Alguna vez has querido saber como es realmente participar en una investigación científica, sin necesariamente tener el entrenamiento o la educación del area? Descubrir nuevas especies, identíficar cuerpos celestes, quizás simplemente hacer trabajo de campo en las fronteras de tu propia ciudad, catalogando los animales y plantas que coexisten en tu habitat local. Mediante proyectos y aplicaciones de ciencia ciudadana, esto es una posibilidad, y ya hay una diversidad de personas cotidianas que la han aprovechado, indirectamente volviendose científicos.\nAlrededor del mundo, una multitud de gobiernos y instituciones ya estan resolviendo problemas concretos utilizando ciencia ciudadana. Ya sea por que consideran mucho más eficiente aprovechar el amplio alcance que les otorga, porque lo consideran necesario para lograr conseguir una comunicación mas directa entre los científicos y el entorno el cual estudian, porque piensan que el vinculo entre los científicos y la gente común debe ser mas estrecha, o porque requieren de la información que pueden obtener de reportes y observaciones hechos durante el dia a dia de los ciudadanos, simplemente ven ahí un potencial muy importante y explotable, y es de esperar que el foco de estos proyectos se este ampliando cada vez mas y mas, desde problemas particulares de biodiversidad o reporte de deslaves, hasta temas de políticas públicas y decisiones legales.\nPensando nada más en el momento actual en el que vivimos, vemos que hay muchas oportunidades para participar en estos proyectos inclusive en lugares del mundo donde no son muy comunes. Sólo hace falta tiempo libre y una conexión a internet para empezar a transcribir documentos de la libreria del congreso estadounidense1, identificar animales en Australia2 o ayudar a monitorearlos en la India3. Todo esto sin ni siquiera ir a recolectar datos en el campo como tal, lo cual pone otro gran montón de posibilidades sobre la mesa, las cuales definitivamente solo hemos empezado a explorar.\n¿Tienes curiosidad por cual es el verdadero potencial de esta practica? Si quieres saborear una pequeña muestra, solamente tienes que revisar los siguientes proyectos que presentamos a continuación.\nButterfly Conservation Butterfly Conservation4 es una ONG que trabaja con la protección de la vida salvaje basada en el Reino Unido que, tal como su nombre lo indica, se dedica a realizar investigaciones y proyectos que apuntan hacia la conservación y restauración del habitat de mariposas y polillas, buscando tanto proteger especies locales en peligro como apoyar y promover esfuerzos internacionales de preservación. En su pagina comparten recursos tanto para aprender a identificar especies individuales, como para ciertas prácticas de permacultura (siembra de ciertas plantas en especifico, creación de un habitat reproductivo, etc.), que otorgan a las mariposas y polillas un refugio dentro de tu jardín. Como organización, tienen una multitud de proyectos de conservación dedicados a la creación de mejores prácticas de agricultura y pastizales económicos, pero repletos de polinizadores y flores silvestres.\nSus investigaciones también utilizan prácticas de ciencia ciudadana. Permiten a cualquier persona que esté interesada, trabajar como voluntario/a tanto en sus oficinas como en el campo, en tareas de ayuda a organización de eventos y manejo de reservas naturales, entre otros. También están abiertos a que cualquiera que tenga la posibilidad, les apoye mediante monitoreo de especies dentro de jardines y espacios urbanos. Cualquiera que viva junto a o cerca de una variedad de mariposas o polillas dentro del Reino Unido puede hacer un registro de su observación y así contribuir a una multitud de proyectos dentro de la organización, ya sean de contar o identificar especies o investigar el estado y salud del ambiente en el que conviven.\nCientíficos de la Basura Científicos de la Basura5 es un programa de ciencia ciudadana de Chile integrado y fundado por investigadores de la Universidad Católica del Norte, cuya principal misión es educar a los escolares respecto a la ciencia y al ambiente en el que viven, fomentando un respeto por el manejo de la basura e involucrándolos en actividades que induce al trabajo de campo mediante su realización, generando información científica que a su vez ayuda a diseñar estrategias para que se resuelvan problemas particulares respecto a la acumulación de basura, tanto en espacios urbanos como naturales. Junto a estas actividades, también han desarollado muchas guías metodológicas para muestreos y encuestas en diferentes áreas, de manera que cualquiera que desee puede realizar estas investigaciones de forma independiente, así como guías para que profesores de primaria puedan introducir estos temas de contaminación ambiental en un curriculum escolar.\nHasta ahora han realizado una número importante de investigaciones en instituciones educativas distribuidas a lo largo de Chile. Hay desde investigaciones realizadas por clubes escolares con metodologías estandarizadas, como en 2009, donde el Club Explora del Colegio Los Carrera estudió el impacto que tienen los humanos en la región de Coquimbo, principalmente en los humedales y en el borde costero. O en 2014, cuando se realizó el proyecto \u0026quot;Investigando la basura aprendemos ciencia\u0026quot;, que abarcó muestreos y talleres realizados por los profesores y sus alumnos en una variedad de escuelas.\nMoon Zoo Moon Zoo[6] fue un proyecto lanzado en Mayo 2010, alojado en la plataforma Zooniverse, donde usuarios registrados podían identificar, clasificar y medir formas y relieves en la superficie de la Luna, cerca del sitio de aterrizaje de la misión Apolo 17. De esta forma, catalogaban ciertas características geomorfológicas a lo largo de la superficie lunar, como cráteres frescos y relieves lineares, identificándolas entre millones de imágenes tomadas por el satélite Lunar Reconnaissance Orbiter (LRO) de la NASA. Todo ello desde un portal en el que analizaron, inclusive, las herramientas e interfaces utilizadas por los usuarios para el ingreso de los datos, seleccionándolas y diseñándolas para la encuesta. En este proyecto se prestó especial atención a los métodos de agrupación de información y de filtración de datos, para evitar marcaciones problemáticas, generando verificaciones por expertos.\nEntre algunas de las observaciones realizadas al proyecto, se indicaron ciertos errores metodólogicos y otros más relativos al entrenamiento previo de los usuarios que vacíen información, y el proceso de filtrado de datos; sin embargo, los beneficios que les dio este acercamiento inusual al problema definitivamente se hicieron notar. Entre estos beneficios destacan: la clasificar distribuida de grandes cantidades de datos mediante observación y analísis independiente asignado a voluntariados de Internet, lo cual permitió que este proceso se realizara de una forma mucho mas rápida sin sacrificar necesariamente la calidad de la investigación.\nComo puedes ver, ya hay muchos investigadores que consideran útil y hasta necesaria la participación de los ciudadanos en sus estudios, y no como sujetos en encuestas o entrevistas sino como colaboradores. Inclusive si no te convencen mucho los proyectos de las lista, solamente hace falta buscar en internet para conseguir docenas de ejemplos mas, en todo tipo de lugares alrededor del mundo. Muchos presentan metodologías interesantes o inusuales y por lo tanto vistas interesantes al proceso científico, y definitivamente se merecen tu atención.\n[6]: https://moonzoo.org/ \u0026quot;Moon Zoo\u0026quot;2\n","link":"https://opensciencelabs.org/blog/tres-proyectos-de-ciencia-ciudadana-que-te-sorprenderan/","section":"blog","tags":["comunidad","proyectos","basura","ciencia ciudadana"],"title":"Tres proyectos de ciencia ciudadana que te sorprenderán"},{"body":" Cuando escuchamos la palabra código podríamos pensar que se trata de algo oculto y secreto, en una contraseña o simplemente algún identificador. Sin embargo, en el mundo computacional, por ejemplo, cuando se habla de código se hace referencia a una serie de palabras, números y símbolos que, combinadas, corresponden a un conjunto de comandos que producen una solución, generan el proceso de alguna tarea o forman un sistema en especifico. En desarrollo de software, la palabra código hace referencia a uno o varios lenguajes de programación.\nEl término código abierto se refiere al modo en que se tiene acceso al código que involucra un software. Es decir, el software creado por algún grupo o individuo que se etiquete como de código abierto, tendrá su código fuente disponible para todo público de forma libre, en Internet o cualquier otro medio, podrá ser copiado, utilizado y distribuido siempre y cuando se respeten los términos establecidos por quien lo diseñó. Este tipo de proyectos ha permitido el intercambio constante de conocimiento de manera tal que el software reciba mejoras continuamente, se aplique en distintos ámbitos y se amplíen las capacidades del software.\n¿Cómo puede ayudarte el código abierto? Antes de responder esta cuestión, pensemos en las tareas específicas que hacemos en nuestras investigaciones, en los recursos de software y las herramientas que necesitamos para conseguir resultados óptimos. Entre algunas de esas tareas puede estar el cálculo de una serie de indicadores, la creación de documentos con un formato similar, la edición, almacenamiento y procesamiento de los datos.\nAhora bien, si prestamos atención a estas tareas muchas veces las podemos considerar repetitivas, porque bajo condiciones similares se realiza el mismo procedimiento. Esto ha permitido que se desarrollen herramientas, aplicaciones y software por parte de las empresas e individuos, de manera que permitan, faciliten y ahorren tiempo en los procesos.\nEs aquí cuando el código abierto puede ser de mucha ayuda, dado que donde se requiera un software o una serie de comandos que resuelvan una tarea en específica, se abre un abanico de posibilidades para reutilizar código previamente desarrollado por otro equipo de trabajo, y encontrarás distintas fuentes de información para localizarlo, pues la retroalimentación del conocimiento es constante. En otras palabras, el código abierto es una forma de inteligencia colectiva en la cual muchas personas están involucradas, comparten y colaboran. Además, están dispuestos a ayudar con sus conocimientos poniendo a disposición sus trabajos. Logrando así una mayor interacción entre expertos en el área y personas que se inician en el tema central es decir, una comunidad. Para que estas comunidades surjan sólo es necesaria una plataforma de comunicación que muchas veces puede ser un foro, en el cual se realizan consultas y sugerencias.\n1Una de las comunidades de código abierto más grande del mundo es 2GitHub, en la cual se alojan millones de proyectos a lo largo y ancho de todo el planeta. Los proyectos bajo el código abierto pueden ser utilizados por cualquier persona para casi cualquier propósito y, por tanto, se pueden emplear para construir otras cosas. Es decir, son de estándar abierto, están a disposición del público aunque pueden tener varios derechos de uso asociados.\nCualquiera puede inspeccionar un proyecto de código abierto en busca de errores e inconsistencias, permitiendo que sea transparente. Este aspecto es muy importante dado que posibilita que, por ejemplo, los entes gubernamentales e instituciones que tienen una serie de restricciones permitan su práctica sin problema alguno, y se sentirán confiados sobre la manera en que la información sea utilizada, pues podría ser monitoreada.\nFinalmente, el código abierto recibe un aporte considerable por parte de empresas importantes a nivel informático apoyando el surgimiento de nuevos proyectos y publicando los avances en sus páginas. Tal es el caso de IBM [https://developer.ibm.com/open/projects/]\nEjemplos de Código Abierto Linux: es una familia de sistemas operativos de código abierto tipo Unix basados ​​en el núcleo de Linux, un núcleo del sistema operativo lanzado por primera vez el 17 de septiembre de 1991 por Linus Torvalds. [https://en.wikipedia.org/wiki/Linux]\nAndroid: es un sistema operativo móvil desarrollado por Google, basado en Kernel de Linux y otros software de código abierto. Fue diseñado para dispositivos móviles con pantalla táctil, como teléfonos inteligentes, tabletas, relojes inteligentes, automóviles y televisores. [https://en.wikipedia.org/wiki/Android_(operating_system)]\nRStudio: es un entorno de desarrollo integrado (IDE) para R. Incluye una consola, un editor de resaltado de sintaxis que soporta la ejecución directa de código, así como herramientas para el trazado, el historial, la depuración y la gestión del espacio de trabajo, esta disponible bajo ediciones de código abierto y comercial. [https://rstudio.com/]\nAmanda: anteriormente conocido como Advanced Maryland Automatic Network Disk Archiver, es una herramienta de archivo de código abierto que es capaz de respaldar los datos que residen en varios ordenadores de una red. Utiliza un modelo cliente-servidor, donde el servidor se pone en contacto con cada cliente para realizar una copia de seguridad a una hora programada. [https://en.wikipedia.org/wiki/Amanda_(software)]\nReferencias\n(WORKANA) [https://www.workana.com/i/glosario/codigo-abierto/]\n","link":"https://opensciencelabs.org/blog/que-es-el-codigo-abierto-y-como-puede-ayudarte/","section":"blog","tags":["código","software"],"title":"¿Qué es el código abierto y cómo puede ayudarte?"},{"body":"","link":"https://opensciencelabs.org/tags/software/","section":"tags","tags":null,"title":"software"},{"body":" Recientemente se ha vuelto popular la creación de espacios tales como MediaLabs y otras formas de laboratorios sociales. Estas organizaciones de innovación sugieren el uso del modelo abierto del laboratorio, donde se hacen disponibles tanto utensilios como instrumentos (ya sean de trabajo o de medición), como un entorno en el cual se puede experimentar con este material, y donde se ponen en contacto personas que, quizás, nunca hayan estado relacionadas con el mundo académico o emprendedor de ninguna forma, permitiéndoles cocrear investigaciones y productos de forma independiente.\nLa experiencia que ofrecen estos lugares es tan , que muchos espacios variados (principalmente museos de ciencia y de tecnología) han empezado a ofrecer este mismo servicio, con un enfoque especializado en la realización de ciencia con metodologías experimentales. Ya sea como parte de un plan educativo o simplemente como un negocio prestado a individuos interesados, estos laboratorios sociales trasladan las ideas de la cultura DIY a la esfera de la ciencia ciudadana, otorgando los medios para que las personas aprendan a hacer ciencia con su practica, enseñandoles a solucionar problemas concretos de su comunidad con investigaciones empíricas. De esta forma, ayudan a distribuir el conocimiento científico de una forma mas didáctica y inmediatamente útil, muy distinta a como es comunmente recibido en escuelas y libros.\nEstos sitios no solamente ofrecen un lugar donde trabajar, sino también una comunidad que reune una gran variedad de actores: organizaciones sin fines de lucro, gobiernos, empresas sociales, y por supuesto, principalmente, ciudadanos comunes. La confluencia de estos entes se debe a que el laboratorio social es un lugar primariamente diseñado para la creación y experimentación de nuevas ideas, un lugar donde cualquiera puede probar, proponer, inventar, y encontrar nuevas ideas o hipótesis. Esto obliga a los laboratorios sociales ser espacios que sobrevivan al constante cambio, a la reconfiguración de sus herramientas según las necesidades de los usuarios, ser espacios flexibles y abiertos donde se pueden encontrar soluciones rapidas y conclusiones certeras sín importar el reto al cual se este afrontando.\nA pesar de su novedad, es un modelo que promete, mezclando aspectos de resolución de conflictos, estudios innovativos, aprendizaje didáctico e organización espontanea en un mix que podría tener un impacto bastante significativo en los modos de trabajo en donde se desenvuelven tanto ciudadanos como emprendedores y científicos. Por supuesto, hay un número de problemas con la manera en la que existen actualmente, como el riesgo de que sus usuarios se vuelvan parte del precariado, volviendo estos espacios un lugar de trabajo extraoficial, fuera del alcance de normativas laborales y derechos que les otorgaria un empleo regular.\n¿Que laboratorios sociales existen actualmente? La institución que inmediatamente viene a la mente cuando pensamos en modelos experimentales de laboratorio es el MIT Media Lab, una comunidad de investigación que activamente promueve \u0026quot;una cultura unica y antidisciplinaria que fomenta la mezcla no convencional de areas de estudio supuestamente dispares\u0026quot;[1]. Apoyado por una multitud de organizaciones en industrias y negocios variados, su principal misión es, mediante este arreglo en el que estudiantes de distintas esferas de la ciencia trabajan juntos, crear \u0026quot;tecnologías disruptivas que ocurren en las franjas, liderando areas como computación vestible, interfaces tangibles ... desde enfoques digitales al tratamiento de enfermedades neurologicas, hasta tecnologías avanzadas de imagen que pueden 'ver alrededor de una esquina'.\u0026quot;.\nDentro de esta comunidad, existe una multitud de programas conjuntos en los que sus integrantes trabajan con colaboradores del MIT. Cualquiera que desee ver los resultados de esta bomba de experimentación y distintas perspectivas solamente necesita ir a su canal de YouTube[2], donde estan alojados tanto conferencias y charlas como presentaciones cortas (menos de 5 minutos) de proyectos particulares, hechos por los investigadores. Es facil apreciar como su uso de tecnícas y herramientas desarrolladas en el sitio llevan a resultados un tanto interesantes y prometedores, como impresoras 3D que integran procesos biologícos en la fabricación de objetos[3]. Sín duda un modelo interesante a pesar de su obvia restricción en cuanto al personal que trabaja ahí.\nA pesar de que esta organización en particular solamente abarca la comunidad particular de los estudiantes del MIT, existén otros proyectos con un grado de accesibilidad mucho mayor, tal como el Medialab Prado[4] de Madríd, España. Este proyecto se trata de un laboratorio verdaderamente ciudadano, en el que cualquiera puede realizar propuestas y trabajar junto a otras personas en los proyectos que deseen. Su visión es de un laboratorio que sustente comunidades de aprendizaje y de práctica conformadas por personas de todo tipo de trasfondos, experimentando con metodologías y modos de trabajo en el proceso, transformandolos conforme se desarollan proyectos 'culturalmente libres'.\nPara este proposito, se hace un espacio completamente abierto al público, donde se acogen numerosos grupos de trabajo involucrados en el prototipado de una múltitud de proyectos. Mediante una plataforma online y numerosas fases de producción y debate, se genera \u0026quot;un contexto de intercambio de conocimientos y habilidades en torno a un problema colectivo\u0026quot;[5], y para solucionar estos problemas, se promueve la utilización de herramientas libres y código abierto. Periodícamente Medialab Prado publica información acerca de proyectos para los cuales se requieren propuestas, y despues en los talleres en que se desarollen estas propuestas se puede tanto ser promotor del proyecto como trabajar directamente como un colaborador. Aparte de ser un espacio donde pueden colaborar las personas, también se suelen alojar conferencias y actividades relacionadas dentro de el.\nAlrededor del mundo existen un multitud de similares espacios cuyo objetivo es integrar al ciudadano común en el proceso científico, plantenadose como una especie de transformacion tanto de la forma en la que se distribuye el conocimiento y se capacitan las personas, como del proceso de innovación y colaboración, con un enfoque social. Iniciativas tales como el SociaLab, que comenzó en Colombia[6], la Honey Bee Network[7], o el Climate CoLab[8] permiten a cualquier persona que disponga de tan solo un poco de curiosidad y algo de tiempo trabajar en proyectos científicos a gran escala, en cuestiones de traducción, diseño, mentoría, y por supuesto, analísis, investigación, y experimentación.\n[1]: \u0026quot;The MIT Media Lab at a Glance\u0026quot; [2]: \u0026quot;MIT Media Lab\u0026quot; [3]: \u0026quot;3D printing with living organisms\u0026quot; [4]: \u0026quot;Medialab Prado\u0026quot; [5]: \u0026quot;Medialab Prado - Qué es\u0026quot;\n","link":"https://opensciencelabs.org/blog/que-son-los-laboratorios-sociales-y-como-pueden-ayudar-los-equipos-de-investigacion/","section":"blog","tags":["laboratorios sociales","comunidad","ciencia ciudadana"],"title":"¿Qué son los laboratorios sociales y cómo pueden ayudar a los equipos de investigación?"},{"body":"","link":"https://opensciencelabs.org/tags/cambios/","section":"tags","tags":null,"title":"cambios"},{"body":" En otros de nuestros artículos publicados, te hablamos sobre Git de 0 a 100 e investigación colaborativa con Git. Allí hemos repasado sobre las bondades de este sistema y su uso actual en la colaboración en proyectos abiertos, grandes o pequeños, manejándolos con mayor eficiencia e inspección al ser un sistema de control de versiones distribuido, lo que indica que cada desarrollador tiene el historial completo de su repositorio de manera local y existe una copia central.\nNo solo los desarrolladores de software utilizan Git. Esta herramienta es útil en los casos donde necesites llevar a cabo proyectos colaborativos: por ejemplo, si tienes un blog, puedes gestionar los artículos y almacenarlos en un repositorio de Git.\nEn este post te presentamos algunos tips para que tu trabajo en git sea más productivo, posiblemente, que lo que ha sido hasta ahora.\nManeja las ramas adecuadamente Como te mencionamos en nuestro artículo Git de 0 a 100 en diez sencillos pasos puedes manejar distintas ramas en tu repositorio. En cada rama, se registran todos los cambios hechos por quienes la utilizan y también puedes realizar operaciones entre las ramas como su fusión, por ejemplo. Generalmente, las ramas son empleadas para desarrollar funcionalidades aisladas unas de otras. Por defecto el repositorio se crea con una rama, denominada \u0026quot;master\u0026quot;.\nEn el manejo de ramas debes considerar, entre otras cosas, lo siguiente:\nCualquier repositorio tiene o debería tener mínimo dos ramas: una conocida como master, que es la rama de producción, y la segunda rama, que se deriva de master, en la cual se desarrollan nuevas funciones o se corrigen fallos encontrados en master. A esta rama se le suele denominar develop.\nPuedes crear ramas derivadas de develop para desarrollar otras funcionalidades y/o corregir detalles de esta rama, suelen denominarse features.\nEn la rama master solo deben estar las modificaciones definitivas del proyecto, es decir, no debes \u0026quot;tocarla\u0026quot; hasta que estés seguro que los cambios en el proyecto no arrojen problemas al momento de hacer pruebas.\nDebes mantener actualizada la rama donde trabajes con la rama de donde se derivó.\nEvita mezclar cambios de diferentes ramas.\nVerifica la rama donde te encuentras al momento de editar cualquier archivo, así evitas realizar cambios y subirlos a la rama equivocada y afectar el desarrollo de todo el equipo de trabajo. Esto es sumamente necesario.\nCrea alias para los comandos de git que más utilices Con Git, a diario tecleas cierta cantidad de comandos, algunos que pueden tornarse repetitivos. Además, esta herramienta no ofrece la función de autocompletado. Puedes ser más productivo, si creas alias para aquellos que más utilices. El alias es un \u0026quot;nombre\u0026quot; que, en este caso, le asignamos a un comando de Git para que sea más corto, esto nos permite ejecutar la misma acción tecleando menos, es decir, nos ayuda a ahorrar tiempo y son más fáciles de recordar.\nPara fijar alias a los comandos utiliza git config --global. Por ejemplo:\n1$ git config --global alias.br branch 2$ git config --global alias.st status 3$ git config --global alias.ci commit De ahora en adelante escribes git br en lugar de git branch y así para los demás del ejemplo. No existe un estándar para la creación de alias, todo dependerá de que te sientas a gusto con ellos. A medida que aumentes tu trabajo con Git, utilizarás frecuentemente otros comandos, si te sientes a gusto no dudes en crear alias para ellos.\nJuntar commits en uno solo En la mayoría de ocasiones existen proyectos con muchas ramas, varios colaboradores y, por tanto, muchos commits. Para ahorrar tiempo y hacer el trabajo menos tedioso, puedes unir los commits.\nEsta alternativa requiere que tomes en cuenta algunas cosas:\nNo se recomienda mezclar cambios de diferentes ramas.\nEvita, en la medida de lo posible, que los cambios sean de distinto tipo (por ejemplo, un cambio en un archivo de texto y otro en uno de código), previniendo inconvenientes si por algún motivo debes luego deshacer los cambios.\nPuedes utilizar alguna interfaz gráfica para manejar Git Tal vez usar el terminal para gestionar Git puede resultarte al principio algo complejo, mayormente si estás iniciándote con el control de versiones. Por eso puede resultarte conveniente emplear algunos clientes gráficos de Git, para gestionar los proyectos de una forma visual e intuitiva y acelerar tu trabajo. Muchos de ellos son totalmente gratuitos, de código abierto y los hay para cualquier sistema operativo.\nEn la wiki de Git puedes encontrar una lista más completa de los clientes de Git\nLas interfaces gráficas se adaptan a distintos flujos de trabajo, es decir, algunas incluyen más funcionalidades que otras. No obstante, ninguna puede considerarse mejor que otra, solamente que cada una se ajusta a las necesidades de los usuarios. Vamos, ¡anímate a usar alguna de ellas!\nMás sobre los commits y otras recomendaciones Al comenzar una nueva sesión de trabajo, deberías hacer un fetch o un pull para traerte los últimos cambios. De esta manera, evitas conflictos en el futuro al sobrescribir el trabajo de los demás sin necesidad.\nHaz commit con frecuencia, no tengas miedo de hacer commits con cosas sin terminar y que se muestren así en el histórico.\nCada vez que tengas código que deseas guardar puedes hacer commit. Ten presente que al hacerlo no necesariamente debes hacer un push. Puedes hacer commits en tu repositorio local para proteger y llevar un control de tu trabajo.\nRevisa siempre los cambios antes de subirlos y asegúrate de confirmar en el commit lo que realmente necesites.\nEl mensaje de commit debe ser conciso pero al mismo tiempo informativo.\nNo subas cambios directamente a la rama master, siempre y cuando no lo amerite.\nTe hemos presentado algunos tips para que tengas un mejor manejo y mayor productividad al utilizar git en tus proyectos. Tal vez muchas de ellas son evidentes; sin embargo, por más mínimas que nos puedan parecer, debemos tenerlas presentes para evitar molestias en el proyecto y en el grupo de trabajo y aumentar así nuestra productividad en el control de versiones con Git.\nReferencias\nGit Book\nDomina Git desde cero\nLos 10 mandamientos del control de código fuente\n","link":"https://opensciencelabs.org/blog/cinco-tips-para-aumentar-tu-productividad-con-git/","section":"blog","tags":["git","ramas","repositorios","cambios"],"title":"Cinco tips para aumentar tu productividad con Git"},{"body":"","link":"https://opensciencelabs.org/tags/git/","section":"tags","tags":null,"title":"git"},{"body":"","link":"https://opensciencelabs.org/tags/ramas/","section":"tags","tags":null,"title":"ramas"},{"body":" Comúnmente, existe una visión de la ciencia que la dibuja como una actividad que se realiza de forma solitaria y apartada del grupo más numeroso de la sociedad, que es desarrollada por científicos asociales y que realizan sus investigaciones de forma privada, casi oculta, y comparten su descubrimientos solamente entre una comunidad selecta de individuos, casi todos hombres, hablando con un vocabulario rebuscado y imposible de entender.\nYa sea para buscar nuevas ideas, integrar más la comunidad científica en ámbitos populares, para obtener colaboradores con los que trabajar, o para que una mayor cantidad de personas adquieran conocimientos o habilidades relacionadas con una investigación, la ciencia ciudadana involucra tanto científicos y profesionales como a gente común, actuando como voluntarios en su proceso, es decir, en la \u0026quot;recolección y analísis sístematico de los datos, desarollo de teconlogías, pruebas de fenomenos naturales, y la difusión de esas actividades\u0026quot;1, para de esta forma romper generar un impacto mayor.\nEsta no es exactamente una práctica o idea nueva, pues ya antes tuvo otros nombres, como investigación participativa. Sin embargo, las nuevas tecnologías de comunicación (como las redes sociales) han ayudado a que la ciencia ciudadana disfrute de una especie de renacimiento. Hay una multitud de historias con gran notoriedad de personas totalmente desconocidas y ajenas a la comunidad científica que, gracias a tener la oportunidad de aportar su granito de arena, terminan descubriendo objetos celestes desconocidos, clasificando galaxias, identíficando especies de aves, etc. Estas personas son lo que se conocen como \u0026quot;cientificos ciudadanos\u0026quot;, personas comunes y corrientes que contribuyen con trabajo y datos a proyectos de investigadores académicos.\nAunque es imposible saber con exactitud quienes fueron los primeros científicos ciudadanos (ya que la ciencia como institución es relativamente reciente), se sabe que nuestros antepasados, sin ser exactamente investigadores o fílosofos dedicados, solian practicar una especie de astronomía amateur, haciendo la parte de observadores cuidadosos que simplemente, de forma intuitiva, descubrían cuerpos estelares y monitoreaban aves y otros animales. En la era moderna, se considera que los colonizadores americanos fueron los primeros científicos ciudadanos como tal, registrando información exhaustiva acerca del clima y la geografía, en un intento de entender cuando iban a caer las tormentas, usando datos de una limitada cantidad de personas y buscando patrones que podrián aparecer si se juntaban todos estos juntos.\nPorque ciencia ciudadana? Existen muchos motios por los cuales la ciencia ciudadana debe recuperar su papel en los aportes de la ciencia moderna. Te enumeramos algunos de los más notables:\nRecolección de datos: Dependiendo del objeto de estudio en cuestión, la participación de una cantidad de personas de una variedad de trasfondos y localidades puede ser necesaria para obtener una muestra lo suficientemente amplia y exhaustiva. La colaboración de estas en forma de recolección de ciertos datos (comportamiento de especies animales, estudio del movimiento de ciertas plantas, alertas de plagas, etc.) puede ser fundamental para la investigación, sin exigir necesariamente un sacrificio muy grande en cuanto a tiempo y esfuerzo se refiere.\nEducación mediante la practica: La ciencia ciudadana ofrece una oportunidad perfecta para que quienes normalmente no se mueva en un entorno de laboratorio científicos, pueda comenzar a participar en proyectos como investigadores, y para que también de esta forma empiecen a desarollar aptitudes y habilidades referentes al area en la que trabajen, sin mencionar los conocimientos que obtengan como resultado del estudio conducido.\nColaboración libre y abierta: Los proyectos de ciencia ciudadana suelen estar abiertos a todo tipo de personas, siempre y cuando estas quieran involucrarse: sin importar que sean estudiantes, profesores, trabajadores, jubilados, desempleados, etc. Los equipos científicos suelen establecer una plataforma mediante la cual pueden participar los ciudadanos. Por ejemplo, juegos que intenten explotar al máximo las capacidades intuitivas y racionales de las personas, necesarias para algún problema difícil de resolver, como Foldit 2, o aplicaciones que apunten a una audiencia regional, o en ciertos casos, internacional; y luego recojer datos desde ahí. De esta forma se puede recolectar datos desde una variedad de entes o grupos de personas de manera paralela. Es cierto que un equipo científico no puede estar en todos los lugares al mismo tiempo, pero de esta forma se pueden expandir el foco de la investigación sin sacrificios significativos.\nRetroalimentación: La ciencia ciudadana se establece una especie de diálogo entre los ciudadanos que aportan sus datos y los científicos que aportan sus conocimientos y enseñan métodos y analisis de estos. En esta relación \u0026quot;entrada-salida\u0026quot;, se logra plantear el problema estudiado dentro de parametros mucho mas amplios, obteniendo una nueva perspectiva que es una especie de síntesis entre la ciudadana y la científica. Los beneficios de estos se pueden ver principalmente en la area de cambio clímatico y biodiversidad, cuyas afirmaciónes suelen depender en estudios realizados mediante ciencia ciudadana3.\nQuienes hacen ciencia ciudadana? Como fue anteriormente mencionado, podemos ver el impacto que puede hacer esta colaboración primordialmente en áreas donde se le deja la tarea de clasificar y encontrar patrones a los ciudadanos. Un gejemplo interesante en este sentido, es el proyecto Penguin Watch 4, que permite a cualquiera aportar su granito de arena hacia 'entender cambios en la población de los pingüinos, y en sus índices de supervivencia y reproducción', mediante observación de fotos tomadas por drones y aviones, identíficando tanto pinguinos adultos y bebes como huevos de estos, y otros animales. Sitios como Zooniverse5 albergan una variedad de este tipo de proyectos, donde se les permite a ciudadanos comunes colaborar en proyectos tan extravagantes como Galaxy Zoo: Clump Scout, donde se estan buscando galaxias 'grumosas', pocas y aisladas en la gran fabrica del universo, aprovechando el incremento en el uso de instrumento de observación de astros.\nPara encontrar ejemplos de ciencia ciudadana que se hace en nuestro ámbito regional, solo hace falta buscar. En sitios como Ciencia Ciudadana en España6, se muestran una variedad de instituciones y su localidad dentro de un mapa, permitiendo a cualquiera facilmente participar y investigar mas en cuanto a estos proyectos. En Cuba, por ejemplo, el desarollo de ciencia ciudadana ha aportado mucho a programas de monitoreo de su biodiversidad, principalmente destinados a apoyar estudios de conservación de aves7. En proyectos como estos, se puede ver fácilmente en que áreas es mas eficaz la ciencia ciudadana: problemas en los que se puede establecer de forma facil una plataforma por la cual interactuan ciudadanos y cientificos, donde estos podrán realizar la tarea de forma relajada y así ayudar a encontrar patrones.\n","link":"https://opensciencelabs.org/blog/que-es-ciencia-ciudadana/","section":"blog","tags":["ciencia ciudadana","comunidad"],"title":"¿Qué es ciencia ciudadana?"},{"body":" ¿Como puedes tener total confianza y seguridad en que tu metodología es sensata, y de que tu investigación ha dado resultados certeros y facil de verificar? ¿Son veraces los estudios y descubrimientos de otros científicos?\nCiertamente, la capacidad de validar y repetir el proceso llevado a cabo por los investigadores es algo crucial a la hora de responder estas preguntas. Nos encontramos en un momento historico en el que podemos, mediante tecnologías digitales, acercarnos cada vez mas a satisfacer un criterio infalible de reproducibilidad en algunas areas (como la ciencia de datos). Escribir cada uno de los pasos realizados ya es una practica inherente al proceso de investigación en sí, debido a la necesidad de coordinar proyectos en los que colaboran cientos de personas, y al desarrollo de software que permite grabar y compartir este proceso de una forma eficiente y completa.\nAun así, paradojicamente, nos encontramos también en medio de una crisis en las ciencias, donde los resultados de una gran cantidad de experimentos son dificiles o imposibles de replicar [1], ya sea debido a ciertos limites en la investigación en sí o por otras razones. Siendo la reproducibilidad uno de los pilares del método científico como tal, estos dos hechos, tomados juntos, se hacen algo desconcertantes. Quizás sea importante repasar exactamente que consideramos como investigación reproducible y cuales son sus principios o metas, y que iniciativas o herramientas hay para asegurar esa condición.\n¿Qué hace reproducible una investigación? Podemos llamar a una investigación reproducible si ésta puede ser repetida por otros. En términos estrictos, esto simplemente significa que, contando con las herramientas necesarias, cualquiera puede tomar la descripción o grabación del experimento o estudio en cuestión para volverlo a realizar y verificar si el resultado es el mismo o lo suficientemente parecido (en tal caso, se dice que los resultados son replicables).\nPara que una investigación sea reproducible, por ende, se requiere que sus métodos, datos, herramientas y configuración, sean descritos de una forma detallada y precisa, dependiendo del área de conocimiento, y que esta información sea legible tanto por un ser humano como por una computadora. Esto, obviamente, se complica cada vez más dependiendo del tamaño de la investigación y su complejidad. Ciertas herramientas, como Jupyter, permiten realizar el analísis y, a la vez esquematizan y muestran comentarios sobre los pasos del experimento, dentro de un mismo entorno de trabajo, lo cual ayuda bastante. Sín embargo, al final del dia esto depende primordialmente de las decisiones que tome el investigador, y no hay ninguna herramienta que garantiza la reproducibilidad simplemente por ser usada.\nEn ese caso, ¿en torno a qué aspectos deberían tomar las decisiones los usuarios? ¿Cuáles preceptos éticos deben seguir para dirigirse hacia una investigación reproducible? En la siguiente sección hablaremos de los principios de la investigación reproducible.\nCuales són los principios de la investigación reproducible? Transparencia. Es importante recordar que, tal como cualquier otra cosa que te puedas imaginar (la realización de un plato de cocina, una canción, una pintura, etc.), sólo se puede decir que una investigación es reproducible si se pueden ver y entender los pasos que llevaron a su realización. Si realizas análisis de datos o elaboras algún tipo de código, por ejemplo, es necesario que tengas disponible toda la información referente al entorno (paquetes, configuraciones, carpetas del proyecto, dependencias, etc.) gracias a los cuales ejecutar el código, además de que es necesario que esté comentado rigurosamente para que otros puedan entender exactamente por qué funciona.\nMétodologia abierta. Siendo la ciencia una práctica colaborativa, es de bastante importancia mantener un alto grado de transparencia, como anteriormente mencionamos. Es importante también añadir que obligarte a compartir el procedimiento que llevaste a cabo no sólo te da mas confianza a la hora de compartir tus resultados, sino que también te anima a revisar cada paso dado y pensar si fue el correcto (y permite a otros verificar lo mismo, también).\nEnlazamiento de los resultados a los datos iniciales. Una investigación reproducible sistematiza su procedimiento de forma tal que se pueden ver claramente los datos de entrada, como estos fueron generados y por que proceso se analizan estos, ademas de hacerlos disponibles libremente (en cuanto sea aplicable). De esta forma, se traza una ruta desde los datos de salida hacia los de entrada, y viceversa.\nEstos tres principios se pueden aplicar independientemente del tipo de investigación. Claramente, será mucho más fácil compartir un entorno virtual que el Acelerador de partículas (en inglés Large Hadron Collider, LHC), pero lo importante es hacer tanto los datos como detalles respecto a la forma en la que fueron generados libremente disponibles, haciendo el experimento repetible, y por tanto, verificable por la comunidad científica.\n##Que herramientas hay para realizar investigación reproducible?\nSin duda, independientemente del tipo de trabajo que estés realizando, existe una variedad de opciones de software para lidiar con el problema de documentar, archivar, y esquematizar datos y archivos de una forma limpia y organizada, sin necesidad de tardar muchas horas describiendo estos en texto plano. Según Stodden et. al (2013)[2], hay cuatro tipos generales de herramientas en uso:\nComputación autoría y publicación alfabetizada. Ésta describe herramientas que permiten la creación de documentos que integran elementos rich media (codigo y demás) junto a texto (por lo general en Markdown o LaTeX) y demas archivos multimedia para presentar reportes que generan resultados tanto visuales como textuales en tiempo real. En este ambito, sin duda una de las mas populares es Jupyter, que soporta una cantidad abrumadora de lenguajes de programación (principalmente Julia, Python y R) sin perder sencillez o intuitividad.\nControl de versiones. Se refiere a aquellas herramientas que te permiten rastrear tu trabajo a lo largo del tiempo, tomando registro de los cambios y evoluciones que toma. De esta forma, permiten tanto volver a un punto anterior en el analísis sin empezar desde cero, como observar como cambia la investigación y las ideas referentes a ella cronologicamente. El sistema de control de versiones git es sin duda el mas popular, con una variedad de servicios web disponibles dependiendo de tus necesidades (tales como GitHub o Gitlab).\nRegistro de procedencia de los datos. Procedencia se refiere a mantener un registro de la cronologia y historia de los objetos de investigación, tales como datos, codigo fuentes, figuras, y resultados. Entre estas herramientas estan VisTrails, Kepler y Taverna.\nHerramientas que capturan y preservan un entorno de software. Algo increiblemente importante pero a la vez dificil y complicado de hacer es instalar y configurar una red de versiones especificas de dependencias, paquetes y herramientas para uso compartido entre tus colaboradores. Existen varios niveles de virtualización disponibles para llevar a cabo esta tarea, tanto la emulación completa de un entorno virtual especifico (como lo hacen Virtualbox of VMWare) o nada mas la creación de instancias separadas de espacios de usuario (como Docker).\n[1] https://www.displayr.com/what-is-the-replication-crisis/ [2] http://stodden.net/icerm_report.pdf\n","link":"https://opensciencelabs.org/blog/cuales-son-los-principios-de-la-investigacion-reproducible/","section":"blog","tags":["reproducibilidad","datos"],"title":"¿Cuáles son los principios de la investigación reproducible?"},{"body":"","link":"https://opensciencelabs.org/tags/acceso/","section":"tags","tags":null,"title":"acceso"},{"body":" Si estás interesado en practicar la ciencia abierta o simplemente quieres o necesitas conocer más acerca del tema, resulta de suma importancia que descubras sobre los datos abiertos. Es decir, datos que sean accesibles a cualquier persona con la finalidad que sean reutilizados y redistribuidos y no tengan grandes exigencias de permisos específicos para su descarga y procesamiento, los cuales te servirán para llevar a cabo cualquier proyecto que tengas en mente o culminar alguno. Sin embargo, la finalidad de este post no es hablarte específicamente sobre los datos abiertos, sino sobre algunos repositorios de datos abiertos. A pesar de esto, una pequeña introducción no está de más para entrar en confianza sobre el tema. Puedes visitar nuestro artículo sobre Datos abiertos aquí.\nLos repositorios de datos abiertos son almacenes de datos que tienen la finalidad de promover un entorno de libre acceso al compartirlos entre personas, permitiendo la creación de diferentes enfoques respecto a los datos manejados, obteniendo soluciones innovadoras e incentivando la redistribución y reproducibilidad en las investigaciones. En cualquier caso, en todos los países se necesitan datos de buena calidad que permitan identificar medidas públicas y privadas eficaces, realizar comparaciones y evaluar cambios en el tiempo con respecto a otros países, afianzar metas sociales, supervisar avances, entre otras cosas.\nEn la web puedes encontrar gran cantidad de repositorios y portales de datos abiertos que te dan acceso a la descarga y visualización de conjuntos de datos en diferentes formatos, los cuales también pueden utilizarse para dar solución a tareas académicas, hacer pruebas, probar herramientas de manejo de datos, entre otras situaciones afines.\nA continuación te contamos acerca de cinco repositorios de datos abiertos sobre algunos países, sin orden en particular:\n1. Portal de Datos de Europa Ofrece una recopilación de datos y metadatos referidos a contenidos publicados por entidades de la administración pública que se encuentran disponibles en portales de acceso público de los distintos países de Europa. De la misma manera, ofrece información sobre el proceso de suministro de datos y los beneficios de reutilizarlos. El portal está traducido en varios idiomas y cuenta aproximadamente con 976547 conjuntos de datos.\nUno de sus objetivos principales es promover la accesibilidad de los datos abiertos y su valorización, desde su publicación hasta la reutilización. El portal cuenta con varias secciones: Búsqueda de conjuntos de datos, Proporcionar datos, Utilizar datos y Formación y biblioteca donde básicamente encontrarás, entre otras cosas, buscadores de conjuntos de datos por categorías, por relevancia, fecha de creación, modificación y por ubicación, formación y módulos de aprendizaje sobre los datos abiertos, los beneficios que trae su utilización y referencias a otras iniciativas importantes en el área, también información para inclusión de datos desde otros portales. Es de gran ayuda si requieres conjuntos de datos sobre los distintos países de Europa, donde puedes realizar comparaciones a través del tiempo y entre distintos países, por ejemplo.\n2. Datos de libre acceso del Banco Mundial El Grupo de gestión de datos sobre el desarrollo del Banco Mundial promueve una iniciativa de acceso abierto y gratuito a datos sobre el desarrollo en el mundo, encargado de mantener conjuntos de datos sectoriales, macroeconómicos y financieros a los cuales se puede acceder por país o por indicador. Este grupo se encarga de coordinar el trabajo estadístico, preparar estudios sobre pobreza, documentos de investigación y otros trabajos sectoriales y económicos, como estrategias de atención a países. La información proporcionada por este repositorio proviene, en su mayoría, de los sistemas estadísticos de los países miembros y por tal motivo, la calidad de los datos depende de la eficiencia y calidad de dichos sistemas.\nComo usuario de los datos del Banco Mundial, puedes copiar, distribuir, adaptar, exhibir o incluir los datos con fines comerciales o no, sin costo adicional y sujeto a ciertas restricciones como: reconocer la autoría de los datos, no reproducir los logotipos o marcas registradas del Banco Mundial, no puedes afirmar que el Banco Mundial aprueba el uso que hagas de los datos, entre otras restricciones mínimas.\nDale un vistazo al Catálogo de Datos y al Banco de Datos del Banco Mundial que te servirá para complementar información.\n3. Portal de Datos Abiertos: Números para el desarrollo del Banco Interamericano de desarrollo Permite explorar, visualizar y descargar datos sobre indicadores socioeconómicos de América Latina y el Caribe. Los datos disponibles provienen de investigaciones y otras fuentes utilizadas por el Banco. En este portal puedes encontrar datos sobre distintos temas: educación, mercados laborales, integración global, pobreza, sexo y agricultura, entre otros.\nEl portal está dirigido a investigadores, estudiantes, responsables gubernamentales, analistas y otros que trabajen en temas de desarrollo y políticas públicas. Permite analizar más de 1000 indicadores de desarrollo de los países de América Latina (la dolarización, la deuda pública interna, salario mínimo y Cobertura por pensiones y seguro social, entre otros), seleccionar datos sobre los países en específico y por indicador.\nPuedes descargar los datos en formato '.xls' y '.csv' para compartir o reutilizarlos en tus proyectos. Asimismo, el portal te brinda formas de explorar los datos de los países a través de visualizaciones animadas e interactivas.\n4. Observatorio de la Complejidad Económica (OEC) El observatorio proporciona información confiable y clasificada según estándares reconocidos sobre aspectos comerciales y productivos de los países de todo el mundo. Posee una serie de menús: Países, Productos, Visualizaciones, Clasificación y Publicaciones, que garantizan el manejo eficiente y facilidad en el análisis de dichos datos.\nEn estos menús encontrarás descripciones con el contenido económico de los países que necesites, puedes acceder a la información contenida sobre los 200 productos más comercializados a nivel internacional, explorar los datos de forma gráfica, construyendo y filtrando la información de interés. También observarás un listado de los productos y los países clasificados de acuerdo a la complejidad económica, encontrarás artículos, notas y documentos referentes al avance del sitio en la explicación de la complejidad económica de los países. Puedes realizar búsquedas por periodicidad y profundidad, por año, categorías, países y realizar comparaciones entre ellos. Asimismo, los datos, visualizaciones y publicaciones se encuentran disponibles para su descarga y envío.\n5.Iniciativa de datos abiertos del gobierno de España Esta iniciativa lleva el nombre de Aporta y se desarrolló con el fin de promocionar la apertura de la información pública y desarrollo de servicios avanzados basados en datos en el Gobierno de España. Cuenta, entre otros productos, con la plataforma datos.gob.es que sirve como punto de encuentro entre todos los actores del entorno de datos abiertos en España: usuarios, ciudadanos o profesionales que demandan datos y/o quieren conocer novedades, aplicaciones o servicios relacionados con ellos. También organismos públicos que proporcionan y utilizan datos y que quieren estar al tanto de novedades del sector. Y demás personas que requieren fuentes de datos para crear productos y servicios que quieren dar a conocer.\nLa plataforma tiene una sección de Catálogo de datos donde muestra los conjuntos de datos disponibles (alrededor de 25.822 a la fecha) y permite realizar búsquedas por categoría, formato, publicador, nivel de administración, frecuencia de actualización y etiqueta. Este repositorio sirve tanto de punto de localización como de entrada a nuevos datos disponibles. Es una buena alternativa si quieres conocer o necesitas información sobre el desarrollo del Gobierno en España.\nEn Open Science Labs pensamos que cada país debe contar con un repositorio de datos abiertos, donde se encuentre información referente al desempeño del país en todos los ámbitos (social, económico, educativo, tecnológico, entre otros). Asimismo, apostamos a que se divulgue en cada país la cultura de los datos abiertos y aún más allá, la práctica de la ciencia abierta. Las estadísticas y datos de todos los países deben estar a disposición de cualquier ciudadano y/o institución, siempre y cuando el acceso y manejo de ellos se haga de manera responsable.\nEl Barómetro de Datos Abiertos es una medida global del grado en que los gobiernos están publicando y utilizando datos abiertos con el propósito de rendir cuentas, innovar y lograr un impacto social con beneficios a los ciudadanos.\nLos repositorios de datos abiertos que te mostramos son algunos de los muchos que están disponibles y te pueden ser de gran ayuda. En los siguientes enlaces encontrarás referencias a otros repositorios.\nBiblioteca Universitaria Huelva Biblioteca Universidad de Extremadura Portal de Datos Abiertos de la Unión Europea Gapminder Portal de Datos Abiertos de Esri España FAIRsharing Odisea OpenDOAR ","link":"https://opensciencelabs.org/blog/te-hablamos-de-cinco-repositorios-con-datos-abiertos-sobre-paises/","section":"blog","tags":["datos","repositorios","acceso"],"title":"Te hablamos de cinco repositorios con datos abiertos sobre países"},{"body":" El acceso abierto es un término que se utiliza para definir aquellos proyectos que están disponibles para todo público de forma libre y gratuita, en Internet o cualquier otro medio. En este tipo de proyectos se permite copiar, utilizar o distribuir el contenido con la condición de que se le den créditos al autor.\nSurgió con la finalidad de que las personas puedan acceder a la información sin tener que realizar una costosa inversión, evitar los arduos prótocolos que imponen los derechos de autor y facilitar la distribución de la información; eliminar las barreras de acceso.\nSe habla de una costosa inversión porque para publicar artículos de alguna investigación en la mayoría de las revistas reconocidas era necesario pagar una cantidad importante de dinero sin tener en cuenta los costos operativos que se tuvo en el proceso para lograr los resultados.\nAnálogamente, si se deseaba leer algún artículo o proyecto del cual se tenía una noción gracias al abstract o resumen, era necesario cancelar una suma de dinero. Esto muchas veces resultaba en pérdidas, ya que las descripciones no eran suficientes para comprender de qué trataba el documento completo y no coincidía con la intención de búsqueda.\nPor otro lado, las barreras de acceso también incurren en la parte académica porque muchas instituciones no cuentan con la facilidad de pago y los encargados de brindar la formación intelectual se limitan a la información que tienen a la mano.\nCon esto último podríamos llegar a pensar que el acceso abierto busca erradicar las publicaciones de pago, pero no es así. El objetivo del Acceso abierto es lograr que todas las personas se mantengan informadas y tengan la posibilidad de encontrar otra alternativa si no pueden cubrir los costos. Esto aprovechando que Internet nos brinda mucha libertad de información y respetando las normas y sus implicaciones legales. Así mismo, ya estamos en una era donde la digitalización juega un rol importante y las impresiones ya no son tan comunes como antes, los documentos pueden compartirse a nivel internacional fácilmente.\nEl acceso abierto engloba libros, revistas, artículos, código, datos, resultados, entre otros. Estos pueden ser de médicina, biología, ciencias sociales u otra área. La ventaja principal es el impacto sobre las publicaciones; reciben más vistas.\nPor otro lado, el acceso abierto no implica que los proyectos de investigación son 100% gratuitos, es más un aporte de científicos y estudiosos del área los que se encargan de cubrir los gastos y realizar las revisiones, ediciones y ajustes necesarios para la publicación. Es el entusiasmo por informar y lograr avances lo que define esta acción. Así mismo, los encargados de la investigación pueden recibir una especie de subsidio que les ayuda a mantenerse operativos en el trabajo.\nExisten diversos repositorios que permiten incluir, almacenar, mantener, organizar y difundir los archivos de las investigaciones según el área de estudio, estos repositorios pueden variar y ser totalmente académicos, de una biblioteca, una comunidad, entre otros.\nLas investigaciones y el acceso abierto Cuando se realizan investigaciones se plasma todo el proceso de estas en un documento que pudiese estar comprendido por los pasos que formaron parte de la investigación así como los resultados. Muchas veces este trabajo debe ser expuesto y válidado por una serie de especialistas para finalmente ser publicado.\nPor lo general, las publicaciones se realizaban en libros y revistas que pudiesen o no ser académicos, este proceso tiende a ser costoso y tarda un periodo considerable de tiempo según sea el caso. El acceso abierto elimina ciertas barreras que facilita el proceso de publicación lo cual implica una retroalimentación continua entre investigadores.\nEs importante tener en cuenta que el acceso abierto en las investigaciones, ya que permite promoverlas de manera efectiva a un amplio grupo de personas. Además, se reconoce el trabajo y la autoría, se puede encontrar respaldo de instituciones o empresas para nuevas investigaciones y son un punto de partida para la investigación colaborativa.\nEl acceso abierto puede ser considerado como punto fundamental para el progreso en la comunidad científica, los logros serán mayores y las personas tendrán mayor interés en los avances. Cualquiera que desee leer por interés académico, referencia, citar o por simple curiosidad lo puede hacer. Lo mejor de ello es que el plagio es más difícil y el mensaje podrá ser captado por mayor cantidad de personas.\nReferencias Suber, Peter.Una introducción al acceso abierto. En publicación: Babini, Dominique; Fraga, Jorge CLACSO,Consejo Latinoamericano de Ciencias Sociales, Ciudad de Buenos Aires, Argentina. 2006. pp 15-33 ISBN: 987-1183-53-4.\nDisponible en la World Wide Web: [http://bibliotecavirtual.clacso.org.ar/ar/libros/secret/babini/Peter%20Suber.pdf]\n¿Qué es el Acceso Abierto o el Open Acces? [https://youtu.be/-6qKCcRaaOA]\n","link":"https://opensciencelabs.org/blog/que-es-el-acceso-abierto-y-por-que-debes-tenerlo-en-cuenta-para-tus-investigaciones/","section":"blog","tags":["proyectos"],"title":"¿Qué es el acceso abierto y por qué debes tenerlo en cuenta para tus investigaciones?"},{"body":" Si eres una persona que escribe constantemente artículos para blogs o informes, utilizando para ello editores de texto convencionales, detente en este momento y pregúntate: ¿Qué pasaría con todo el trabajo que he venido escribiendo con mi editor de texto si ya no pudiera volver a utilizarlo? ¿Te asusta verdad?, y si no es tu caso imagínate, ¿si esto le ocurre a una persona que por años ha estado escribiendo un libro? Para combatir esa incertidumbre, puedes comenzar a escribir en texto plano y darle formato con la ayuda de Markdown.\nMarkdown es una herramienta creada en 2004 con la finalidad de convertir (texto plano)[https://es.wikipedia.org/wiki/Archivo_de_texto] a formato HTML (HyperText Markup Language)[https://es.wikipedia.org/wiki/HTML], usando para ello una serie de caracteres en diferentes casos, guiones o asteriscos por ejemplo, para iniciar una lista, entre otros. También es denominado como un (Lenguaje de marcado)[https://es.wikipedia.org/wiki/Lenguaje_de_marcado] que emplea texto plano y te permite obtener texto con formato, esto es, títulos, imágenes, negritas, cursivas, enlaces, entre otros. Markdown combina las ventajas que proporciona el texto plano con la necesidad de darle formato a lo que escribes y reducir los inconvenientes si la finalidad es exportar el contenido a la web.\nCuando te encuentres con un archivo .md significa que está escrito en Markdown. Puedes escribir texto en Markdown en cualquier editor (por ejemplo, en Windows con el Bloc de notas). El proceso de transformar o interpretar el Markdown a formato HTML, PDF u otro tipo de formato, se realiza con editores de texto creados específicamente para manejar este lenguaje. Los cuales están disponibles para que trabajes online u offline.\nEsta herramienta está siendo ampliamente utilizada en la actualidad por las personas que escribimos artículos para la web regularmente. Y te decimos escribimos porque los artículos de este blog están editados con Markdown.\nA continuación vamos a mencionar, sin orden de importancia, cinco cosas que no debes olvidar al trabajar con Markdown:\n1. Existen editores para cualquier sistema operativo (SO) El sistema operativo de tu computador, ya sea Windows, Linux o Mac OS, no es una limitante para usar Markdown. Puedes leer o editar texto en Markdown donde quieras o usar estos útiles editores que te sugerimos, que van destinados a usuarios iniciados y profesionales en el uso del lenguaje:\nPara trabajar online Dillinger StackEdit Según el Sistema Operativo Typora (cualquier SO) WriteMonkey (Windows) Laverna (cualquier SO) Haroopad (cualquier SO) Caret (cualquier SO) ReText (Linux) Boostnote (cualquier SO) Mark Text (cualquier SO) VSCode (cualquier SO) 2. Dile adiós a la engorrosa sintaxis HTML Si aún no utilizas Markdown, puedes comenzar ahora mismo, su sintaxis es simple y legible. Sabemos que al escribir en HTML estamos propensos a cometer errores debido a las famosas etiquetas de apertura y cierre y a la legibilidad en la estructura del texto. Incluso puedes emplear Markdown sin tener conocimientos sobre HTML. Atrévete, sácale provecho al uso de este lenguaje quedarás impresionado.\n3. Puedes hacer diferentes cosas El Markdown no es solamente usado para escribir y publicar artículos en la web. Puedes implementarlo para distintas tareas, tales como: tomar notas y apuntes, escribir informes, un libro, tesis, foros, entre otros.\n4. Accesible y compatible Puedes trabajar con Markdown en editores online y offline, como te mencionamos anteriormente. Por tal motivo, puedes acceder y editar archivos .md desde distintos dispositivos: tablets, computadores de escritorio, teléfonos inteligentes. Puedes leer este tipo de archivos de texto independientemente del editor, esto quiere decir que Markdown es compatible con otros formatos. De la misma manera, puedes ejecutar código, comentarlo y escribir texto en Markdown al mismo tiempo. Por ejemplo, utilizando Cuadernos de Jupyter o RMarkdown, entre otras herramientas.\nSi deseas conocer más acerca de los cuadernos de Jupyter, te invito a que revises nuestro artículo ¿Ya has probado los Cuadernos de Jupyter? Te explicamos qué son y cómo te ayudarán en tu próxima investigación..\n5. Usando caracteres le das formato al texto Así como lo acabas de leer, el formato en archivos Markdown se especifica mediante algunos caracteres como #, *, -, !, (), [], \u0026quot;\u0026quot;, ?, entre otros. Por ejemplo, si al comienzo de una línea dejas un espacio, luego de colocar una almohadilla (#) se activa el formato de título, donde el número de almohadillas seguidas indica el nivel del título. Asimismo, si escribes una palabra entre asteriscos el resultado de la conversión a HTML es la palabra en cursivas, si la encierras con dos asteriscos en negrita y tres en negrita y cursiva a la vez. Estos son algunos ejemplos. En los archivos Markdown puedes también añadir enlaces e imágenes a tu escrito.\nPuedes aprovechar desde ahora mismo el potencial de Markdown para tu vida académica y/o profesional, para comenzar cualquier proyecto colaborativo o simplemente tomar apuntes. Hay que resaltar que el usuario final, por ejemplo, las personas que leen tus artículos, no notan que escribes con Markdown. Sin embargo, el lenguaje está pensado para garantizar la comodidad y eficiencia del escritor.\nAcá te dejamos algunos enlaces a manuales e información importante sobre Markdown:\nGuía breve de Markdown (http://fobos.inf.um.es/R/taller5j/30-markdown/guiabreve.pdf) Información sobre Markdown (https://markdown.es/) Blog (https://joedicastro.com/pages/markdown.html) Referencias Página del proyecto Markdown, John Gruber\nBlog sobre Markdown (https://markdown.es/editores-markdown/)\n","link":"https://opensciencelabs.org/blog/cinco-cosas-que-no-debes-olvidar-al-trabajar-con-markdown/","section":"blog","tags":["markdown"],"title":"Cinco cosas que no debes olvidar al trabajar con Markdown"},{"body":"","link":"https://opensciencelabs.org/tags/markdown/","section":"tags","tags":null,"title":"markdown"},{"body":" ¿Estás interesado en integrar un poco de programación en tu rutina cotidiana?, ¿Necesitas aprovechar de la versatilidad y eficiencia que te otorga manejar con fluidez codigo?, ¿O simplemente quieres aprovechar de la utilidad de poder realizar análisis computacional?. Sea cual sea la razón, te podrías estar preguntando por donde empezar. Habiendo tantos lenguajes de programación disponibles, con una cantidad prácticamente infinita de usos, puede serte difícil decidir con cuál empezar a aprender o cuál aportará más a tu trabajo.\nProbablemente hayas escuchado de Python en algún momento, debido a que es un lenguaje con mucha difusión, que goza de una gran comunidad y patrocinio de grandes compañías (principalmente Facebook, Google, Amazon y Capital One). Se trata de un lenguaje interpretativo (no requiere ser compilado) y de alto nivel, lo cual lo hace perfecto para principiantes y cualquier tipo de persona que quiera entrar en el mundo de la programación. Si aún no te hemos convencido, aqui te damos mas excusas para aprender a usar Python en tu próóximo proyecto de investigación!\nLenguaje estándar para ciencia reproducible No importa cual sea la rama en la que te desenvuelvas, Python es una de las principales herramientas en la creación de investigaciones reproducible. Siendo un lenguaje que se presta muy bien a la creación de 'scripts' pequeños y modulares, ademas de ser bastante ligero y poseer su propio manejador de paquetes (pip), hace que la creación de un entorno virtual para investigación colaborativa y reproducible sea sencilla e indolora. Dejar disponible cóódigo libre usado en tu investigación hará mucho para garantizar su reproducibilidad, sobre todo si utilizas un programa de control de versiones como git, y esto no es algo que puedas hacer usando programas pre-compilados de código cerrado.\n##Gran cantidad de recursos y apoyo disponibles\nSiendo Python un lenguaje que cuenta con una gran comunidad internacional, hay un sinfín de libros y guías dispuestas a ayudarte en tu ruta de aprendizaje, en todo tipo de plataformas. Si tienes algún problema o duda, es cuestión de buscar o preguntar por algun sitio de consulta (como StackOverflow), y si lo que quieres es aprender a escribir código, hay un sinfín de posibilidades a tu alcance, desde cursos directos en sitios como Codeacademy, hasta libros como Python Crash Course o Learn Python 3 the Hard Way. Además, su uso común en ambientes académicos hace sencillo encontrar con quien colaborar.\nLibrerías dedicadas a análisis científico Hay una multitud de librerías de Python que reciben mantenimiento y apoyo regular por parte de desarrolladores y usuarios, y que son utilizadas muy comúnmente en ámbitos no solo de estadística o ciencia de datos, sino también en experimentos, dependiendo de la circunstancias. Librerías como matplotlib, Pandas, SciKit learn son usadas regularmente en una variedad de análisis, ya que proporcionan herramientas para manipulación y interpretación de datos de alto nivel en una gran cantidad de formatos, cuyos resultados pueden ser luego fácilmente mostrados de una forma visual e intuitiva sin sacrificar reproducibilidad.\nInterpretado y sencillo de aprender Ya que Python es un lenguaje de alto nivel (más parecido a nuestros 'lenguajes naturales', abstrayendo mucha de la lógica interna de la computadora), está diseñado específicamente para que el código escrito en este sea fácil de leer y entender, con uso significativo de espacios en blanco y constructos del lenguaje; se hace mucho mas intuitivo para aquellos que no esten acostumbrados a leer y escribir código. Además, que sea interpretado significa que no te tienes que preocupar por compiladores y demás tecnicismos.\nAutomatización de tareas manuales y tediosas Sin escribir mucho código, Python permite que muchas tareas de manejo e interpretación de datos o archivos (tales como comparación de dos tablas de datos, conversión de tipos de archivos, etcetera) se puedan automatizar de una forma rápida y sencilla. Sin mencionar que hay una cantidad enorme de apoyo para todo tipo de formatos de imágenes, películas, música, texto, etcetera. De hecho, este es el foco del libro Automate the Boring Stuff with Python un libro de acceso abierto para la lectura desde su sitio web.\nCreación de tu propio entorno de trabajo Con la continua creación de scripts y uso de librerías adaptadas a tu flujo y area de trabajo, eventualmente puedes automatizar y hacer mas eficiente gran parte de tu investigación, teniendo un conjunto de herramientas de código abierto y acceso libre a tu disposición, para que las puedas modificar y mejorar como desees. Si aprendes a integrar elementos de interfaz gráfica (GUI) en tu código, te sera aún mas fácil integrar de forma fluida scripts de Python en tus proyectos de investigación colaborativa, haciéndolos accesibles y sencillos de usar.\nVisualización y demostración de análisis Existen una gran cantidad de opciones en relación a librerías de Python usadas muy comúnmente en escritura de artículos de análisis computacional. Ya sea el anteriormente mencionado Matplotlib, librerías que enlazan R a Python, o 'cuadernos' como los de Jupyter. Existe una variedad de herramientas que permiten a cualquiera no solamente ver gráficos sino también fácilmente entender como fueron generados y experimentar con las variables y modelos usados.\nMultiplataforma y soporte en varias IDEs Python, al ser un lenguaje abierto, es inherentemente multiplataforma. Pero lo mas importante es la gran cantidad de entornos de desarrollo integrado (IDEs, por sus siglas en inglés) que soportan nativamente, sin necesidad de plugins, la sintaxis de Python, haciendo posible el uso de completación de código y el aprovechamiento de otras capacidades de la IDE que estés utilizando (como integración con git, programación visual y otras añadidas mediante plugins).\nScripting con librerías de multiples lenguajes de programación Debido a la facilidad y rapidez de escribir muchos scripts pequeños en Python, se han creado distintas utilidades que se apoyan a su vez en código anteriormente escrito con otros lenguajes (tales como C++) para interactuar con controladores de hardware, leer archivos con datos crudos, ejecutar operaciones que son mas eficientes a bajo nivel, etc. En pocas palabras, puedes usar a Python como si fuese una especie de \u0026quot;gestor\u0026quot; de una multitud de programas ya hechos, dándote aún mas flexibilidad sin complicar demasiado las cosas.\nComputación interactiva Python posee un terminal interactivo que te permite ejecutar y evaluar comandos de una forma directa, y 'recordar' comandos previamente utilizados al instante, además de importar librerías sin necesidad de correr archivos con código previamente escrito (en formato .py), definir variables, correr y grabar funciones, etcetera. Ciertas herramientas, como Jupyter, permiten integrar la shell dentro de una interfaz web, lo cual facilita a cualquiera a cualquier usuario interactuar con tus modelos y funciones libremente.\n","link":"https://opensciencelabs.org/blog/razones-para-usar-python-en-tu-proximo-proyecto-de-investigacion/","section":"blog","tags":["bibliotecas","herramientas","código"],"title":"10 razones para usar Python en tu proximo proyecto de investigación"},{"body":" Ya sea por temas de financiamiento, el uso de tecnologías de comunicación más avanzadas, o la necesidad de realizar proyectos interdisciplinarios, la investigación colaborativa es una práctica bastante frecuente. A pesar del enfoque histórico y el tratamiento en medios de comunicación, hacia descubrimientos individuales, y pese a la presencia de ciertos personajes carismáticos, la realidad hoy en día es otra: la gran mayoría de los científicos trabajan dentro de grupos donde los involucrados aportan al resultado final gracias a la retroalimentación constante, por encima de que muchas veces ni siquiera comparten la misma disciplina entre los investigadores vinculados. La eficiencia de la cooperación se hace notar por si sola, y la necesidad de dar resultados rápidos en proyectos cada vez más grandes, requiere de la creación de grupos con flujos de trabajos disciplinados y metodologías ágiles.\nLas prácticas de ciencia abierta (libre distribución de la información, disponibilidad de métodos, datos y herramientas usadas, colaboración abierta), son atractivas no solo por cuestiones éticas, sino también porque sirven de maravilla para el problema de organización de equipos. Además del uso de herramientas como Git para compartir código fuente y la información dentro de un grupo pequeño de investigadores para que todos puedan trabajar partiendo del mismo punto, el uso de los recursos compartidos libremente por otros y los posibles aportes o sugerencias de gente interesada en tu investigación puede resultar bastante significativo para tus proyectos.\n¿Cuáles son, entonces, las principales herramientas de una investigación colaborativa de ciencia abierta? Tomando en cuenta que necesitamos rapidez, disciplina, coordinación, y libre disponibilidad y colaboración entre todos los posibles integrantes de nuestro grupo, podemos afirmar que, por lo general, debemos usar las siguientes:\nControl de versiones El uso de software de control de versiones y de plataformas que alojen sus respectivos repositorios en la nube (como Github, Gitlab, Docker, etc.) se ha vuelto bastante esencial tanto para cuestiones de ciencia abierta como para desarrollo de todo tipo de software, desde scripts pequeños de procesamiento de archivos hasta videojuegos o modelado 3D. La seguridad que te otorga el sistema de respaldo, el alojar tus archivos en la nube, y la facilidad con la que te deja colaborar con tus colegas, añadiendo juntos archivos y revisiones al repositorio de una forma orgánica, lo hace una herramienta indispensable para todo tipo de proyecto que utilice código.\nEl libre acceso a tus proyectos mediante sus repositorios facilita también las tareas de divulgación de tu trabajo, localización de colaboradores, corrección errores en tu procedimiento, reproducción de tu investigación, y añadir tus proyectos a tu curriculum.\nManejo de equipos en tus repositorios Muchas plataformas que utilizan control de versiones, suelen ofrecer también herramientas para el manejo de equipos como la creación de cuentas, permitiendo restringir acceso a ciertas carpetas del repositorio, los cambios que hagan otros necesitan aprobación, se pueden asignar miembros del equipo para que revisen los cambios, etc. Si no posees de manera explícita esta forma organizar tu equipo, te cuento que puede resultarte bastante beneficioso, especialmente si trabajas con colegas en distintas disciplinas. Sitios como Github permiten anexar grupos, establecer una jerarquía clara entre grupos, administrar automáticamente la membresía del equipo de Github mediante un proveedor de identidad (o IdP, tal como Azure AD), además de ofrecer una plataforma donde pueden debatir y discutir. Aprovechar estas herramientas al máximo es crucial a la hora de organizar grupos que no puedan verse en persona.\nMetodología ágil El método ágil se refiere principalmente a un conjunto de prácticas que implementan los principios descritos en el manifiesto ágil, creado en el 2001 por personas que querían innovar en los modos tradicionales de gestionar proyectos de software. En términos generales, estas metodologías intentan enfocar el desarrollo del software hacia las necesidades de las personas y las interacciones cliente-desarrollador, apuntando hacia la 'entrega temprana y continua de software con valor'. De esta forma, se logra mantener un desarrollo constante, funcional y transparente, entregando software funcional regularmente mediante un flujo de trabajo sencillo y eficaz.\nExisten múltiples implementaciones de este método, una de las más populares siendo Scrum, un framework de procesos ágiles diseñado para manejar problemas complejos y adaptativos sin sacrificar valor, creatividad o productividad. Principalmente pensado para equipos pequeños de 10 miembros o menos, reemplaza un acercamiento algorítmico preprogramado, por uno heurístico que valora la capacidad de las personas de adaptarse y auto-organizarse en torno a problemas complejos emergentes. Para este objetivo, busca girar el proceso de trabajo en torno a 'sprints' que duren alrededor de un mes, donde, tras un proceso de planificación, se crea un producto usable (llamado un 'incremento') y se realiza una revisión del sprint. Se trata de una de las más famosas implementaciones gracias a que su efectividad ha sido comprobada empíricamente, para revisar esto puedes revisar el artículo Scrum and CMMI – Going from Good to Great. Scrum es comúnmente utilizado en empresas que desarrollan software, su uso en investigaciones científicas ya está siendo explorado.\nEntrenamiento en políticas de ciencia abierta Uno de los principales problemas a la hora de llevar a cabo proyectos de ciencia abierta es que, debido a su relativa novedad, muchas empresas e instituciones no tienen un esquema de trabajo o de políticas orientadas hacia su logro, mucho menos personas capacitadas en el área que puedan ayudar. Además, una cantidad importante científicos consideran que la forma más práctica de aprender a usar estas herramientas es trabajando con ellas.\nPor lo tanto, es crucial para los proyectos de ciencia abierta capacitar a sus integrantes para desarrollar implementaciones de estas políticas mientras trabajan, basándose en cómo se realizan en otras instituciones (ya sean empresas o gobiernos). Revisando temas de derechos de autor, propiedad intelectual, acceso abierto, o datos de investigación, aclarando la disponibilidad tanto de la investigación como los datos y métodos utilizados. Para leer más sobre esto puede visitar Open Science overview in Europe y Guidelines to the Rules on Open Access to Scientific Publications and Open Access to Research Datain Horizon 2020.\nIncentivo a la ciencia abierta Muchos científicos pueden tener dudas respecto a los métodos de remuneración o el financiamiento que pueden recibir por una investigación que se ate a principios de ciencia abierta. Actualmente buena parte de la comunidad científica no conoce en detalle el concepto de ciencia abierta, y por lo general se toma el libre acceso a publicaciones como principal requerimiento para que una investigación sea 'abierta'. También, desconocen si las instituciones de investigación y cuerpos de financiamiento tienen lineamientos y directrices en cuanto a acceso libre en cuanto a las publicaciones se refiere.\nPor lo tanto, es necesario para todo grupo u organización interesado en la realización de ciencia abierta establecer reglas y políticas claras, y altamente recomendado que establezcan incentivos (tales como criterios de contratación que busquen individuos anteriormente involucrados en investigaciones abiertas o incorporación de ciencia abierta en el desarrollo, apoyo y evaluación de personal científico, que son recomendaciones de una organización danesa, National Platform Open Science) para integrar mas investigadores dentro de esta esfera.\nUn artículo donde puedes leer más al respecto es Open science report: How to provide the skills researchers need?.\nReferencias Manifiesto por el Desarrollo Ágil de Software. (s. f.). http://agilemanifesto.org/iso/es/manifesto.html Home. (s. f.). Scrum.org. https://www.scrum.org/ Jakobsen, C. R., \u0026amp; Sutherland, J. (2009). Scrum and CMMI Going from Good to Great. 2009 Agile Conference. doi:10.1109/agile.2009.31 Open Science overview in Europe. OpenAire. https://www.openaire.eu/os-eu-countries \u0026quot;Guidelines to the Rules on Open Access to Scientific Publications and Open Access to Research Datain Horizon 2020\u0026quot; https://ec.europa.eu/research/participants/data/ref/h2020/grants_manual/hi/oa_pilot/h2020-hi-oa-pilot-guide_en.pdf Fingerle, B. (2022, 25 marzo). Open Science Report: How to Provide the Skills Researchers Need? ZBW MediaTalk. https://www.zbw-mediatalk.eu/2017/08/report-wie-bekommen-forschende-die-qualifikationen-fur-open-science/ Open Science – Nationaal Programma Open Science. (s. f.). https://www.openscience.nl/ ","link":"https://opensciencelabs.org/blog/aspectos-clave-en-el-manejo-de-equipos-de-ciencia-abierta/","section":"blog","tags":["investigación colaborativa"],"title":"Aspectos clave en el manejo de equipos de ciencia abierta"},{"body":"","link":"https://opensciencelabs.org/tags/investigaci%C3%B3n-colaborativa/","section":"tags","tags":null,"title":"investigación colaborativa"},{"body":" La Investigación colaborativa surge en el momento en el que varias entidades, que pueden estar especializadas en diferentes áreas, se establecen un mismo objetivo o proyecto. La finalidad de una investigación bajo este modelo es encontrar soluciones, descubrir o explicar comportamientos de un fenómeno en particular el cual puede ser económico, social, político, científico, entre otros.\nLa investigación colaborativa se presenta en distintas ocasiones donde se requiera un ciclo colaborativo de acuerdo a las necesidades que se presenten en un proyecto, se busca brindar aportes significativos en la sociedad o entorno.\nA continuación te mostramos algunos ejemplos en los cuales puede resultar útil implementar este tipo de investigación:\nUn departamento de una organización está ayudando a otro que tiene una deficiencia con respecto a la optimización de sus actividades.\nLos cultivos de una localidad se están viendo afectados por una plaga; esa plaga es similar a una ocurrida años atrás. Para estudiar las causas, consecuencias y prevenir futuros episodios como este, se han reunido varios biólogos expertos junto con historiadores, ingenieros agrónomos y especialistas en otras áreas.\nUn grupo de expertos en diversas disciplinas tienen en mente crear un documento que sea pieza fundamental en la conformación del presupuesto nacional del siguiente año fiscal.\nUn diseñador industrial está proponiendo un rediseño de uno de los productos de la empresa en la que trabaja. Para ello realiza un estudio con la ayuda de sus compañeros expertos en marketing y estadística. Con esto busca obtener una mejor perspectiva de los usuarios, sus necesidades y aceptación del mercado en general.\nUna institución privada desea financiar las actividades de una fundación. Para lo cual recurre a un grupo de expertos con la finalidad de evaluar y presentar un esquema del presupuesto y la descripción de lo que debe invertir para obtener los mejores resultados.\nCada una de las situaciones ejemplificadas requieren de la participación de distintos grupos multidisciplinarios que pueden estar formados por personas, entidades, institutos o grupos de trabajo que interactúen a la vez con la información. Esto puede ser de manera individual, en paralelo o en conjunto para conformar lo que sería el proyecto final. La idea es que, todos los miembros del equipo que llevarán a cabo el proyecto, cumplan con tareas especificas según sus conocimientos o aptitudes.\nLas tareas asignadas a cada miembro pueden o no depender condicionalmente unas de otras y deben promover el cambio y fomentar la participación. Esto implica que el proyecto estará sujeto a cambios constantes por la integración de nuevas ideas. Es aquí cuando nos podemos plantear ¿Cómo almacenamos todos los cambios que ocurren hasta que es alcanzado el objetivo final? ¿Qué debemos hacer si un miembro del proyecto elimina por accidente información importante?.\nPara esto proponemos el uso de los sistemas de control de versiones (VCS, por sus siglas en inglés) pues nos permiten almacenar todos los cambios realizados y la información asociada a ellos. En este caso te recomendamos el uso de Git.\nGit Es un sistema de control de versiones que se diferencia de sus similares por la forma en la que manejan sus datos; Git lo hace como una secuencia de copias instantáneas. Además, \u0026quot;todo es verificado mediante una suma de comprobación (checksum en inglés) antes de ser almacenado, y a partir de ese momento es identificado mediante esta, esto quiere decir que es imposible cambiar el contenido de cualquier archivo o directorio sin que Git lo sepa\u0026quot;.\nPara ejecutar la mayoría de las operaciones en Git solo se necesitan archivos y recursos locales. Estas funcionalidades te permiten hacer investigación colaborativa y que la información siempre esté salvaguardada.\nPor otro lado Git, al igual que otros VCS, posee un sistema de ramificación; el cual consiste en tomar la versión principal del proyecto para poder trabajar en ella individualmente, pero sin alterar la versión original, manejando así una especie de copia de esta. Hechas las modificaciones, la rama puede volver a fusionarse con el archivo de origen.\nTal vez pienses que el proceso de creación de ramas es lento y tedioso, debido a la cantidad de contenido o información en el proyecto, pero en Git esto resulta rápido y sencillo. Una de las ventajas de utilizar ramas es que, como colaborador, puedes trabajar de manera separada y eficiente, sin alterar la versión principal. Así mismo, puedes crear subproyectos constituidos por ramas de las cuales se deriven otras ramas.\nGit te permite obtener tu propio repositorio remoto o utilizar otros alternativos, con lo cual obtendrás el máximo provecho a la información y a su vez compartirás conocimiento rompiendo barreras de distancia.\nLa investigación colaborativa con Git es ideal para crear grandes movimientos y proyectos. Los avances y cambios llegarán en poco tiempo, los equipos de trabajo pueden crear ambientes amigables de trabajo y cada aporte puede ser cuestionado de manera positiva consultando a los involucrados oportunamente, respetando su autoría y tiempo de dedicación al proyecto.\nReferencia: The entire Pro Git book. Autores: Scott Chacon y Ben Straub\n","link":"https://opensciencelabs.org/blog/investigacion-colaborativa-con-git/","section":"blog","tags":["git","ramas"],"title":"Investigación Colaborativa con Git"},{"body":" Los datos se consideran, y así debe ser, la materia prima para realizar distintas actividades como la investigación, la toma de decisiones basadas en estadísticas, la divulgación de información, la colaboración entre proyectos y otras. Por tal motivo si estás manejando datos (independientemente de la cantidad) lo mejor es garantizar una buena gestión de ellos.\nSi estás leyendo esto es porque algo te motivó a conocer más sobre la gestión de datos y lo que debes poner en práctica para lograrlo. Comencemos por decir que gestión de datos está relacionada con el manejo de datos durante todo su ciclo de vida, es decir, desde que son recopilados o tomados de otras fuentes, hasta que se culminan las operaciones con ellos y/o son depositados finalmente para que sean utilizados por otros. La gestión de datos comprende una serie de prácticas, procedimientos, procesos y manejo de sistemas informáticos para ejercer control sobre los datos disponibles, ya sea en una organización, para un proyecto de investigación o en cualquier actividad donde la base fundamental sea el tratamiento de datos.\nEn este post no vamos a conocer en profundidad el amplio tema de la gestión de datos, pero si te daremos algunas sugerencias y recomendaciones para que, si estás ejecutando un proyecto, estas por iniciar alguno o hasta ahora tienes pensado hacerlo, puedas gestionar mejor los datos que se generen en este proceso. Los tips que te mostramos a continuación están basados fundamentalmente en la gestión de datos de investigación, pero pueden ser replicados fácilmente en otras actividades donde el protagonista sean los datos. Comencemos.\nSelecciona y organiza tus datos En cualquier proceso investigativode investigación se reúnen diversos conjuntos de datos, los cuales en la mayoría de ocasiones son de dimensiones grandes. El principal objetivo es garantizar que tus datos adopten los principios FAIR (Fáciles de encontrar (findable), accesibles, interoperables y reusables). Inicialmente necesitas organizar los datos por carpetas de acuerdo a cada tema que consideres. Teniendo en cuenta que al final de la investigación te aconsejamos que tengas una carpeta donde se encuentren los datos \u0026quot;crudos\u0026quot;, datos procesados y resultados.\nResulta importante que decidas los datos que verdaderamente son necesarios de preservar a largo plazo y qué datos eliminar, para lo cual te sugerimos limpiar tus datos y eligir aquellos que pueden ser útiles. Si en ocasiones necesitas llevar un control sobre todas las operaciones o cambios en tus datos, puedes utilizar herramientas como Git (enlace a artículo Git de cero a cien) para llevar un control de versiones.\nDocumenta y cita los conjuntos de datos que utilices Al igual que con cualquier recurso bibliográfico, los conjuntos de datos que utilices en tus proyectos que sean provenientes de terceros, deben ser citados siguiendo los estándares de acuerdo al tema que estes tratando. La citación adecuada de los datos de investigación brinda distintos beneficios, entre ellos: La investigación tiene mayor publicidad, promueves la reutilización de datos y puedes recibir un estímulo por usar y publicar los conjuntos de datos. Asimismo puedes comparar distintas publicaciones que usen el mismo conjunto de datos y sustentar las conclusiones de los investigadores o encontrar disimilaridades en los resultados.\nUn tema realmente importante en el mundo de los datos abiertos, el código abierto, y en fin, en la Ciencia abierta, es el de la documentación de los datos. La tarea de documentar es básicamente generar, preservar y dar acceso a toda la información sobre el contexto de los datos, su contenido y estructura, el proceso de generación o recopilación,la forma como van a ser utilizados (operaciones a ser realizadas), las transformaciones a las que han sido sometidos, entre otras operaciones que garanticen su reutilización e interpretación adecuada, ya sea por parte de las personas que los han creado o por otras personas interesadas en ello. Sugerimos que esta actividad comience junto con la investigación, para que no se obvie información importante.\nNo se podría hablar de documentar datos sin mencionar a los metadatos. Podemos referirnos a ellos como \u0026quot;datos sobre los datos\u0026quot; y nos permiten describirlos de forma estructurada y normalizada para lo cual existen estándares generales y especializados.\n3 Garantiza la seguridad y la reutilización de los datos\nLos datos siempre están expuestos a amenazas de seguridad, por ejemplo, acceso y manejo no autorizado, corrupción del conjunto de datos y también su pérdida parcial o total. Las siguientes alternativas podrán ayudarte a proteger tus datos:\nContar con un repositorio personal (respaldo) para los datos y el proyecto general, por ejemplo, utilizando unidades en red dentro de la institución, un repositorio institucional (si es el caso) o un repositorio personal (por ejemplo, en GitHub). Guardar los datos en la nube. Nunca olvides el uso de contraseñas robustas, capaces de resistir ataques informáticos. 4 Guarda tus datos en repositorios\nPara facilitar el acceso, preservación, reutilización y seguridad de los datos, te recomendamos que los deposites en repositorios creados para esto, o puedes crear tu propio repositorio. Esto no excluye la posibilidad de compartir los datos de tus proyectos de manera informal, por ejemplo, mediante una solicitud de correo electrónico. Sin embargo, esta no es la manera adecuada de hacerlo, ya que existen plataformas que te brindan la posibilidad de que tus datos estén a la disposición de cualquiera, por ejemplo, GitHub. Si usamos estas herramientas hacemos que otros investigadores puedan utilizar nuestros datos, o en otros casos hacer que un proyecto de investigación sea colaborativo (enlace a artículo investigacion_colaborativa e investigacion_colaborativa con git).\nDe la misma manera, puedes depositar tus datos en algunos repositorios que se encuentran disponibles de acuerdo al tema de estudio, para lo cual debes informarte sobre sus políticas y tomar una decisión sobre distintas alternativas que tengas, donde te garanticen los derechos como recolector de datos y la seguridad de los mismos.\nSi almacenas los datos de tu proyecto en un repositorio puedes conseguir financiamiento, ya que actualmente crece la cantidad de empresas que tienen esto como un requisito. Asimismo puedes protegerlos y hacer que tu tiempo y recursos invertidos estén de alguna manera \u0026quot;compensados\u0026quot;.\n5 Forma parte de la promoción en la apertura y licenciamiento de datos\nComo se mencionó al inicio, debes garantizar en la medida de lo posible, que tus datos sigan los principios FAIR. Para promover esa apertura existen condiciones referentes a la reutilización de un conjunto de datos, las cuales varían dependiendo del tipo de investigación y de cada caso en particular. Sin embargo, la ciencia abierta (enlace a artículo de ciencia_abierta) promueve el máximo grado posible de apertura de los datos de investigación, esto quiere decir que si tu propósito es \u0026quot;hacer ciencia abierta\u0026quot; necesitas comenzar por asignar licencias abiertas a tus datos, o con la menor cantidad de restricciones posibles.\nLas licencias especifican claramente las condiciones bajo las cuales se pueden reutilizar los conjuntos de datos y las operaciones que se pueden realizar con estos, además de las condiciones con respecto a la propiedad intelectual. Existen estándares de licencias para la apertura de los datos las cuales pueden ser usadas libremente.\nYa te hemos dado algunas sugerencias para que manejes mejor los datos de tus proyectos, recuerda que esto puede ser replicado para cualquier tipo de proyecto que estés realizando o tengas pensado ejecutar. Si continuas indagando sobre el tema de la gestión de datos, puedes toparte con algo denominado Plan de Gestión de Datos, el cual es un documento formal donde se plazma toda la información referente a los procesos y tareas a los cuales serán sometidos los datos durante todo su ciclo de vida. En resumen, es un documento que debe tomar en cuenta todos los aspectos que te mencionamos anteriormente.\nEsperamos que te haya servido esta información y de ahora en adelante comiences a ponerla en práctica en el manejo de datos de tus proyectos.\nReferencias\nComunidad global de gestión de datos Gestión de datos de investigación Recomendaciones para la gestión de datos de investigación\n","link":"https://opensciencelabs.org/blog/cinco-cosas-que-te-ayudaran-gestionar-mejor-los-datos-de-tus-proximos-proyectos/","section":"blog","tags":["datos","proyectos","gestión"],"title":"Cinco cosas que te ayudarán a gestionar mejor los datos de tus próximos proyectos"},{"body":" El manejo de los datos es un aspecto muy importante a considerar en los proyectos de ciencia abierta. Con respecto al almacenamiento y uso de los datos, hay un número nada despreciable de movimientos e iniciativas en boga que buscan un mayor grado de transparencia y distribución de la información en todo tipo de ámbitos. Principalmente en la esfera pública (en temas referidos a políticas gubernamentales, uso del presupuesto de los ministerios, etc.), son iniciativas que buscan hacer libres las investigaciones, técnicas y datos utilizados para justificar la información y politicas dadas por estas instituciones. Movimientos tales como el Partido Pirata prometen que, cuando estos datos estén disponibles, no solamente se ejecutarán las políticas de una forma más eficiente sino que se podrá garantizar la veracidad de la investigación permitiendo generar una fuerte confianza en ésta.\nPor esto mismo, el tema de los datos abiertos es tan popular en comunidades de ciencia actualmente. Dado que la posibilidad de contar con datos abiertos es ofrecida por tecnologías computacionales, el internet, e instrumentos de grabación ubícuos, en realidad es una simple extensión del dogma científico proponer que todos compartan sus métodos en un formato reproducible, legible tanto por humanos como por computadoras, y por lo tanto ayudar en cuanto la replicabilidad de sus investigaciones. Pero, ¿qué son datos abiertos? y ¿Qué exactamente queremos que sea parte del bien común?\nQue son los datos? Cuando nos referimos a datos, por lo general hablamos de un conjunto de materiales crudos que usamos en investigaciones, estudios y demás para derivar conocimientos de ellos. Ya sean resultados de encuestas, medidas de laboratorio, o grabaciones e imágenes del campo de estudio, se trata de la 'entrada' que recibe el proceso investigativo para su realización. En otras palabras, un 'dato' es una unidad de información.\nDurante el proceso investigativo los datos pueden ser analizados, estudiados, visualizados, coleccionados, medidos, etc. Para alcanzar un nivel aceptable de transparencia, estos pasos deben ser también anotados y convertidos en datos en si mismos. De esta forma los métodos utilizados pueden ser verificados y reproducidos por cualquiera con acceso a las herramientas adecuadas. Sin acceso, por lo menos escrito o grabado, al proceso mediante los cuales se obtuvieron los datos, no se puede confiar en estos y por lo tanto prácticamente carecen de significado.\nQue son datos abiertos? En la actualidad, una inmensa cantidad de datos son recolectados y procesados diariamente de forma casi automática como consecuencia del funcionamiento de empresas, organizaciones e individuos. Aunque estos datos en su mayoría pertenecen a entes privados y, por lo tanto, son puestos a disponibilidad de apenas una cantidad selecta de personas, su 'minado' y posterior uso ya ayudan muchísimo a la eficiencia y control del trabajo. Entonces, ¿que pasaría si esta enorme base de datos estuvieraa disposición del público para su libre uso?\nEso es lo que significa que algo tenga datos 'abiertos'. Según el Open Data Handbook, los datos abiertos son aquellos que pueden ser vistos, utilizados, reutilizados, y redistribuidos libremente por cualquier persona, y que se encuentran sujetos, cuando mucho, al requerimiento de atribución y de compartirse de la misma manera en que aparecen. De esta forma, 'abierto' puede aplicarse a información acerca de cualquier sujeto, ya sea en áreas como finanzas, ciencia, cultura, negocios, producción o cultura; siempre y cuando ésta esté sujeta a una licencia abierta para libre uso y beneficio al público. Por lo tanto, 'abierto' puede aplicarse también a información en una variedad de formatos, ya sean pedazos de texto enriquecido, imágenes, videos y hojas de cálculo entre otras.\nLo más importante es que los datos, para que sean 'abiertos', no deben ser simplemente liberados, sino deben también estar disponibles en formatos y lenguajes que puedan ser recibidos y procesados de forma significativa por una computadora. También deben estar sujetos a una licencia 'abierta', es decir, que mínimo permita su uso, modificación, y reproducción universales (sin restricción en cuanto a quiénes o cuántas personas lo pueden ver), y que según sea apropiado, permita también uso comercial, uso sin referencia alguna a los creadores originales, o modificación de la licencia en sí.\nPorque datos abiertos? El principal beneficio que proporciona tener datos abiertos en proyectos locales es la interoperabilidad, o la capacidad de diversos sistemas y organizaciones de trabajar en conjunto, usando los mismos datos sin restricciones o dificultades, inclusive sin siquiera organizarse entre sí. Quizá ya hayas disfrutado de esto, a la hora de consultar o revisar repositorios en Github, por ejemplo. De esta forma, todos pueden aprovechar al máximo los datos de todos, haciendo el trabajo más rápido y eficiente. Por esta misma razón se estima que los datos abiertos pueden aportar mucho a la economía, ya que en temas de finanzas harían mucho mas fácil tomar decisiones y, por ejemplo, estudios de mercado se podrían realizar de manera más sencilla.\nLa transparencia es también una de las principales razones por las cuales se exige datos abiertos, sobre todo en el ámbito gubernamental. Las instituciones públicas recogen una gran cantidad de datos al año, que cuentan como 'públicos'. Estos se podrián liberar mediante una política de Estado y así cualquiera podría, en teoría, revisar en función de sus intereses particulares y saber, por ejemplo, en que se gastan los impuestos o mediante cuál proceso se hacen leyes. Ya existen varios ejemplos de esto siendo realizado en un grado mas reducido, en proyectos como el Where does my money go? de Inglaterra, donde se muestra aproximadamente cuanto dínero es gastado en las distintas funciones de gobierno. Con un mayor grado de transparencia se promete que la corrupción se hará más difícil y habrá mayor participación de los ciudadanos en los procesos políticos y administrativos del Estado.\nTambién en el ámbito de las ciencias es importante considerar cuestiones de transparencia y reproductibilidad. Siendo los datos abiertos prácticamente la única forma en la que pueden replicarse los análisis computacionales, y siendo estos ahora muy comunes en todo tipo de investigaciones, el problema de la disponibilidad de los datos se hace integral para el cumplimiento del criterio de ciencia.\nSín duda los datos abiertos representan uno de los movimientos y tendencias mas interesantes e importantes dentro de la comunidad científica. Es imperativo para el progreso de la ciencia cambiar el paradigma de los lineamientos generales en cuanto a la publicación de la investigación y los hallazgos se refiere. Mas aún en una era donde la casi instantanea y amplia distribución de todo tipo de información posibilita la creación de redes colaborativas mas eficientes y grandes, investigaciones y analísis que no sacrifican reproducibilidad o documentación según se van volviendo mas complejos. Los datos abiertos son el primer paso a el establecimiento de una ciencia abierta, transparente y retroalimenticia, acelerando aún mas el proceso investigativo a la vez que se establecen practicas etícas y mas libertades, tanto para trabajadores en el area como aficionados o interesados.\n","link":"https://opensciencelabs.org/blog/que-son-los-datos-abiertos/","section":"blog","tags":["datos"],"title":"¿Qué son los datos abiertos?"},{"body":" Si eres una persona con deseos de desarrollar proyectos de código abierto que puedan ser compartidos, quieres replicar y /o mejorar proyectos existentes o convertirte en un científico de datos, es muy probable que hayas leído o escuchado sobre el Lenguaje R. En este post daremos un paso breve sobre sus características, las posibilidades de emplearlo en tus proyectos y las oportunidades laborales que tendrás cuando aprendas a utilizarlo.\nAntes de conocer sobre R, vamos primero a resaltar la importancia que tiene y ha tenido la Estadística en distintos ámbitos, ya te darás cuenta por qué lo hacemos. Como profesional en cualquier área, habrás estudiado o al menos te mencionaron la palabra estadística. El mundo y las situaciones cotidianas están rodeadas de incertidumbre y la estadística es la disciplina que se encarga de estudiarla. Sin embargo, para implementarla y conocer su gran potencialidad, resulta necesario manejar una herramienta que sea fácil de aprender, que cuente con la aprobación de un gran número de analistas de datos, que esté en constante actualización y que sea demandada en grandes empresas. En efecto, el lenguaje R cumple con estos y otros requerimientos.\nR fue desarrollado por los estadísticos Robert Gentlemann y Ross Ihaka del Departamento de Estadística de la Universidad de Auckland en 1993. El acrónimo R se deriva de los nombres de sus desarrolladores. Actualmente es un proyecto de software libre para la computación estadística y los gráficos. Es colaborativo, gratuito, de código abierto y se encuentra a cargo del R Development Core Team. Esto quiere decir, que detrás del proyecto existe una comunidad de usuarios y programadores que buscan mejorar y desarrollar nuevas funcionalidades para el lenguaje. R se perfila como un lenguaje para estadísticos, sin embargo cualquier persona interesada puede utilizarlo. Está pensado para que los usuarios implementen funciones estadísticas, desde las más básicas como el cálculo de promedios, la generación de publicaciones con aplicaciones web, la aplicación de técnicas de machine learning, hasta la generación de gráficos interactivos y de alta calidad. Tienes todo lo que necesitas en un mismo lenguaje.\nPuedes utilizar R a través de línea de comandos, sin embargo te recomendamos que utilices un Entorno de Desarrollo Integrado (IDE), por ejemplo RStudio (el cual desde octubre del 2022 se convertirá en Posit) que es uno de los más utilizados por su fácil empleo y las amplias funcionalidades que ofrece.\nAhora bien, ya que conoces un poco más sobre R, quizás en este momento te preguntarás:\n¿De qué me puede servir aprender este lenguaje?\nLa respuesta es simple pero extensa, aquí te presentamos algunas razones para que te animes a utilizar R:\nSi necesitas resumir, visualizar y analizar cualquier cantidad de datos, R es una buena alternativa porque es fácil de aprender. Solo necesitas tener a disposición un computador, tiempo y sed de conocimientos.\nCualquier funcionalidad estadística, como el cálculo de medidas descriptivas, la generación de gráficos potentes y de alta calidad (estáticos y dinámicos) pueden ser fácilmente implementados con R. Tienes todo lo que necesitas en un mismo lenguaje.\nMediante la generación de Scripts puedes tener almacenado y a disposición inmediata el código y los datos originales (por ejemplo un archivo .csv más el script de R) para resolver un problema en particular. Esto te permite reutilizarlo y también compartirlo haciéndolo reproducible y colaborativo.\nLos entornos de desarrollo integrado, como Rstudio, facilitan el desarrollo y te permiten manejar el lenguaje de una manera amigable. En una ventana podrás ejecutar el código, en otra se mostrará la salida, también tienes una ventana para ver las variables que has guardado y otra disponible para que guardes tu script, todo en un mismo lugar.\nR te permite obtener resultados detallados y generar reportes profesionales con ayuda de herramientas como Rmarkdown. Con esta funcionalidad puedes exportarlos a formatos como HTML y PDF. Tu jefe, o la persona interesada en tus reportes, quedará impresionado cuando le presentes un informe detallado utilizando R.\nComo mencionamos antes, es un software de gran demanda en el mundo laboral, y conocerlo puede mejorar tus posibilidades de empleo. Actualmente las empresas buscan analizar sus datos para tomar decisiones informadas y en base a ello, obtener ventajas competitivas. Por tal motivo, si cuentas con algunas habilidades para el procesamiento y análisis de datos, puedes darle valor a tu perfil profesional utilizando R.\nSi te animas, muy pronto podrás formar parte de los desarrolladores de R incorporando librerías y paquetes para funciones estadísticas.\nAunque no tienes que ser un estadístico ni un programador para usar R, te recomendamos que aprendas los aspectos básicos sobre la interpretación de estadísticas y gráficos, y de dónde se derivan; esto te será de gran ayuda a la hora de generar reportes y/o interpretar resultados. Lo más importante es la disposición y el ánimo que tengas, recuerda que R es fácil de aprender.\nEn la web, en libros y tutoriales disponibles en la página oficial de R encontrarás la documentación necesaria para que aprendas a utilizar este lenguaje y conozcas las funciones y paquetes a tu disposición. El acceso a la documentación de R es totalmente gratuita, una de las características más resaltantes del lenguaje.\nCon R puedes procesar datos de distintos formatos ya que, entre otras cosas, permite leer datos de diferentes software como SPSS, SAS o Excel.\nEl sistema operativo de tu computador tampoco es un inconveniente a la hora de trabajar con R, ya que es compatible con Windows, Linux y MacOS.\nComo R es de código y acceso abierto, permite hacer control de versiones usando una herramienta como Git, entre otras.\nActualmente se encuentran disponibles más de 2300 bibliotecas desarrolladas en R y puedes descargarlas a través del Comprehensive R Archive Network (CRAN). ¡Imagina todo lo que puedes hacer para procesar tus datos con estas bibliotecas!.\nEn el post Gigantes informáticos dan su apoyo al lenguaje de programación R indican que Microsoft, Google, HP y Oracle se han sumado al consorcio R porque apoyan el desarrollo de este lenguaje. Si esto es así, debe ser porque tiene altas potencialidades ¿qué opinas?\nDe la misma manera, grandes e influyentes empresas reconocen sus capacidades, entre ellas NASA, Banco Santander, Samsung, Western Union, eBay, Honda, Hyundai, Avon, Nestle, entre otros según lo mencionado en este post.\nQuizás también te preguntarás ¿tiene inconvenientes?\nPues si, aunque R es potente en el ámbito estadístico y de ciencia de datos, no es un lenguaje de programación de propósito general. Los lenguajes de propósito general, como su nombre lo indica, pueden ser utilizados con distintos fines, entre ellos la comunicación entre computadoras y dispositivos, el acceso y manejo de bases de datos, el diseño de imágenes o páginas, la creación de sistemas operativos, compiladores, entre otras cosas y, como ya mencionamos, R es utilizado principalmente como un lenguaje estadístico. Asimismo, en algunos casos, puede resultar lento si se compara con otros lenguajes de programación, como Python.\nA continuación presentamos dos estudios formales donde se refleja el lugar que ocupa R con respecto a su uso.\nLa 20ª Encuesta Anual de KDnuggets Software Poll 2019 la cual contó con más de 1.800 participantes, donde Python obtuvo el primer lugar. Sin embargo, R no se queda atrás en esta encuesta y junto con otro lenguaje llamado RapidMiner son usados aproximadamente por el 50% de los participantes.\nEn el Estudio de popularidad de lenguajes de programación PYPL PopularitY of Programming Language basado en la cantidad de tutoriales que se buscan en google, para este año R ocupa el séptimo lugar.\nQuizás estés pensando que no saber programar es una limitante para aprender R. Eso no debería preocuparte, porque hay una cantidad importante de tutoriales que pueden aportarte ideas para comenzar, y también puedes probar con códigos de ejemplo y datos reales que son de acceso abierto. En las referencias te dejamos algunos enlaces de tutoriales de R, libros y algunas Cheatsheets (hojas de referencia).\nAlgunos libros para que te inicies con R Libro R para principiantes\nLa traducción al español de “An Introduction to R”. Libro \u0026quot;Una Introducción a R\u0026quot;\nHojas de referencia \u0026quot;Cheatsheets\u0026quot; Manejo de datos\nRmarkdown\nReferencias Website de R\nR, un lenguaje y entorno de programación para análisis estadístico\nQUÉ ES R SOFTWARE\n¿PARA QUIÉN ESTÁ PENSADO R SOFTWARE?\n","link":"https://opensciencelabs.org/blog/que-es-el-lenguaje-r-y-como-puede-ayudarte-en-tus-proyectos/","section":"blog","tags":["rstudio","rmarkdown","proyectos","markdown"],"title":"¿Qué es el Lenguaje R y cómo puede ayudarte en tus proyectos?"},{"body":"","link":"https://opensciencelabs.org/categories/estad%C3%ADstica/","section":"categories","tags":null,"title":"estadística"},{"body":"","link":"https://opensciencelabs.org/tags/rmarkdown/","section":"tags","tags":null,"title":"rmarkdown"},{"body":" La investigación abierta despliega nuevos horizontes en distintos niveles, económicos, sociales, industriales, políticos e incluso en las ciencias puras. Esta investigación permite que los resultados de los estudios y de los procesos sean abiertos, respetando la licencia de conocimiento libre. Además, se publican los datos, procedimientos y otras herramientas de la investigación (cuadernos de notas, cuadernos de campo, videos de experimentos, datos de encuestas, etc.).\nLa investigación abierta, por lo tanto, no solo cuestiona el acceso parcial a los resultados finales, sino que se plantea el acceso todos los elementos intermedios comunicables y potencialmente útiles para otros investigadores. (David, den Besten y Schroeder, 2010)\nAños anteriores existía una limitación para el acceso y publicación porque para poder publicar los resultados o un artículo relacionado con la investigación era necesario recurrir a revistas. Estas revistas exigían al investigador una cantidad de dinero para costear la publicación y a su vez las personas que la deseaban leer debían pagar, logrando de esta manera que muchos no tuviesen el acceso a la información o no pudiesen hacer público su trabajo. Adicionalmente, en este tipo de publicaciones por lo general solo se refleja el procedimiento y los resultados obtenidos.\nEn el caso de la investigación abierta las publicaciones no son necesariamente gratuitas, pero se ha conseguido que investigadores almacenen, publiquen y compartan sus resultados, procedimientos y datos en repositorios a los cuales se puede acceder de manera gratuita principalmente por la web. Estos repositorios mayoritariamente corresponden a institutos, bibliotecas, revistas digitales y entes públicos. Es importante saber que los derechos de autor son respetados.\nPor otro lado, las ciencias puras se caracterizan por ver los cambios en entidades, entender, mostrar soluciones y considerar la aplicación de nuevas técnicas. Principalmente, se encargan de ensanchar el conocimiento básico de la naturaleza, excluye intereses prácticos. Además, este tipo de ciencia ha sufrido una serie de altibajos a lo largo del tiempo por la cantidad de información que revela, la cual puede no beneficiar a muchos intereses, es una práctica que requiere grandes inversiones y no siempre se cuenta con ella.\nAlgunos ejemplos de ciencia pura son:\nEl estudio de la evolución del universo y el lugar de la Tierra en el cosmos.\nObservación de ondas gravitatorias.\nEstudio de la genética de los osos polares.\nSíntesis y estudio de los compuestos que se basan en cadenas de carbono.\nSe dice que la investigación abierta podría cambiar el futuro de la investigación en ciencias puras porque esta brinda la posibilidad de compartir más que resultados, contrastar la investigación con otros enfoques o simplemente tener un punto de partida para investigaciones similares. Así mismo, puede funcionar como un medio que llame la atención de una serie de institutos que estén dispuestos a colaborar con los recursos necesarios para tener éxito en la práctica.\nPero no solo eso, con la investigación abierta se puede lograr unir distintos puntos de vista y establecer grupos de investigación colaborativa, logrando la universalidad del proyecto bajo el concepto de ciencias puras. La ventaja de esto es el avance de este tipo de ciencia que a su vez servirá como fundamento para las ciencias aplicadas, se abren nuevos logrando una mejora continua. Esto se debe a que las ciencias puras inspiran a la ciencia aplicada, es muy importante saber que sin estos dos tipos de ciencia las tecnologías y la nueva era no serian posibles por la capacidad de aporte de cada una.\nEjemplo\nUn grupo de científicos independientes estudiaron la genética de unos osos polares de la Antártida y encontraron que tienen características especiales con respecto al clima y su comida. Es importante entonces que los resultados se publiquen en revistas o plataformas que pueden difundir el tema. Es posible pensar en que se debiere hacer en una revista especializada, no obstante se requiere una cantidad de tiempo para que esto se logre satisfactoriamente. A corto plazo no es viable.\nMientras que si se decide publicar los resultados bajo investigación abierta se tiene que los resultados, los datos y otros aspectos generales y específicos estarán disponibles en un repositorio que a su vez puede recabar dinero a partir de donaciones y apoyo de instituciones para nuevas investigaciones.\nEn una visión más detallada el futuro de las ciencias puras depende esencialmente del interés de las personas de nuevas generaciones, la educación y el acceso a la información. Implicando de esta manera un esfuerzo continuo de las partes que conforman la sociedad. Cuando se implementa la investigación abierta para hacer ciencias puras se está permitiendo el incentivo de personas a realizar trabajos similares, se cubre en un abanico de necesidades de conocimiento y se permite la educación continua porque logra que los educadores, docentes y profesores tengan acceso a nuevos avances de manera gratuita y sin limitación alguna.\n","link":"https://opensciencelabs.org/blog/la-investigacion-abierta-podria-cambiar-el-futuro-de-la-investigacion-en-ciencias-puras-te-contamos-por-que/","section":"blog","tags":["datos"],"title":"La investigación abierta podría cambiar el futuro de la investigación en ciencias puras. Te contamos por qué."},{"body":" ¿Quieres cambiar tus artículos a un formato más intuitivo, legible y fácil de editar? Si tu respuesta es sí, puedes hacerlo con los Jupyter Notebook, una aplicación web que permite incorporar código y texto a los documentos de una forma sencilla y fluida; facilitando que otras personas colaboren en tu investigación. Utilizar estos elementos permitirá ver la descripción y resultados de tu analísis de una forma más gráfica y en tiempo real, algo especialmente útil para garantizar la reproducibilidad de tus resultados.\nEl uso de Jupyter Notebook es bastante común en las comunidades científicas actuales: por ejemplo, la creación de la foto de un agujero negro utilizó un cuaderno de Jupyter cuyo código está en este repositorio de GitHub. Así como este, existe una gran variedad de ejemplos de uso de cuadernos de Jupyter en todo tipo de áreas, los cuales usualmente están disponibles en un repositorio público de GitHub. Veamos a continuación, con más profundidad, de qué se trata esta aplicación.\n¿Qué es Jupyter? Jupyter se refiere a la organización de código abierto sin fines de lucro llamada Project Jupyter, que es la principal organización que desarolla una multitud de proyectos, entornos de ejecución principalmente en Julia, Python y R, de allí se construye su nombre. El principal propósito de Jupyter es “apoyar la ciencia de datos interactiva y la computación científica en todos los lenguajes de programación” (Jupyter). De hecho, todos sus proyectos son desarrollados de forma abierta en GitHub bajo la licencia modificada de BSD. El proyecto promete mantener disponible tanto el software como su código, para su uso libre.\nSin duda, la característica más popular de Jupyter Notebook, es ser una aplicación web que permite editar y compartir documentos (llamados \u0026quot;cuadernos de jupyter\u0026quot;) que contienen trozos de código, visualizaciones, ecuaciones, entre otras, todas interactivas y ejecutadas en tiempo real. La integración de los elementos rich media en documentos intuitivos y sencillos de editar, la ha convertido en una herramienta muy popular en la elaboración de artículos, análisis e investigaciones científicas.\nAdemás de Notebook, el proyecto Jupyter ofrece un entorno de desarrollo llamado JupyterLab, que posee una interfaz simple, personalizable y capacidades modulares para que puedas añadir nuevos componentes o plugins según lo consideres necesario. Jupyter Notebook y Jupyter-lab tienen una interfaz muy parecida, sin embargo, este último ofrece más funcionalidades.\n¿Qué es un cuaderno de Jupyter? Un cuaderno de Jupyter es simplemente un archivo .ipynb generado por la aplicación web, que contiene una multitud de ‘celdas’ con código, texto Markdown (en formato LaTeX), o metadatos (raw). Al ser interpretadas por Jupyter, estas celdas terminan teniendo una apariencia muy similar a la de un documento de texto, y tras ejecutar las celdas que contienen código, se muestra la salida en otra celda. Es muy común el uso de bibliotecas como matplotlib para mostrar gráficos (dentro de las celdas de código), pero gracias a su versatilidad, puede ser utilizado también para mostrar videos o imágenes que cambien o se actualizen a lo largo del tiempo, para mostrar enlaces a archivos locales o instalar kernels de otros lenguajes, lo cual amplía sus posibilidades.\n¿Cómo uso Jupyter? Si deseas hacer tu propio cuaderno de Jupyter y experimentar un poco, solamente tienes que ir al sitio web, donde encontrarás varias opciones para probar Jupyter con varios lenguajes de programación desde una interfaz web, sin tener que instalar nada. Dentro de esta página, puedes acceder a enlaces de entornos virtuales prefabricados dentro del sitio como MyBinder. Mybinder es un sitio en el cual podrás crear un entorno virtual a partir de un repositorio de github, con el que podrás interactuar y experimentar con tus cuadernos de Jupyter.\nSi deseas utilizar Jupyter desde tu computadora, basta con instalarlo utilizando pip o conda. Sin embargo, la popular distribución Anaconda incluye los paquetes necesarios para utilizar Jupyter, y es la opción recomendada por el propio Project Jupyter. Simplemente tendrás que dirigirte al enlace de descarga para instalarla. Después de esto, podrás ejecutar Jupyter Notebook desde la terminal, y acceder a la interfaz web desde la URL http://localhost:8888 (por defecto).\n¿Quién usa Jupyter? Jupyter es un proyecto apoyado abiertamente por empresas como Google (de hecho, puedes hacer cuadernos de Jupyter en el propio Google Drive, utilizando Google Colab), Microsoft e IBM. Además de una gran cantidad de universidades alrededor del mundo. No es extraño, que en el propio GitHub se encuentren alrededor de 5 millones de cuadernos de Jupyter (según un análisis que utiliza también un cuaderno para mostrar sus resultados! (nbestimate), y que abarquen áreas desde la ciencia de datos, estadística o economía, hasta las ciencias sociales o psicología. También existe una gran cantidad de listas curadas (A gallery of interesting Jupyter Notebooks) con ejemplos de aplicaciones reales de Jupyter.\nJupyter es, sin duda, una de las iniciativas de ciencia abierta más prometedoras que hay. Cuenta con una popularidad inmensa incluso fuera de su área de enfoque, y una accesibilidad bastante impresionante que permite a científicos, de todo tipo de trasfondos, aprovechar de sus capacidades rich media en cuestión de segundos. Y para aquellos que deseen entrar un poco más profundo en el tema, existe una gran cantidad de recursos y documentación de apoyo dedicado a Jupyter (Jupyter Guide) que hace de tu aprendizaje algo bastante sencillo e indoloro. Llevar tus investigaciones a otro nivel es cuestión de comenzar a aprender, ¡nada más!\nReferencias Jupyter\nnbestimate\nA gallery of interesting Jupyter Notebooks\nJupyter Guide\n","link":"https://opensciencelabs.org/blog/ya-probado-los-cuadernos-de-jupyter-te-explicamos-que-son-y-como-te-ayudaran-en-tu-proxima-investigacion/","section":"blog","tags":["jupyter","cuaderno"],"title":"¿Ya has probado los Cuadernos de Jupyter? Te explicamos qué son y cómo te ayudarán en tu próxima investigación."},{"body":"","link":"https://opensciencelabs.org/tags/cuaderno/","section":"tags","tags":null,"title":"cuaderno"},{"body":"","link":"https://opensciencelabs.org/tags/jupyter/","section":"tags","tags":null,"title":"jupyter"},{"body":" Alrededor del mundo, gracias a la importancia del sector tecnológico a nivel global, existe una gran cantidad de programadores, todos con sus destrezas, afinidades y aspiraciones particulares que hacen de sus proyectos colaborativos algo interesante y único, contribuyendo con su toque personal. Debido a la gran prevalencia de prácticas de código abierto en plataformas tales como Github, utilizadas por la mayoría de los desarrolladores de software existentes, se puede ver en ocasiones cómo el proceso mediante el cual proyecto se llevó a cabo y cómo pensaron respecto a ciertos problemas que se presentaron, cómo previeron cada mínimo detalle necesario para reproducir y crear de manera independiente el producto final, ya sea una pieza de software, un diseño de hardware, o inclusive algo tan común pero no menos importante como lo es una foto o un sonido, reproducibles en todo sentido de la palabra.\nTodo esto puede hacer el proceso de ver que tipos de proyectos la gente ha realizado, algo bastante interesante, inclusive más allá de la útilidad que el producto final te podría aportar. Ver como otros desarrolladores han pensado en torno a problemas específicos es algo que puede resultar increíblemente productivo a la larga, ya que te permite reconfigurar tu mente y encontrar métodos de resolución de problemas en los cuales quizás no hayas pensado, y quizás te des cuenta de que existen otros problemas en la forma en la que comunmente planteas tu flujo de trabajo.\nPara encontrar cualquier cantidad de proyectos increíbles en todo tipo de áreas (ya sea inteligencia artificial, ingeniería eléctrica, la física, los videojuegos o el procesamiento de imágenes y sonido) solo hace falta un poco de curiosidad y algo de tiempo libre. A pesar de que existen muchas iniciativas que pueden llegar a parecer algo sencillas o no muy claras, hay muchas personas cuyo trabajo está lleno de pasión, y realmente se merece tu atención. Desde lectores digitales de tinta electrónica D.I.Y. hasta inteligencia artificial que compone canciones basadas en tu estilo, te sorprenderá la cantidad de creatividad que pueden mostrar.\nHandmade Hero Handmade Hero1 es un proyecto en marcha que intenta \u0026quot;crear un juego completo, de calidad profesional, acompañado por videos que expliquen cada línea de su codigo fuente\u0026quot;. Se trata de directos de dos horas cada uno, hasta la fecha, han habido 609, mediante los cuales el programador (Casey Muratori) explica paso a paso cómo él crea un juego desde cero, desde la creación del entorno de programación en el cual se va a compilar el coóigo, pasando por una multitud de temas relacionados a escritura de código multiplataforma, salida de sonido, arquitectura del juego, manejo de memoría, renderización de gráficos, procesos de debugging, uso de OpenGL, voxeles, entre muchos otros más. En cuanto se lance el juego al mercado, éste se venderá junto al código fuente, el cual estará disponible bajo una licencia de acceso público después de dos años.\nThe Open Book The Open Book2 es un proyecto disponible en GitHub que busca crear una alternativa completamente libre y abierta a aquellos dispositivos que están especializados para la lectura de libros y otros documentos digitales. Tal como lo plantean en la pagina del proyecto: \u0026quot;Los libros están entre los documentos más importantes de nuestra cultura, pero aún asi, todos los dispositivos de lectura - el Kobo, el Nook, la Kindle e inclusive el iPad son todos dispositivos cerrados, operando como piezas pequeñas autónomas de plataformas grandes y cerradas cuyos dueños no suelen tener los mismos intereses que sus lectores\u0026quot;. Para este propósito, el Open Book esta diseñado de tal forma que el usuario pueda fácilmente añadir o quitar accesorios o pedazos de código según sea adecuado para sus necesidades, y tiene una documentación extensa en la cual se detalla tanto la preparación del circuito Arduino como las piezas necesarias y cómo ensamblarlas.\nLifeTrac Formando parte de la iniciativa Open Source Ecology3, como parte de un conjunto de modelos abiertos (llamado GVCS, o Global Village Construction Set4) que buscan ofrecer versiones de libre acceso de \u0026quot;aquellas 50 máquinas que se requieren para que exista la vida contemporánea\u0026quot;, el LifeTrac5 se trata, tal como su nombre lo indica, de un tractor multipropósito completamente abierto y de bajo costo. Resalta, además, por su diseño modular, con motores desmontables y partes que se comparten entre las demas máquinas de este conjunto, permitiendo que tenga la habilidad de 'cambiar' de forma rápida entre éstas. Este acercamiento al modelo le otorga además una vida útíl más larga debido a que le da una mayor facilidad de reparación. En su wiki ofrecen diagramas y planos detallados que permiten a cualquiera con las herramientas adecuadas fabricar cada pieza y ensamblarla sín restricción alguna respecto a su uso.\nMagenta Magenta6 es un proyecto de investigación multimedia utilizando Python y TensorFlow para \u0026quot;explorar el rol del machine learning en el proceso de creación del arte y la música\u0026quot;. Similar a otras iniciativas de inteligencia artificial, tales como MuseNet7, buscan crear algoritmos de entrenamiento y refuerzo profundo para la generación no solamente de archivos de audio, sino también de imágenes, dibujos, y otros materiales, con el propósito no tanto de \u0026quot;estorbar\u0026quot; o quizás \u0026quot;remplazar\u0026quot; artistas y músicos ya existentes, sino simplemente de proporcionarles herramientas inteligentes que actuén como una extensión de su flujo de trabajo actual. Si quieres ver los frutos de su investigación, puedes ver tanto los modelos que han creado hasta ahora en su GitHub como una lista de aplicaciones y demostraciones8 que han preparado los autores del proyecto, los cuales incluyen un percusionista que genera ritmos basados en las melodías que toques9, una inteligencia artificial que intenta emular tu estilo de composición10, y inclusive similares aplicaciones que funcionan como plugins de Ableton Live11.\n","link":"https://opensciencelabs.org/blog/algunos-proyectos-entretenidos-de-codigo-abierto/","section":"blog","tags":["código","proyectos"],"title":"Algunos proyectos entretenidos de código abierto"},{"body":"","link":"https://opensciencelabs.org/tags/equipos/","section":"tags","tags":null,"title":"equipos"},{"body":" La investigación colaborativa es un término que se le atribuye al hecho de realizar o llevar a cabo investigaciones y/o proyectos donde participan más de una persona, instituciones o empresas. La ventaja de este tipo de investigación es la unión de distintos conocimientos, experiencias y perspectivas que pueden resultar en innovaciones, aprendizajes mutuos y condiciones estables u optimas para enfrentar obstáculos.\nEs importante resaltar que cuando un grupo de personas trabajan de manera conjunta no se puede establecer directamente como investigación colaborativa. Este tipo de investigación esta más orientado al trabajo donde se comparten, respetan y forman ideas sin que existan jerarquías, es decir, sin un jefe que ordene la realización de actividades a los demás miembros del equipo.\nA continuación se presenta una serie de aspectos que se deben conocer sobre la investigación colaborativa:\nDialogo Cuando se aplica la investigación colaborativa se requiere de un dialogo profesional constante, en el cual hay negociación, una toma conjunta de decisiones, comunicación efectiva y aprendizaje mutuo. Esto implica que todas las personas involucradas tendrán una participación activa, expresando sus expectativas y la viabilidad del trabajo en conjunto. Lo que le va a permitir a cada una aportar sus ideas de forma productiva, crear un ambiente de confort y eliminar cualquier aspereza que se forme en el camino. Además de establecer las herramientas que los acompañarán en el desarrollo del proyecto.\nConfianza Cuando distintas personas trabajan a la vez e interactúan seguido es importante que entre ellos exista confianza. En este caso se basa en las visión de seguridad y creencia de las capacidades de cada uno de los miembros del equipo.\nAl existir confianza, cada persona podrá expresarse con mayor facilidad y se generará un ambiente de trabajo más productivo, donde cada una cumplirá su rol sin preocupación alguna y tendrá una perspectiva positiva con el trabajo de los demás.\nPlanificación Para lograr los objetivos de la investigación de manera satisfactoria se deben identificar todas las cuestiones, establecer e implementar un plan de acción. De manera que cada una de las actividades que se realicen estén delimitadas y cualquiera pueda colaborar teniendo en cuenta sus capacidades.\nSin embargo, la investigación colaborativa no puede ser programada detalladamente porque es un proceso dinámico en el que muchas veces es necesario hacer ajustes en varios aspectos, toma protagonismo la renegociación y con ello el dialogo. En pocas palabras, se planifica pero se debe estar sujeto a posibles cambios.\nFormalidades En la investigación colaborativa al contar con distintas personas trabajando a la vez es importante que se tengan en cuenta algunas formalidades. Esto para crear una conciencia de compromiso en cada uno de los miembros del equipo de trabajo. Dentro de estas se incluyen la planificación y el diálogo.\nConsiste esencialmente en definir roles y responsabilidades con la finalidad de aumentar las posibilidades de éxito.\nActitud Es un aspecto muy importante porque va a definir el rumbo del proyecto, principalmente en los casos en los cuales se encuentren obstáculos. Permitirá el aprovechamiento del tiempo y los recursos que se dispongan. Al tener un equipo con distintas capacidades y formaciones es necesario que cada persona sea entusiasta, abierta, tolerante, con ansias de aprender y tenga toda las características que implica la colaboración.\nCanales de Comunicación En este caso no existen limitaciones, las personas involucradas pueden ser de distintas nacionalidades, países o continentes, por tanto se emplea cualquier canal de comunicación. De manera física o digital, utilizando espacios o plataformas que se consideren adecuadas.\nControl de Versiones Es recomendable incluir un sistema de control de versiones en la implementación del proyecto, permitiéndonos revisar el progreso, asignar tareas y visualizar cambios.\nAdemás, afianzará la confianza y toda la información estará respaldada.\nExisten diversos sistemas que permiten realizar un control de versiones, una de ellos es Git.\nLimitaciones Es importante tener presente que quizá ocurran distintos inconvenientes, y que aparezcan en este caso las limitaciones. Pueden ser de carácter económico, social, personal, entre otros. El equipo debe estudiar y encontrar posibilidades que solventen estas situaciones. Existe la opción de delimitar la investigación.\nEn resumen, la investigación colaborativa presenta un conjunto muy interesante de oportunidades, crecimiento grupal o individual e implementación de nuevas tecnologías, innovaciones y cambios que pueden marcar la diferencia en pro de una mejor sociedad. Cada uno de los entes involucrados debe tener en cuenta que tanto su opinión como la de los demás es importante, la confianza, el respeto y los distintos canales de comunicación son claves para lograr un recorrido productivo para asi obtener un proyecto con buenos resultados.\n","link":"https://opensciencelabs.org/blog/todo-lo-que-debes-saber-sobre-la-investigacion-colaborativa/","section":"blog","tags":["investigación colaborativa","equipos"],"title":"Todo lo que debes saber sobre la investigación colaborativa"},{"body":" ¿Necesitas aprender Git para manejar con mayor eficiencia y control tus proyectos y trabajos? Ya sea para desarrollo de software, creación de páginas web, investigaciones científicas, o para manejar tus escritos, te podría ser muy útil aprovechar la seguridad que te da Git para el control de versiones, o la facilidad con la que permite la investigación colaborativa. Además, podría serte de mucha ayuda a la hora de buscar empleo en tu área de trabajo, ya que los proyectos y contribuciones que tengas almacenados en Git te servirán como parte de tu currículo. Sin embargo, puede parecerte algo intimidante debido a la gran diversidad de opciones que te proporciona, además del uso requerido de la línea de comandos en la aplicación Git. Pero si sigues los 10 pasos que presentamos a continuación, te darás cuenta de lo sencillo que puede resultar subir y manejar archivos en tu primer repositorio, crear varias ramas en el mismo y compartir archivos con colaboradores.\n1. Crea tu cuenta en Github Aunque es posible emplear git a nivel local, es preferible que utilices una plataforma que te permita alojar repositorios en la nube, tal como Github o Gitlab para difundir fácilmente tu trabajo. Puedes registrar una cuenta Github, donde simplemente tendrás que proporcionar tus datos y seguir los pasos de creación de cuenta. Luego de registrarla, podrás seleccionar un plan de pago cuando quieras, o simplemente usarlo de forma gratuita.\n2. Crea tu primer repositorio Inmediatamente después de crear tu primera cuenta, Github te guiará hacia la creación de tu primer repositorio, a través de https://github.com/new, donde tendrás que ponerle un nombre y una descripción. Github automáticamente genera el repositorio con un archivo README.md, el cual es un simple archivo de texto que será visto al entrar en la página del repositorio. Este archivo tiene información importante acerca del repositorio, el propósito de los archivos que están allí y de cómo está organizado. También puedes incluir en él algún enlace a la página web del proyecto (si la tienes), o un correo para contactos e información.\n3. Instala Git en tu computadora Para poder subir archivos a tu repositorio desde tu disco duro, tendrás que instalar Git en tu computadora. Simplemente descárgalo desde https://git-scm.com/, o, si estás usando Linux, instálalo mediante el gestor de paquetes de tu distribución buscando el paquete git. Después podrás usarlo en la línea de comandos. Verifica si se instaló correctamente ejecutando\n1git –-help 4. Clona un repositorio Cuando creas un repositorio Git, automáticamente se crea una carpeta oculta .git con información de los archivos y ramas de tu repositorio, los cambios a estos y el último commit. Tu repositorio en Github también contiene esta carpeta, así que, para ahorrarte un dolor de cabeza, deberías clonarlo (copiarlo en tu ordenador), ya sea descargándolo desde su página o en la línea de comandos escribiendo:\n1git clone https://github.com/(tu usuario)/(nombre del repositorio).git También puedes copiar la URL del repositorio desde la página.\n5. Agrega archivos a tu repositorio y haz tu primer commit Cada vez que realizas cambios en tu repositorio (ya sea modificando, agregando o borrando archivos), deberás sincronizarlos haciendo lo que se conoce como un commit. Puedes utilizar los comandos:\n1git add {nombre de tu archivo} 1git rm {nombre de tu archivo} para hacer cambios en la copia local de tu repositorio, ya sea añadir y modificar o eliminar archivos, respectivamente. Antes de sincronizar los cambios, debes ‘empaquetarlos’ en un commit, mediante el comando\n1git commit -m “{descripción de los cambios}” Después podrás sincronizar ese commit con el servidor de Github utilizando el comando\n1git push origin master Con aplicaciones gráficas como Github Desktop u otra similar, podrás realizar estos cambios de una forma mucho más intuitiva.\n6. Maneja distintas ramas de tu repositorio Cuando creas tu repositorio con git, este solo tiene una rama principal o “default”, la cual se denomina master. En git, una rama es una especie de ‘apuntador’ que señala a una serie específica de commits. Cuando quieras hacer cambios en tus archivos, para realizar pruebas sin afectar el funcionamiento del código alojado en la nube que ya sabes que funciona, puedes crear otra rama. Si los resultados son de tu agrado, podrás sincronizar ambas ramas más tarde.\nPara crear otra rama, simplemente ejecuta:\n1git checkout -b {nombre de tu rama} Esto hará que, a partir de ahora, todos los cambios que realices a tus archivos sean parte de la rama que has creado.\nSi deseas sincronizar tu nueva rama con el servidor de Github, ejecutas:\n1git push origin {nombre de tu rama} Igual que para hacer cambios en master, deberás hacer un commit para sincronizar los cambios locales con el repositorio de Github.\n7. Realiza un merge El comando git checkout nos permite cambiar de rama dentro del repositorio. Puedes usarlo para volver a hacer cambios en la rama master con el siguiente comando:\n1git checkout master Si estás satisfecho con los cambios que has hecho en la rama, puedes hacer un merge, lo que quiere decir que se fusionan los cambios hechos en la rama secundaria con los de la rama en la que estás ubicado actualmente (en este caso, master) de la siguiente manera:\n1git merge {rama con cambios} Git intentará hacer este proceso automáticamente, pero puede ser que hayan conflictos entre ramas con los cambios hechos. En este caso, tendrás que editar los archivos que te muestra Git, y agregarlos manualmente ejecutando\n1git add {nombre de archivo} 8. Verifica cambios con tu copia local En caso de que tu copia local del repositorio no tenga los cambios hechos hasta el último commit en la rama que estás trabajando, puedes actualizarla ejecutando\n1git pull Para ver los cambios que se han realizado entre las distintas ramas del repositorio, ejecuta el comando\n1git diff {rama fuente} {rama a comparar} También puedes ver la historia del repositorio (los commits hechos a lo largo del tiempo) usando el comando git log. Recomendamos que primero ejecutes git log –help para ver como puedes aprovechar mejor esta herramienta.\n9. Propone cambios a repositorios de terceros En caso de que quieras hacer un commit a un repositorio que sea de otra persona, simplemente tendrás que ir a la página del repositorio en Github, hacer un fork (una copia personal de ese repositorio, como un puente hacia el original), y clonarlo en tu computadora.\nLuego de crear los commit deseados y subirlos a tu fork, podrás dirigirte a la página donde este se encuentra y dar clic a New pull request (o solicitud de extracción). Esto te llevará a una página donde puedes evaluar los cambios que has hecho y crear una solicitud para que los propietarios del repositorio los fusionen con su rama master.\n10. Acepta o niega cambios propuestos Cuando un colaborador siga los pasos descritos anteriormente y haga una solicitud de extracción en tu repositorio, podrás verificar los cambios que se han realizado en el commit de su fork, además puedes ver su descripción y las sugerencias que han dado. Podrás entonces conversar con ellos en los comentarios de la solicitud de extracción, y dependiendo de lo que consideres apropiado, aceptar o negar los commit propuestos y fusionar su fork con la rama master de tu repositorio.\nEn caso de que quieras que un colaborador pueda contribuir al proyecto sin necesidad de aprobar sus commit, podrás invitarlos mediante la página de Parámetros (accesible desde la página del repositorio), simplemente dando clic a Colaboradores en la barra lateral izquierda y añadiendo su nombre de usuario de GitHub.\nSi has seguido todos los pasos hasta ahora, felicidades, ya puedes considerarte oficialmente un usuario de git. Mantener y actualizar tus propios repositorios y colaborar con los demás usuarios de Github es más sencillo de lo que parece. Si así lo deseas, puedes seguir buscando información acerca de cómo aprovechar git al máximo, ya sea a través del libro Pro Git o en la documentación de Github.\n","link":"https://opensciencelabs.org/blog/git-de-en-diez-sencillos-pasos/","section":"blog","tags":["git","repositorios","github"],"title":"Git de 0 a 100 en diez sencillos pasos"},{"body":"","link":"https://opensciencelabs.org/tags/github/","section":"tags","tags":null,"title":"github"},{"body":" Si buscas la democratización del conocimiento, oportunidades de intercambio y colaboración, mayor productividad científica, y mucho más, la Ciencia Abierta es el camino. La producción del conocimiento científico se verá revolucionado gracias a esta forma de hacer ciencia.\nLos avances constantes del internet y las redes han hecho posible y facilitan mucho más la búsqueda e intercambio de información en distintos ámbitos. Esto se considera un factor importante para el desarrollo de la Ciencia Abierta. Para mostrarte un concepto claro sobre este término, comencemos por citar algunas definiciones que se encuentran en la web y libros sobre el tema.\nLa ciencia abierta es la práctica de la ciencia de tal manera que otros puedan colaborar y contribuir, donde los datos de la investigación, las notas de laboratorio y otros procesos de investigación están disponibles gratuitamente, bajo términos que permiten la reutilización, redistribución y reproducción de la investigación, sus datos y métodos subyacentes (FOSTER)[https://www.fosteropenscience.eu/foster-taxonomy/open-science-definition]\nLa OCDE (2016) indica que “ciencia abierta se refiere a los esfuerzos para hacer que el proceso científico sea más abierto e inclusivo a todos los actores relevantes, dentro y fuera de la comunidad científica, como lo permite la digitalización”.\nSegún (The Royal Society, 2012) la ciencia abierta se define como “datos abiertos (disponibles, inteligibles, accesibles y datos utilizables) combinado con el acceso abierto a las publicaciones científicas y la comunicación efectiva de sus contenidos”\nPodemos resaltar entonces, que la ciencia abierta es un movimiento, una manera de ver y hacer ciencia, que busca crear una cultura donde la información de todo el proceso de investigación científica, ya sean los datos, protocolos, cuadernos de laboratorio, resultados obtenidos en las diferentes etapas de este proceso, sean gratuitos y de libre acceso. De esta manera, todas las personas involucradas en el proceso de investigación, ya sean los propios científicos, instituciones de investigación y financiamiento, y público en general, pueden contribuir y colaborar con el esfuerzo de investigación. Con esto se garantiza que el trabajo científico sea abierto e inclusivo, donde el investigador se percate que poner a libre disposición sus trabajos le garantizan, entre otras cosas, el aumento del impacto y difusión de sus investigaciones.\nLa ciencia abierta es una forma de producir conocimiento científico promoviendo la comunicación y acceso efectivo del contenido de las investigaciones científicas en todas las áreas (instrumentos de trabajo, resultados intermedios y finales) mediante la digitalización y las bondades del internet.\nEl acceso al contenido de algunas publicaciones científicas hasta hace pocos años se realizaba, en la mayoría de ocasiones, por medio de revistas donde mayormente había que pagar para obtener los papers y resultaban muy pocos los documentos gratuitos. Estas publicaciones solo reflejan el procedimiento y los resultados obtenidos, con el movimiento de la ciencia abierta. Esta forma de hacer ciencia tradicional se combina con nuevas y novedosas herramientas digitales con el fin de poner a libre disposición no sólo las publicaciones finales, sino también los datos de la investigación, el software, notas de laboratorio o los cuadernos de trabajo, evaluaciones por pares, entre otros.\nEste enfoque busca que las distintas etapas del proceso de investigación esté abierta a la revisión, crítica, participación y colaboración, aportes para mejoras, reproducción y reutilización para todos los involucrados, creando nuevas formas de acceder al conocimiento científico.\nLa ciencia abierta es un enfoque compuesto por distintas disciplinas relacionadas. Según el proyecto FOSTER sobre ciencia abierta incluye 8 elementos:\nOpen notebooks (Cuadernos abiertos) Datos abiertos Revisión abierta Open access (Acceso abierto) Sotfware libre de código abierto Redes sociales académicas Ciencia ciudadana Recursos educativos abiertos Todos estos aspectos afectan de una u otra forma el ciclo completo de la investigación. En el blog NeoScientia mencionan algunos de estos componentes como grados de apertura de la ciencia, estos son: Open Research, Open Access, Open Notebook y CrowdScience. Otros autores las denominan como iniciativas que incluye la ciencia abierta. Distintas formas de clasificarlos, pero todos con el mismo fin, la disponibilidad gratuita de todos los recursos de investigaciones científicas.\nPuedes visualizar en la siguiente figura la taxonomía sobre la ciencia abierta.\nA continuación mencionamos algunos beneficios de la práctica de la ciencia abierta:\nPara el investigador:\nOfrece mayor impacto y difusión de sus trabajos, a la vez que ganan reconocimiento y fuentes para trabajos futuros. Brinda distintas maneras de publicar los artículos. No pierdes la autoría o méritos al publicar de manera abierta. Puedes ajustar el derecho al uso de la información que publicas, protegiendo el contenido en torno a licencias Creative Commons o Science Commons Cuando interactúas con otros investigadores sobre trabajos en temas similares, puedes aprender de forma más rápida y eficiente; evitando que trabajos parecidos sean duplicados. Para las empresas de financiamiento (públicas o privadas):\nPracticando la ciencia abierta, estas empresas y los estadistas se convencerán que los procesos de investigación son más reconocidos y de mayor calidad. Para los usuarios y público en general: En este enfoque la producción de conocimiento es eficiente, democrática y permite atender mejor a las demandas sociales. Como usuario tienes posibilidades para contribuir e intervenir en cualquier proceso de conocimiento abierto. Puedes encontrar las respuestas que buscas mediante la democratización del conocimiento. El aumento actual en la práctica de la ciencia abierta a despertado iniciativas en personas e instituciones de varios países, desde hace pocos años. Creando emprendimientos, comunidades y proyectos sobre ciencia abierta. A continuación mencionamos algunos:\nFOSTER\nOpen Knowledge Foundation\nODSL (Open Data Science Latam)\nDatalat\nOpen Science Comunity Leiden\nOpen Knowledge Foundation\nAmelica\nAssociation of European Research Libraries LIBER\nMonuMAI\nEn resumen, la ciencia abierta busca cumplir con los requerimientos actuales y futuros en lo que se refiere al acceso, reproducción, publicación y colaboración en investigaciones de cualquier disciplina. La ciencia abierta es un movimiento que ha revolucionado la forma de ver y hacer ciencia, y en nuestra opinión es el futuro.\nReferencias Anglada, Lluís; Abadal, Ernest (2018). “¿Qué es la ciencia abierta?”. Anuario ThinkEPI, v. 12, pp. 292-298.\nCurso de Open Science para investigadores del CSIC\nPortal de FOSTER\nBlog NeoScientia\nBlog Cientópólis\n","link":"https://opensciencelabs.org/blog/que-es-la-ciencia-abierta/","section":"blog","tags":["datos"],"title":"¿Qué es la ciencia abierta?"},{"body":"","link":"https://opensciencelabs.org/tags/governance/","section":"tags","tags":null,"title":"governance"},{"body":"","link":"https://opensciencelabs.org/tags/mentor%C3%ADas/","section":"tags","tags":null,"title":"mentorías"},{"body":"The objectives of this document include formalizing the governance of the Open Science Labs (OSL) project. In both common and uncommon situations, outlining the decision-making procedure and the interactions between the various members of our community, including the relationship between work that may be supported by for-profit or nonprofit organizations and open source collaborative development.\nSummary OSL is a community-owned and community-run project. To the maximum extent possible, decisions about project direction are made by community consensus (but note that \u0026quot;consensus\u0026quot; here has a somewhat technical meaning that might not match everyone's expectations -- see below). Some members of the community additionally contribute by serving on the OSL (Eunice Rodas, Ever Vino, Ivan Ogasawara, Luis Casas), where they are responsible for facilitating the establishment of community consensus, for stewarding project resources, and -- in extreme cases -- for making project decisions if the normal community-based process breaks down.\nCommonly, everyone is responsible for specific areas or tasks and, if there is anything that needs to be decided by the group, this person brings this topic to one of our contributor's meetings and we can discuss and decide that together. The main criteria we have that should be respected is that the content should be related to an \u0026quot;open\u0026quot; topic (private technologies are not allowed, for example), and the access to that information should also be open (references to private content is not allowed neither). So, we try to have an open space for everyone to bring their ideas and have also the space to implement that idea as well, the steering council first main goal is to help contributors to share their ideas before to put it in practice.\nThe project Open Science Labs (OSL) is a community that aims to join people from all parts of the world, specially from Latin America countries and create an open space for teaching, learning and sharing topics around open science and open computational tools.\nOSL also motivates initiatives about English language because it increases the possibilities of collaboration in open projects across the world.\nThe software developed by OSL initiatives are released under some OSI approved license (such as BSD, Apache 2.0, or MIT), built openly and hosted on public GitHub repositories under the OpenScienceLabs organization.\nThe Project is conducted by a distributed team of contributors, who are individuals that have collaborated with code, documentation, graphical design or other kind of work to the Project. Anyone can be a Contributor. Contributors can be affiliated with any legal entity or none. Contributors participate in the project by submitting, reviewing and discussing GitHub pull requests and issues and participating in open and public Project discussions on GitHub, discord, among other channels. The basis of project participation is openness and transparency.\nThe Project Community consists of all Contributors and Users of the Project. Contributors work on behalf of and are responsible to the larger Project Community and we strive to keep the barrier between Contributors and Users as low as possible.\nIn order to improve transparency and a better fiscal workflow, OSL is currently looking for a fiscal sponsor to help our project to grow.\nGovernance This section describes the governance and leadership model of The Project.\nThe principles of Project governance are:\nOpenness \u0026amp; Transparency Active Contribution Institutional Neutrality Diversity, Equity and Inclusion Education Consensus-based decision making by the community In general, all project decisions will be made by consensus of all interested Contributors. The primary goal of this approach is to ensure that the people who are most affected by and involved in any given change can contribute their knowledge in the confidence that their voices will be heard, because thoughtful review from a broad community is the best mechanism we know of for creating high-quality software.\nThe mechanism we use to accomplish this goal may be unfamiliar for those who are not experienced with the cultural norms around free/open-source software development. We provide a summary here, and highly recommend that all Contributors additionally read Chapter 4: Social and Political Infrastructure of Karl Fogel's classic Producing Open Source Software, and in particular the section on Consensus-based Democracy, for a more detailed discussion.\nIn this context, consensus does NOT require:\nthat we wait to solicit everybody's opinion on every change, that we ever hold a vote on anything, or that everybody is happy or agrees with every decision. For us, what consensus means is that we entrust everyone with the right to veto any change if they feel it necessary. While this may sound like a recipe for obstruction and pain, this is not what happens. Instead, we find that most people take this responsibility seriously, and only invoke their veto when they judge that a serious problem is being ignored, and that their veto is necessary to protect the project. And in practice, it turns out that such vetoes are almost never formally invoked, because their mere possibility ensures that Contributors are motivated from the start to find some solution that everyone can live with -- thus accomplishing our goal of ensuring that all interested perspectives are taken into account.\nHow do we know when consensus has been achieved? First of all, this is rather difficult since consensus is defined by the absence of vetos, which requires us to somehow prove a negative. In practice, we use a combination of our best judgement (e.g., a simple and uncontroversial bug fix posted on GitHub and reviewed by a core developer is probably fine) and best efforts (e.g., all substantive API changes must be posted to a github issue or a discussion on discord in order to give the broader community a chance to catch any problems and suggest improvements; we assume that anyone who cares enough about OSL to invoke their veto right should be on the github OSL repositories or discord). OSL, is a small group, and aims for quick and transparent communication, so the common channels for communication are the github issues and the discord channels. So, all people involved can have a quick and transparent communication about any specific problem and we can react very quick.\nIf one does need to invoke a formal veto, then the process should consist of:\nan unambiguous statement that a veto is being invoked, an explanation of why it is being invoked, and a description of what conditions (if any) would convince the vetoer to withdraw their veto. If all proposals for resolving some issue are vetoed, then the status quo wins by default.\nIn the worst case, if a Contributor is genuinely misusing their veto obstructively to the detriment of the project, then they can be ejected from the project by consensus of the Steering Council -- see below.\nSteering Council The Project will have a Steering Council that consists of Project Contributors who have produced contributions that are substantial in quality and quantity, and sustained over at least one year. The overall role of the Council is to ensure, with input from the Community, the long-term well-being of the project, both technically and as a community.\nDuring the everyday project activities, council members participate in all discussions, code review and other project activities as peers with all other Contributors and the Community. In these everyday activities, Council Members do not have any special power or privilege through their membership on the Council. However, it is expected that because of the quality and quantity of their contributions and their expert knowledge of the Project Software and Services that Council Members will provide useful guidance, both technical and in terms of project direction, to potentially less experienced contributors.\nThe Steering Council and its Members play a special role in certain situations. In particular, the Council may, if necessary:\nMake decisions about the overall scope, vision and direction of the project. Make decisions about strategic collaborations with other organizations or individuals. Make decisions about specific technical issues, features, bugs and pull requests. They are the primary mechanism of guiding the code review process and merging pull requests. Make decisions about the Services that are run by The Project and manage those Services for the benefit of the Project and Community. Update policy documents such as this one. Make decisions when regular community discussion doesn’t produce consensus on an issue in a reasonable time frame. However, the Council's primary responsibility is to facilitate the ordinary community-based decision making procedure described above. If we ever have to step in and formally override the community for the health of the Project, then we will do so, but we will consider reaching this point to indicate a failure in our leadership.\nCouncil decision making If it becomes necessary for the Steering Council to produce a formal decision, then they will use a form of the Apache Foundation voting process. This is a formalized version of consensus, in which +1 votes indicate agreement, -1 votes are vetoes (and must be accompanied with a rationale, as above), and one can also vote fractionally (e.g. -0.5, +0.5) if one wishes to express an opinion without registering a full veto. These numeric votes are also often used informally as a way of getting a general sense of people's feelings on some issue, and should not normally be taken as formal votes. A formal vote only occurs if explicitly declared, and if this does occur then the vote should be held open for long enough to give all interested Council Members a chance to respond -- at least one week.\nIn practice, we anticipate that for most Steering Council decisions (e.g., voting in new members) a more informal process will suffice.\nCouncil membership A list of current Steering Council Members is maintained at the page About.\nTo become eligible to join the Steering Council, an individual must be a Project Contributor who has produced contributions that are substantial in quality and quantity, and sustained over at least six month. Potential Council Members are nominated by existing Council members, and become members following consensus of the existing Council members, and confirmation that the potential Member is interested and willing to serve in that capacity. The Council will be initially formed from the set of existing Core Developers who, as of late 2015, have been significantly active over the last year.\nWhen considering potential Members, the Council will look at candidates with a comprehensive view of their contributions. This will include but is not limited to code, code review, infrastructure work, mailing list and chat participation, community help/building, education and outreach, design work, etc. We are deliberately not setting arbitrary quantitative metrics (like “100 commits in this repo”) to avoid encouraging behavior that plays to the metrics rather than the project’s overall well-being. We want to encourage a diverse array of backgrounds, viewpoints and talents in our team, which is why we explicitly do not define code as the sole metric on which council membership will be evaluated.\nIf a Council member becomes inactive in the project for a period of six month, they will be considered for removal from the Council. Before removal, inactive Member will be approached to see if they plan on returning to active participation. If not they will be removed immediately upon a Council vote. If they plan on returning to active participation soon, they will be given a grace period of one month. If they don’t return to active participation within that time period they will be removed by vote of the Council without further grace period. All former Council members can be considered for membership again at any time in the future, like any other Project Contributor. Retired Council members will be listed on the project website, acknowledging the period during which they were active in the Council.\nThe Council reserves the right to eject current Members, if they are deemed to be actively harmful to the project’s well-being, and attempts at communication and conflict resolution have failed. This requires the consensus of the remaining Members.\nConflict of interest It is expected that the Council Members will be employed at a wide range of companies, universities and non-profit organizations. Because of this, it is possible that Members will have conflict of interests, such ones include, but are not limited to:\nFinancial interests, such as investments, employment or contracting work, outside of The Project that may influence their work on The Project. Access to proprietary information of their employer that could potentially leak into their work with the Project. All members of the Council shall disclose to the rest of the Council any conflict of interest they may have. Members with a conflict of interest in a particular issue may participate in Council discussions on that issue, but must recuse themselves from voting on the issue.\nPrivate communications of the Council To the maximum extent possible, Council discussions and activities will be public and done in collaboration and discussion with the Project Contributors and Community. The Council will have a private channel on discord that will be used sparingly and only when a specific matter requires privacy. When private communications and decisions are needed, the Council will do its best to summarize those to the Community after eliding personal/private/sensitive information that should not be posted to the public internet.\nSubcommittees The Council can create subcommittees that provide leadership and guidance for specific aspects of the project. Like the Council as a whole, subcommittees should conduct their business in an open and public manner unless privacy is specifically called for. Private subcommittee communications should happen on the main private discord channel of the Council unless specifically called for.\nInstitutional Partners and Funding The Steering Council are the primary leadership for the project. No outside institution, individual or legal entity has the ability to own, control, usurp or influence the project other than by participating in the Project as Contributors and Council Members. However, because institutions can be an important funding mechanism for the project, it is important to formally acknowledge institutional participation in the project. These are Institutional Partners.\nAn Institutional Contributor is any individual Project Contributor who contributes to the project as part of their official duties at an Institutional Partner. Likewise, an Institutional Council Member is any Project Steering Council Member who contributes to the project as part of their official duties at an Institutional Partner.\nInstitutions become eligible to become an Institutional Partner when they share same values of Open Science Labs and are available to collaborate to the project in any of these ways:\npublicizing open science labs in their social network allocate one or more contributors to help Open Science Labs projects or other affiliated projects funding Open Science Labs activities offering mentoring for Open Science Labs Contributors when contributing to their projects (defined by the Partner). offering opportunties for contracting Open Science Labs Conbributors who have contributed to their projects (defined by the Partner) If at some point an existing Institutional Partner doesn't accomplish with these points mentioned above, then six month grace period begins. If at the end of this six months period they continue not to have any contribution, then their Institutional Partnership will lapse, and resuming it will require going through the normal process for new Partnerships.\nFunding acquired by Institutional Partners to work on The Project is called Institutional Funding. However, no funding obtained by an Institutional Partner can override the Steering Council. If a Partner has funding to do Open Science work and the Council decides to not pursue that work as a project, the Partner is free to pursue it on their own. However in this situation, that part of the Partner’s work will not be under the Open Science Labs umbrella and cannot use the Project trademarks in a way that suggests a formal relationship.\nInstitutional Partner benefits are:\nAcknowledgement on the Open Science Labs websites and in talks. Ability to influence the project through the participation of their Council Member. Council Members invited to Open Science Labs Developer Meetings. A list of current Institutional Partners is maintained at the page About Us.\nDocument history https://github.com/opensciencelabs/opensciencelabs.github.io Acknowledgements Substantial portions of this document were adapted from the NumPy project governance and decision-making document https://github.com/numpy/numpy/commits/main/doc/source/dev/governance/governance.rst.\nLicense CC BY-SA 4.0: https://creativecommons.org/licenses/by-sa/4.0/\n","link":"https://opensciencelabs.org/guidelines/governance/governance/","section":"guidelines","tags":["governance"],"title":"Open Science Labs Project Governance"},{"body":"This is an initial version of Open Science Labs Roadmap.\nTopics that were not considered yet on this document but should be added here in the near future are:\nCommunity Engagement Infrastructure Social media In this document, we are focusing on our three current main areas: events, internship and partnership.\nEvents Open Science Labs motivate anyone and any group from the community to organize events about open science and technologies.\nFor open science and technologies we mean any topic about science or technology that its usage is not restricted by license or agreements. Examples of topics that is accepted:\nOpen Source Open Data Open Access Open Science Open Source Initiative (OSI) licensed libraries Open Source programming languages Science using open source software DevOps using open source technologies Any area of science (if the content is not restricted by a pay wall) This list is just an example of topics accepted, but it is not limited to that. Some examples of topics that is NOT ACCEPTED:\nPrivate and restricted projects Proprietary technology A non open access paper discussion A proprietary operation system A proprietary programming language Now, there are two events that is happening periodically:\nPyCafé DevOps webinars Plans:\nFor these events, a plan is needed to reach to reach out more people and increase the engagement.\nOther meetings that are being considered and that need a greater commitment from the community to make them possible include:\nC++ meetings Compilers meetings R meetings Last but not least, when OSL has all these pieces working we will start to plan an Annual Conference that should cover topics about open science and technologies.\nInternship The internship is a great opportunity to involve more people in the project, as well as to provide opportunities for the community to practice and learn from experienced people from around the world.\nInterns contribute mainly to affiliated projects (Open Science Labs Partnership), so they will work on open source projects and receives mentoring from other experienced contributors.\nWith this program, we aim to have them hired for these projects in the near future (depending on their progress).\nInterns also work on internal tasks to help Open Science Labs to grow, such as: blog post, PR review, documentation, organization tasks, etc.\nPlans:\nFor now, the number of interns that the project can afford is very small, but for this phase, it would be great to have around 10 interns in order to contribute to all the partnerships open source projects and to the Open Science Labs internal tasks.\nAlso, it would be great to participate to Google Summer of Code as well.\nPartnerships Partnership program helps us to connect to other projects and work groups in order to expand our network and experiences.\nAlso, it is a good approach to help the projects to have more visibility and contributions from the community.\nIn the partnership, we need someone from the partners side that will mentoring the interns that will contribute to their projects.\nThe desired scenario for the partnership program is when the intern that is contributing to a project is contracted by them, but it is not a requirement.\nPlans:\nThe partnership program needs to connect to more projects and, for this phase, it would be great to increase the number of partner to 20 (currently it is 5).\n","link":"https://opensciencelabs.org/guidelines/roadmap/roadmap/","section":"guidelines","tags":["mentorías"],"title":"Open Science Labs Roadmap"},{"body":" Código de conducta de las mentorías Al acceder o utilizar los servicios de tutoría de OSL, y por lo tanto formar parte de esta comunidad, usted está de acuerdo en cumplir con nuestro Código de Conducta.\nLos participantes se comprometen a no participar en ninguna actividad torticera o criminal y si usted se involucra en dicha actividad, usted entiende que es totalmente responsable en la medida de la ley y que va a contratar a su propio abogado a su propio costo, pagar y todas las multas necesarias y otros costos y se compromete a mantener OSL inofensivo. Además, OSL queda indemnizada por cualquier acción que usted realice fuera del ámbito de su contrato y tutoría.\nLa participación es voluntaria y los participantes deberán indemnizar, eximir de responsabilidad y defender (colectivamente \u0026quot;indemnizar\u0026quot; e \u0026quot;indemnización\u0026quot;) a la OSL y a su personal o miembros de y contra todas las reclamaciones, demandas, acciones, juicios, daños, responsabilidades, pérdidas, acuerdos, juicios, costes y gastos (incluyendo pero no limitado a los honorarios y costes razonables de los abogados), ya sea o no la participación de una reclamación de terceros, que surgen de o se relacionan con (1) cualquier incumplimiento de cualquier representación o garantía de OSL contenida en este Acuerdo, (2) cualquier incumplimiento o violación de cualquier pacto u otra obligación o deber de OSL bajo este Acuerdo o bajo la ley aplicable, (3) (4) (5)] [otras categorías enumeradas de las reclamaciones y las pérdidas], en cada caso, sea o no causada por la negligencia de OSL o cualquier otra parte indemnizada y si la reclamación correspondiente tiene mérito.\nMentores y alumnos Como participante en la comunidad de mentores, usted se compromete a:\nTratar a los demás dentro de la comunidad de mentores con respeto. Hacer un esfuerzo honesto y dedicar el tiempo suficiente a cada relación de mentoring que se establezca. No promover bienes o servicios de fuentes en las que tenga un interés financiero o personal. No aceptar honorarios o comisiones. Representarse honestamente sin identidades falsas o alias. Reconocer la diversidad de la comunidad OSL y respetar la variedad de normas culturales, creencias, prácticas y valores que contiene. Mentores Como mentor dentro de la comunidad, te comprometes a\nNo utilizar ninguna idea, producto o material que un alumno tenga, o pueda desarrollar, para promover su propio negocio o intereses financieros. Mantener la confidencialidad de todas las ideas, productos o materiales que le hayan sido confiados por su alumno. Animar a sus alumnos a mantener los más altos estándares éticos en sus trabajos. Mantenga un alto nivel de conducta personal y profesional con su alumno. Demuestra empatía sin hacer que el alumno se sienta incómodo. Comunica siempre de forma veraz. Apoya los objetivos de tu alumno y ayúdale a establecer metas alcanzables. Evita la intención o la apariencia de prácticas poco éticas o comprometedoras en las relaciones, acciones y comunicaciones. Remita a su pupilo al administrador del programa de tutoría en el caso de cuestiones o preguntas para las que no se sienta capacitado. No dude en hacer preguntas si encuentra alguna parte de las directrices poco clara o confusa. Tanto el mentor como el alumno tienen la gran responsabilidad de mantener y respetar la confidencialidad de toda la información impartida durante la relación de mentoría, ya que pueden escuchar información sensible y personal. Sin embargo, si dicha información es peligrosa o ilegal, un enfoque apropiado para el mentor es animar al alumno a tomar las medidas adecuadas por sí mismo. Tutoreados Como alumno de nuestra comunidad, usted se compromete a\nPoner esfuerzo y energía en conseguir un mentor. Crear una relación de tutoría relevante, específica, detallada y clara. Mantener la confidencialidad de su relación de tutoría. Construir proactivamente su relación de mentoría. Comunicarse regular y abiertamente con su mentor. Cumplir el compromiso con su mentor y con su proceso de aprendizaje. Completar cualquier tarea acordada entre su mentor y usted. Mantener toda la información sensible proporcionada a través de su relación de tutoría en estricta confidencialidad. ","link":"https://opensciencelabs.org/guidelines/coc-mentoring/coc-mentoring/","section":"guidelines","tags":["mentoria","coc"],"title":"Código de conducta de las mentorías"},{"body":"Descripción de OSL : Open Science Labs (OSL) es una comunidad que ofrece un espacio abierto para compartir, aprender y enseñar temas relacionados de Ciencia Abierta y Tecnologías Computacionales al público de Latinoamérica, pero no restringido a ello.\nMisión de OSL: Crear un espacio abierto colaborativo para el aprendizaje orgánico entre todos de la comunidad. La Diversidad Equidad e Inclusión es uno de los ejes de la comunidad.\nResultados de OSL: Creación de grupos locales para difusión de conocimiento. Aculturamiento de prácticas de trabajo colaborativo y abierto. Actividades para difusión de conocimiento (blog, videos)\nDeclaración DEI de OSL: OSL reconoce que los procesos pedagógicos asociados al desarrollo de nuevas habilidades y destrezas son de largo aliento y son el resultado de la inversión de tiempo, la aceptación de la diversidad en condiciones equitativas y justas, la constancia y, sobre todo, el impacto acumulativo de decisiones enmarcadas en nuestro propósito como organización. Por ello, OSL establece sus objetivos para lograr un progreso medible en el avance de la DEI en cuatro aspectos:\nCapacidades: Ayudaremos a la comunidad de personas con interés en dominar las tecnologías abiertas y aplicarlas en la ciencia, a desarrollar las capacidades necesarias para lograrlo generando diversidad, equidad e inclusión que sea observable en sus espacios de trabajo e interacción. DEI con sentido: Asumiremos nuestras acciones y quehacer como organización con un enfoque positivo e intencional de DEI entre quienes integran OSL en sus distintos roles de colaborador, voluntario e integrante de la Junta Directiva. Ciencia Abierta diversa: Como resultado de desarrollar nuestras iniciativas actuales y futuras, conseguiremos una comunidad más diversa de personas interesadas por la tecnología en el ámbito de la ciencia abierta. COC y DEI en trabajo conjunto: Estableceremos un Código de Conducta (COC) para garantizar el establecimiento de prácticas positivas hacia el respeto de todas las personas y sus consideraciones en términos de honestidad intelectual, académica y personal en el desarrollo de nuestras actividades. En función de ésto, nuestra comunidad considera los siguientes parámetros con respecto a la DEI:\nDiversidad: Nuestra comunidad está abierta a múltiples características demográficas, sociales, políticas, identidades, perspectivas y orígenes. Equidad: Quienes integran nuestra comunidad, así como sus distintos grupos y equipos de trabajo tienen acceso a todas las oportunidades y actividades que realizamos en función que las organizamos buscando, de forma explícita, eliminar las barreras que han impedido históricamente la participación de grupos minoritarios o excluidos. Inclusión: Todas las personas que componen nuestra comunidad experimentan un sentimiento de pertenencia, altos niveles de compromiso con las actividades en las que participan y respeto compartido y mutuamente expresado. ","link":"https://opensciencelabs.org/guidelines/dei/guide/","section":"guidelines","tags":["DEI"],"title":"Declaración de Diversidad, Equidad e Inclusión"},{"body":"","link":"https://opensciencelabs.org/tags/dei/","section":"tags","tags":null,"title":"DEI"},{"body":" ¿Qué es la una mentoría? La mentoría es una técnica o proceso en el que una persona con experiencia (mentor/a) guía a otras personas (aprendices o mentorados/as) para lograr su meta y objetivos personales en un espacio de tiempo limitado. Quien ejerce la mentoría no necesariamente es quien enseña, entrena o impulsa, sino también apoya, alienta a sus aprendices y conservando apertura a preguntas y a escuchar. Se trata de ayudarse mutuamente a expandirse y crecer para que todas las personas aprendan.\nAdemás, una mentoría efectiva brinda oportunidades para compartir talentos, habilidades, experiencias y conocimientos obtenidos a través de la capacitación regular, el entrenamiento y la retroalimentación continuos, no sólo para aprendices sino también para mentores/as.\nQuienes ofrecen la mentoría no tienen responsabilidad directa por el desempeño laboral de los/las aprendices. Solo ofrecen consejos y motivan para potenciar el desarrollo profesional de éstos.\nTipos de mentoría La universidad de Auckland sugiere dos tipos de relaciones de mentoría:\nMentoría informal, cuando alguien con más experiencia que otras personas ayuda de forma espontánea y sin pedir hacerlo de forma explícita. Los vínculos se inician entre individuos de forma directa.\nMentoría formal, hay una solicitud u oferta oficial de relaciones de mentoría. Mentores/as y aprendices siguen un programa de mentoría estructurado, haciendo acuerdos sobre su naturaleza y estableciendo metas entre ellos/as.\nHabilidades y experiencia requeridas para ser mentor/a Según la Universidad Metropolitana de Manchester (MMU), existen al menos diez requisitos para ser mentor/a:\nAutoconciencia: se relaciona con tener objetivos personales propios, carrera y conocer las propias fortalezas.\nSaber hacer organizacional: significa un conocimiento individual que tienen los/as mentores/as, y que proporciona una ventaja sobre otros en el mismo campo, se trata de saber cómo funcionan las cosas.\nCredibilidad en la determinación de objetivos y desarrollo de capacidades: es importante que los/as mentores/as tengan credibilidad personal y profesional en su área y que sean miembros de organizaciones relevantes.\nAccesibilidad: El éxito de la mentoría depende del tiempo dedicado a los/as aprendices. Además, los/as mentores/as deben hablar regularmente para establecer un nivel de comodidad en la relación en torno a los temas fáciles, luego, cuando surge un desafío o una inquietud, es mucho más fácil para tener una discusión útil.\nLas habilidades de comunicación o escucha activa (teniendo en cuenta los intereses, el lenguaje corporal, la atención y dar consejos) ayudan a determinar las motivaciones y necesidades de sus mentorados.\nCapacidad para empoderar: los/as mentores/as tienen la capacidad de crear un entorno de trabajo en el que los/as aprendices se tengan seguridad para contribuir de diferentes maneras.\nUn deseo de ayudar a otros a formarse: los/as mentores/as deben comprender cómo los/as aprendices obtienen experiencia a partir de la mentoría, ya sea de manera formal o informal.\nInventiva: los/as mentores/as deben tener la mente abierta para hacer cosas nuevas y diferentes en la mentoría, para ayudar a los/as aprendices a obtener perspectivas más amplias de sus experiencias.\nEmpatía: la capacidad de sentir las emociones de los/as aprendices, o lo que podría estar pensando o sintiendo.\nComprensión: los/las mentores/as pueden observar a sus aprendices cómo aprenden y brindarles comentarios constructivos.\nAlgunas otras habilidades adicionales son:\nAlentar e inspirar: los/as mentores/as tienen la capacidad de comentar sobre los logros de los/as aprendices. Creen en la capacidad de éstos para crecer personal y profesionalmente. Además, responden a sus frustraciones y desafíos. Es importante que los/as mentores/as compartan su visión personal o la de otros líderes, como sus experiencias, errores y éxitos en el logro de sus objetivos The Center for Health Leadership \u0026amp; Practice (CHLP).\nEl proceso de mentoría / etapas El proceso de mentoría es una actividad que tiene un principio y un final. En este sentido, el MMU enumera tres etapas:\nInicial; (construyendo la relación): en la cual se explican los objetivos de la mentoría. Tiempo para relacionarse (calendario para la comunicación). Se sugiere discutir antecedentes, experiencias, intereses y expectativas. Establecer las reglas (como por ejemplo, el formato de la reunión). Sesiones de mentoría; planificación de sesiones de mentoría (revisión de experiencias, cuándo y cuánto tiempo, metas, avance de avances). Quienes conducen la mentoría deben hablar sobre sí mismos/as, sus habilidades, su organización, experiencia y los desafíos que enfrentan. Además, pueden intercambiar información y ayudar a sus aprendices a establecer y reenfocar sus objetivos periódicamente. Finalmente, deben trabajar hacia las metas (parte larga y desafiante del proceso de mentoría), mediante discusiones, compartiéndoles material, probando otros contenidos de aprendizaje y actividades de desarrollo. Los/as mentores/as crean oportunidades para que los/as aprendices adquieran experiencia, es un buen momento para presentarlos a otros/as colegas. Evaluar el progreso de esta relación mentor/a-aprendices (ajustes, resultados, beneficios). Avanzar; identificar cuándo terminará la relación mentores/as-aprendices, como cuando concluyen los objetivos, los desafíos y el progreso hacia las metas. Ayude a los/as aprendices a identificar y próximos pasos, fomente la autorreflexión. Explore otros tipos de apoyo para cubrir sus necesidades. Además, es importante considerar que hay otras razones para terminar la relación de mentoría, por ejemplo, el programa puede estar llegando a su fin o la relación no está funcionando correctamente y ambas partes desean seguir de forma separada. Establecer metas y expectativas La Harvard University sugiere que tanto mentores/as como aprendices establezcan sus objetivos, expectativas y colaboren activamente para tener una mentoría efectiva. Aquí hay algunos pasos a considerar:\nCompromiso establecido entre aprendices y mentores/as antes de iniciar una relación de mentoría porque requiere tiempo y esfuerzo de ambos. Autoconocimiento, los/as aprendices comienzan determinando objetivos específicos y lo que es más relevante y apropiado para ellos en la relación de mentoring. Una vez que aclaren sus objetivos, ahora pueden considerar cómo esta relación podría contribuir a lograr sus objetivos. Vinculación: los/as aprendices están listos/as para considerar mentores/as potenciales para que los apoyen, en función de sus expectativas con respecto a las cualidades y atributos de los/as mentores. Establecimiento de la relación de mentoría. Los/as mentores y los/as aprendices deben definir pautas y acuerdos al principio de la mentoría. La planificación mantendrá la asociación de mentoría encaminada y enfocada en los objetivos principales. Los mentores y los/as aprendices deben trabajar en conjunto para establecer pasos de acción para cada objetivo y cómo hacerlos efectivos. Una mentoría exitosa depende de la inversión de energía en la relación y el compromiso con la experiencia. El final de una mentoría es una parte tan importante del proceso como los pasos previos. Es importante entender que no significa el final de la relación. En este proceso, puede ser una excelente oportunidad para tener una discusión similar sobre la experiencia en su conjunto o celebrar los logros. Además, los/as antiguos/as aprendices y mentores/as son excelentes recursos para incluir en la red. Al igual que con cualquier conexión de red, los/as aprendices deben asegurarse de mantenerse en contacto y participar en las comunidades derivadas de las mentorías. Ética y mentoría Los/as mentores necesitan examinar y reflexionar continuamente sobre sus valores éticos y cómo pueden influir en las decisiones en su práctica de mentoría. A continuación, se presentan algunas características profesionales que contribuyen a tener una mentoría efectiva:\nLos/as mentores/as y aprendices deben conocer bien el código de conducta de su institución para la mentoría. Al mismo tiempo, deben leer los códigos de ética profesional para tener una relación de mentoría saludable y aceptar eso antes de que comience la mentoría. El desarrollo de pautas normativas, entre mentores/as y aprendices, es una herramienta poderosa para reflexionar en conjunto sobre valores y límites, y para promover el pensamiento ético. En la mayoría de las profesiones, un conjunto de valores determina la conducta profesional ética y se convierte en parte de la identidad profesional. Los/as mentores/as deben asumir la responsabilidad del poder que ostentan y nunca utilizarlo de forma abusiva sobre otros más vulnerables. Debe haber una estructura de denuncia abierta y clara para cualquier abuso de poder. Los/as aprendices pueden identificarse con mentores/as que tienen valores, actitudes y experiencias que ellos tienen o aspiran a tener. Además, The Actuaries w Without Borders describe algunas características personales en la mentoría:\nMentores/as; hacer preguntas abiertas y de apoyo y proporcionar comentarios constructivos. Mentores/as; mantener un tono amistoso y sea positivo. Mentores/as; fomentar las oportunidades de desarrollo para los/as aprendices. Mentores/as; ayudar a los aprendices a resolver su propio problema, en lugar de cómo hacerlo. Mentores/as; dar un refuerzo positivo. Mentores/as; ser accesibles para ayudar a los/as aprendices. Aprendices; estar preparado/a. Aprendices; asumir la responsabilidad de los errores. Aprendices; agradecer a su mentor/a. Mentores/as y aprendices; Valorar al/la socio/a mentor/a como persona Mentores/as y aprendices; Desarrollar la confianza y el respeto mutuos. Mentores/as y aprendices; Escuchar activamente tanto lo que se dice como cómo se dice. Mejores prácticas de mentoría La mentoría implica la relación entre mentores/as y aprendices. Los/as buenos/as mentores/as son personas entusiastas que disfrutan el papel que desempeñan para ayudar a otros a lograr sus objetivos (CHLP). Hay algunos roles diferentes que los/as mentores/as pueden estar obligados a tomar:\nTrabajo en red; los/as mentores/as ayudan a los/as aprendices a encontrar personas y recursos que van más allá de su experiencia. Asesoramiento; los/as mentores/as alientan, inspiran y desafían a los/as aprendices a lograr sus objetivos. Además, actúan como confidentes, ayudando a los/as aprendices a aclarar problemas reales y viendo el panorama general. Facilitar; los/as mentores/as comparten sus experiencias, consejos, enfatizando cómo su experiencia podría ser diferente de sus experiencias. Entrenamiento; los/as mentores/as construyen la confianza de sus aprendices a través de comentarios de apoyo. Disfrutando del proceso de la mentoría; los/as mentores/as deben ser espontáneos solo para enviar una palabra de aliento o una nueva información. Evitar controlar la relación de mentoría. Se recomienda que sea el/la aprendiz quien se asegure fijar la siguiente fecha de reunión en coordinación con el/la mentor/a. Comenzando a ser mentorado en OpenScienceLabs Quien aspire a contar con una mentoría deberá solicitar la mentoría en nuestro GitHub, luego hacer click en \u0026quot;Solicitar mentoría\u0026quot;\u0026quot;, y llenar el formulario correspondiente, detallando el área de mentoría, la disponibilidad de tiempo (incluir la zona horaria) y objetivos que se quiere lograr después de terminada la mentoría. Con base en el formulario, OpenScienceLabs buscará mentores/as dentro la comunidad, en un plazo no mayor a una semana se le mostrará las opciones al/la aspirante a aprendiz. Una vez se haya coordinado con el/la mentor/a y el/la aprendiz se organizará una primer encuentro que en lo posible tendrá la participación de una persona del Steering Council de OpenScienceLabs. A partir de esa primera reunión el/la aprendiz y el/la mentora coordinarán sus siguientes sesiones para la mentoría. Una vez finalizada la mentoría ambos, mentor/a y aprendiz llenarán un formulario para indicar si la mentoría alacanzó sus objetivos, cuáles fueron las dificultades y/o razones de conclusión de la mentoría. Código de conducta de mentores (MCOC) Como organización, nos unimos al . No obstante, hemos decidido complementarlo con un apartado dedicado al proceso de mentoring. Para obtener más información sobre nuestro Código de conducta de mentores, revise esa sección en nuestro [Código de conducta] (mentoring-guideline/docs/COC.md).\n","link":"https://opensciencelabs.org/guidelines/mentoring/guide/","section":"guidelines","tags":["mentorías"],"title":"Guía de Mentorías"},{"body":"Introducción General El propósito de esta guía es acompañar los primeros pasos de colaboradoras y colaboradores de OSL en la elaboración de sus posts para ser publicados en nuestro blog.\nEn la lectura de esta guía se encuentra una base simplificada de los distintos elementos que se deben tener en cuenta en la escritura de este material.\nCaracterísticas básicas de los posts Aunque se admitirán eventualmente materiales traducidos de otros idiomas, correctamente referenciados, en general los artículos deberán ser inéditos. Esto permitirá mejorar el posicionamiento del portal como referencia. Importante: No abordar temas similares a artículos anteriores en el blog. En los artículos abordamos temas generales de ciencia abierta, software de fuentes abiertas que se utiliza en proyectos de ciencia abierta, gestión de equipos de trabajo, ciencia colaborativa, y uso de aplicaciones, bibliotecas y otras herramientas específicas, entre otros. La extensión esperada de los posts es de hasta 900 palabras. Una extensión mínima deseable es de 750 palabras. Cada post debe ir acompañado de una imagen de cabecera o imagen destacada. En los artículos recientes, las imágenes han sido obtenidas de algunos de estos sitios: https://www.glazestock.com/ https://drawkit.com/ https://undraw.co/illustrations Adicionalmente, según la extensión del artículo, pueden haber imágenes internas que sirvan de soporte visual a las ideas planteadas. Utilizar Google Trends para localizar palabras de referencia para contenidos de artículos Los títulos deben cumplir con las siguientes características: ser cortos, estar vinculados con el contenido del artículo e invitar a su lectura. En los títulos se pueden agregar emoticones sin abusar de ellos. Pueden utilizarse hasta tres subtítulos internos para separar las secciones del artículo en caso de ser necesario. Los subtítulos llevan el tamaño de encabezado H2 Es importante incluir referencias a los artículos que facilitamos desde nuestro portal. Asimismo, es muy importante incluir enlaces internos en los artículos. Enlaces tanto a artículos previos en el portal, como enlaces a las páginas de los proyectos, aplicaciones, y herramientas que se reseñan en él entre otros. Atención a las etiquetas, siempre incluirlas sin hacerlas muy simples o poco precisas. Las imágenes utilizadas deben tener contenido “Alt” especificado y autoría al pie de la imagen. Sobre el tono y el lenguaje inclusivo Los artículos se escriben con un tono cercano, simple, directo, claro y preciso ¡No nos interesa mostrar sabiduría sino compartir conocimiento! Queremos animar a más personas a que realicen prácticas colaborativas y de ciencia abierta. El tono debe ser fresco, incluso en tareas algo más complejas de explicar, la idea es animar a quienes nos leen a que continúen con las prácticas de ciencia abierta. Practicamos lenguaje inclusivo. Por ello buscamos el uso genérico de las palabras que no indican ningún sexo ni ningún género de forma preferente: personas, participantes, quienes, entre otras. En caso de deber utilizar alguna palabra que denote sexo y género, indicar también las referencias a otros géneros y sexos: /a/e. Esto se aplica tanto al singular como al plural. En general, tanto el tono como el discurso debe ser respetuoso y claro. Se evitarán palabras que, por razones culturales puedan ser malinterpretadas en otras culturas. En OSL somos muy respetuosos/as/es de otras culturas, prácticas religiosas, preferencias políticas, deportivas y, en general, nunca abordamos en los artículos nuestras preferencias personales en cualquier ámbito que pueda resultar controversial y resultar incómodo a quienes nos leen. Esto es clave para hacer de este espacio un lugar seguro en el que la pasión e interés por la ciencia abierta, nos reúna y anime a colaborar. Aunque en los artículos puede hacerse referencia a experiencias personales, siempre es importante mantener el foco de los escritos en la propuesta de una solución a una necesidad de información o conocimiento sobre los temas abordados. Flujo de trabajo Cada colaborador/a/e establece el ritmo de trabajo que aportará al portal y selecciona los temas y orden en que serán asumidos, así como las fechas en que estarán disponibles para su revisión. Cada colaborador/a/e cuenta con un acompañamiento inicial entre 1 hasta 3 semanas para manejo del wordpress y primeros pasos con el flujo de edición, según lo acordado el Board de OSL. Colaborador/a/e elabora el artículo desde su cuenta en el portal. Una vez terminada la escritura del artículo, junto con las imágenes sugeridas, éste permanece en borrador a la espera de que quien esté asignado/a/e a la revisión, le haga una revisión básica de ortografía, claridad y coherencia. Quien revisa el escrito para su publicación es quien debe programar su publicación en el portal. Los artículos deben contar con entre 5 y 8 palabras clave que serán colocadas en la sección ETIQUETAS del escrito. Igualmente, cada escrito debe contar con la categoría a la cual pertenece. Salvo indicación o acuerdo previo, ningún colaborador/a/e debe editar escritos de otros colaboradores/as. Se anima a nuestros/as/es colaboradores/as a que repliquen sus publicaciones en nuestro portal, a través de sus redes sociales personales, siempre que se haga referencia a las redes sociales de OSL para su promoción. Temas propuestos Guías para instalación de aplicaciones, bibliotecas o librerías de uso frecuente en ciencia abierta y prácticas similares. Títulos sugeridos: Aprende a instalar XX en unos pocos minutos, Te mostramos cómo instalar XX en tu PC rápidamente. Trucos que ayudan a resolver problemas específicos. Títulos sugeridos: 5 tips que necesitas saber para mejorar el rendimiento de XX, 3 claves que no debes perder de vista en tu próximo proyecto de ciencia abierta. Artículos para público general con divulgación de aspectos relativos a ciencia abierta, laboratorios colaborativos, ciencia ciudadana entre otros. Traducciones de artículos interesantes y relevantes para la temática del portal de OSL (previa consulta con equipo editorial). Reseñas sobre artículos, libros, videos, podcasts referidos al ámbito de ciencia abierta y similares. ","link":"https://opensciencelabs.org/guidelines/articles/guide/","section":"guidelines","tags":null,"title":"Guía Editorial para creación de Artículos"},{"body":" Guía para Recaudación de Fondos Patrocinadores fiscales Un patrocinador fiscal es una organización sin ánimo de lucro que comparte su estatus 501(c)(3) con proyectos sin ánimo de lucro cualificados. Con este estatus compartido, el proyecto no necesita constituirse como 501(c)(3), lo que significa, entre otras cosas, que tampoco tiene que presentar sus propios impuestos.\nCommunity Initiatives ¿Qué es Community Initiatives? Es un patrocinador fiscal dedicado cuyo único propósito es proporcionar la mejor infraestructura para los líderes de las organizaciones sin ánimo de lucro. Trabajan en varios temas y en diversas áreas geográficas, también varían en cuanto a personal y presupuesto.\n¿Cómo unirse a Community Initiatives? Para solicitar el patrocinio fiscal de Community Initiatives, los posibles proyectos deben enviar un formulario de consulta, si parece que encajamos bien, el Vicepresidente de Servicios al Cliente nos guiará a través del proceso de solicitud.\n¿Qué contiene el formulario de consulta? Allí se solicita información sobre: datos personales del solicitante, nombre, sitio web, misión del proyecto y las áreas que lo comprenden, el presupuesto previsto del proyecto para el próximo año, desde cuándo opera la organización sus programas, si trabajan actualmente con un patrocinador fiscal o si han trabajado alguna vez con uno de ellos, si se cuenta con un comité de consulta o supervisión. También piden una aproximación de la cantidad de personas atendidas anualmente, si la organización está dirigida por voluntarios, empleados, contratistas independientes o una combinación de ellos y la forma en cómo se llegó a conocer Community Initiatives.\n¿Cómo es el proceso de solicitud? Luego de enviar el formulario de consulta el Vicepresidente de Servicios al Cliente de Community Initiatives se pondrá en contacto con nosotros para realizar una llamada telefónica de presentación. En esta conversación conocerán nuestro proyecto y determinarán si podemos aplicar.\nSi al terminar la llamada telefónica deciden que podemos solicitar el patrocinio fiscal, debemos presentar una solicitud y la documentación de apoyo para completar el proceso.\nLas solicitudes completas incluyen los siguientes documentos requeridos:\nCarta de presentación solicitando el patrocinio fiscal.\nFormulario de solicitud de cuatro páginas.\nPresupuesto del primer año (se requiere la plantilla de Community Initiatives).\nPlan de recaudación de fondos a tres años.\nBiografía y curriculum vitae del Director Ejecutivo.\nBiografías de los miembros del Comité Asesor.\nMaterial adicional del programa (opcional).\nLas solicitudes se aceptan trimestralmente. Los plazos de solicitud trimestral para este año:\n7 de enero\n8 de abril\n17 de junio\n23 de septiembre\nPosteriormente el personal de Community Initiatives programará una reunión para comprender mejor las necesidades operativas del proyecto y realizar una evaluación de riesgos de las actividades propuestas. Será de 45 o 90 minutos de acuerdo al tipo o modelo de solicitud considerada (A o C).\nLa Junta directiva de Community Initiatives debe aprobar la solicitud antes de que el proyecto se incorpore a su amplia red. El estado de la solicitud erá notificado en el plazo de una semana tras la revisión de la junta.\nSi aceptan la solicitud, se celebrará una reunión de orientación para ayudarnos a sacar el máximo provecho de la asociación con Community Initiatives; allí seleccionan una fecha de inicio que nos convenga. Si el proyecto es aprobado, se debe realizar la inscripción en cualquier momento en el plazo de un año desde la aceptación del proyecto. Los proyectos seleccionados deben comenzar su labor en el plazo de un año a partir de la aprobación de la junta directiva.\n¿Qué servicios nos brinda Community Initiatives? Community Initiatives proporciona una administración completa en las áreas más intensivas en tiempo y experiencia de la gestión sin ánimo de lucro, desde recursos humanos, administración de nóminas, preparación y presentación de impuestos, gestión financiera y más. Con Community Initiatives el 90% de nuestros ingresos quedarían en el personal y los programas.\nEspecíficamente los servicios que ofrece son:\nManejo de beneficios, nóminas y recursos humanos entre ellos un manual de personal actualizado, sistemas de contratación establecidos, plan para la asistencia sanitaria de los empleados y otras prestaciones, administración de las nóminas de los empleados y contratistas y expertos de guardia para gestionar los problemas de recursos humanos.\nAdministración del empleo, cartas de oferta de trabajo y autorizaciones de visado para empleados, ajustes salariales, ascensos, cambios de título, aclaración de la FLSA, permisos de ausencia, etc. Revisión de causas de despido, acuerdos de pago final, entrevistas de salida, despidos, reducciones salariales, etc. Procesamiento de cheques, W-9s, 1099s y mantenimiento de la información I-9.\nAdministración de beneficios: planes de salud y bienestar de los empleados, administración de planes de jubilación a través de nuestro 401(k), administración de cuentas de gastos flexibles y administración de COBRA\nGestión de riesgos y cumplimiento: mantenimiento de los registros y la documentación del personal, cumplimiento normativo (ERISA, FLSA, EEO y otras normativas federales y estatales), gestión de riesgos de RR.HH. para la compensación de los trabajadores y el seguro de desempleo, formación relacionada con el cumplimiento para los directores y gerentes de proyectos (EEO, acoso sexual, etc.), plantillas de contratistas independientes y su cumplimiento.\nPolíticas de RRHH y relaciones con los empleados: entrenamiento para la gestión del rendimiento, manual del empleado completo, asesoramiento en materia de relaciones con los empleados, resolución de conflictos, gestión y administración de reclamaciones y mediación.\nGestión financiera: cuentas por pagar, cobros en efectivo, estados financieros mensuales, informes y análisis financieros, gestión del presupuesto y de la tesorería, auditoría anual independiente e informes de cumplimiento y asesoramiento financiero.\nPreparación y cumplimiento de impuestos: declaraciones fiscales e informativas federales, estatales y locales; recepción de donaciones y subvenciones deducibles de impuestos, acuse de recibo de donaciones superiores a 250 dólares, como exige el IRS; remisión y presentación de impuestos sobre la nómina, licencias comerciales estatales y locales.\nApoyo a las subvenciones: colaboración en el desarrollo de solicitudes, revisión de borradores de propuestas, seguimiento financiero de los fondos de la subvención, control del cumplimiento de las subvenciones, seguimiento y apoyo a los informes de las subvenciones.\nGestión de riesgos y seguros: Community Initiatives ofrece la siguiente protección a todos sus proyectos patrocinados fiscalmente: Indemnización laboral Responsabilidad civil general Responsabilidad civil general Propiedad comercial Automóviles propios y alquilados Accidente Responsabilidad civil por prácticas laborales Responsabilidad civil por delitos y robos de empleados\nAsesoramiento jurídico. Community Initiatives ofrece acceso a expertos legales en las siguientes áreas: marca comercial, propiedad intelectual, demandas por discriminación, propiedad inmobiliaria, empleo y discriminación, prórrogas del visado H-1 B, impuesto sobre la renta de las empresas no relacionadas y acuerdos de asociación. Cuando el proyecto requiera un apoyo legal altamente especializado o intensivo, Community Initiatives cuenta con un experto legal a un precio reducido.\nCoaching: los proyectos de Community Initiatives cuentan con un profundo banco de especialistas en organizaciones no lucrativas junto con expertos en consultoría para ayudar, entre otros, con temas relacionados con el marketing y las comunicaciones, la consultoría estratégica, la recaudación de fondos, la participación de la junta directiva y los voluntarios y otras cosas más.\nGestión de donaciones y crowdfunding: Cuando llegan las donaciones, Community Initiatives se asegura de que cada contribución de 250 dólares o más reciba una carta de reconocimiento del donante que cumpla con los requisitos fiscales. Se asocia con FundRazr una plataforma de recaudación de fondos online de vanguardia. A través de este acuerdo de colaboración, los proyectos de Community Initiatives tienen acceso gratuito a una plataforma de donaciones personalizable con las siguientes características: crowdfunding, baja tasa de tramitación, investigación de donantes, informes de donaciones, sitio de donaciones de marca blanca (por una tarifa nominal), a través de la asociación con WeDidIt, se obtiene la financiación rápidamente.\n¿Cuáles son las tasas de cobro de Community Initiatives? Cuotas de patrocinio: Community Initiatives cobra el 10% de los ingresos brutos. Debido a la complejidad de los requisitos de información, cobra un 15% para los fondos gubernamentales.\nRecaudación de fondos mínima: aunque sirven a un número de proyectos con presupuestos anuales millonarios, todos los proyectos de la red deben cumplir con un requisito mínimo de recaudación de fondos anual de 24.000 dólares.\n","link":"https://opensciencelabs.org/guidelines/fund-raiser/guide-es/","section":"guidelines","tags":null,"title":"Guía para Recaudación de Fondos"},{"body":"","link":"https://opensciencelabs.org/tags/mentoria/","section":"tags","tags":null,"title":"mentoria"},{"body":"Open science labs is a community that aims to gather people from all parts of the world, specially from latin america countries and create an open space for teaching, learning and sharing topics around open science and computational tools. An english group is very important in this context because it increases the possibilities of collaboration in open projects.\nCommunity We are using discord to organize our community. There you can decide which group you want to join, for example python, c++, compilers, open science, devops, languages (English, Spanish) , etc.\nAlso, everyone is more than welcome to propose a study-group. If you want to study a specific topic, and want to gather more people to study that with you, we encourage you to propose a study-group.\nIf you want to give a talk or tutorial about a specific topic, raise your voice in the channel #comm-general and we will be more than happy to help you to hold this event on discord.\nCollaborate! If you want to join us, apply to be a volunteer here.\nAlso, take a look into our Code of Conduct.\nWe need help in areas, such as:\nDevOps Articles Videos Community Management Social Media Diversity, Equity and Inclusion Events Documentation Mentoring Project Managements Join our community on discord. Learn more and contribute on GitHub.\nRoadmap If you are interested in the Open Science Labs next steps, please check our Roadmap.\nGovernance For more information about our project governance, please check governance document.\n","link":"https://opensciencelabs.org/about/","section":"","tags":null,"title":"About"},{"body":" ","link":"https://opensciencelabs.org/discord/","section":"","tags":null,"title":"Discord"},{"body":" La mentoría es una técnica o proceso en el que una persona con experiencia (mentor/a) guía a otras personas (aprendices o mentorados/as) para lograr su meta y objetivos personales en un espacio de tiempo limitado. Quien ejerce la mentoría no necesariamente es quien enseña, entrena o impulsa, sino también apoya, alienta a sus aprendices y conservando apertura a preguntas y a escuchar. Se trata de ayudarse mutuamente a expandirse y crecer para que todas las personas aprendan. Para más informaciones, ingrese a la Guía de Mentorías. ¡Encuentre aquí tu mentora o mentor! Ivan Ogasawara 0 cupos disponible Mentoría Grátis Idiomas para la mentoría: Portugués Español Inglés Entusiasta de los compiladores, la ciencia de datos y la ciencia abierta. Experiencia con Python, C++, JavaScript, DevOps y Packaging. Fundador de Open Science Labs. Python Python Científico Python Web JavaScript Vainilla C++ Solicitud de Mentoría Ever Vino 0 cupos disponible Mentoría Grátis Idiomas para la mentoría: Español Ingeniero Ambiental con experiencia en Investigación, análisis químico, desarrollo de modelos matemáticos para bioprocesos, diseño de sistemas de tratamiento de aguas residuales. Experto en Python y Modelos Matemáticos para procesos químicos. Python R Modelos Matemáticos Procesos Químicos Solicitud de Mentoría Luis Gago Casas 0 cupos disponible Mentoría Grátis Idiomas para la mentoría: Español CEO and Owner at AyPhu DevOps IaC Monitoreo Docker Ansible Grafana Prometheus Kubernetes Solicitud de Mentoría Evelyn Donis 5 cupos disponible Mentoría Grátis Idiomas para la mentoría: Español Ingeniera en Sistemas y Auditor Líder Certificado en ISO27001 Seguridad de la Información e ISO22301 Continuidad del Negocio. Con más de 12 años de experiencia en seguridad de la información, seguridad informática, así como la realización de auditoría de sistemas y asesoramiento e implementación de sistemas de gestión de continuidad del negocio, gestión de incidentes y plan de continuidad del negocio, gestión de incidentes y plan de recuperación de desastres, para diferentes industrias financieras, telecomunicaciones, manufactureras, entre otras. \u003c\u003c Ver más/menos texto \u003e\u003e Cuenta con experiencia en seguridad informática, evaluación, identificación y mitigación de riesgos de acuerdo a la implementación de controles internos en las áreas de TI. Sus principales análisis se basan en estructuración, verificación y validación de logs de los sistemas de información, operativos y bases de datos, dentro de los cuales ha podido identificar fraudes informáticos y transaccionales dentro de las organizaciones en las que ha laborado. Así mismo ha realizado análisis de acceso de usuarios a través de la validación de privilegios, roles y segregación de funciones en sistema SAP. Actualmente se desempeña como Consultora Senior en Seguridad de la Información y Ciberseguridad en ES Consulting. Ciberseguridad Seguridad de la información Auditoría de Sistemas Solicitud de Mentoría Fausto Mauricio Lagos Suarez 3 cupos disponibles Mentoría Grátis Idiomas para la mentoría: Español Inglés Matemático con matetría en ingeniería computacional y matemática. Área de investigación: Ecuaciones Diferenciales Ordinarias. Activista por el Software Libre y el Conocimiento Abierto. Desarrollador de Software (Criptología) en el equipo del Centro de Autonomía Digital en Quito (Ecuador). Python Golang Privacidad Solicitud de Mentoría Mateus Venâncio 2 cupos disponibles Mentoría Grátis Idiomas para la mentoría: Portugués Inglés Desenvolvedor de software autodidata. Apaixonado por tecnologia, cachorros e Pokémon. Amo aprender coisas novas e me aperfeiçoar no que eu trabalho. NodeJS Flutter Solicitud de Mentoría ","link":"https://opensciencelabs.org/mentoring/mentors/","section":"mentoring","tags":null,"title":"Mentoras y Mentores"},{"body":"","link":"https://opensciencelabs.org/mentoring/","section":"mentoring","tags":null,"title":"Mentorings"},{"body":" ","link":"https://opensciencelabs.org/facebook/","section":"","tags":null,"title":"Open Science Labs Facebook"},{"body":" ","link":"https://opensciencelabs.org/linkedin/","section":"","tags":null,"title":"Open Science Labs LinkedIn"},{"body":" ","link":"https://opensciencelabs.org/calendar/","section":"","tags":null,"title":"Open Science Labs Public Google Calendar"},{"body":" ","link":"https://opensciencelabs.org/twitter/","section":"","tags":null,"title":"Open Science Labs Twitter"},{"body":" ","link":"https://opensciencelabs.org/youtube/","section":"","tags":null,"title":"Open Science Labs Youtube"},{"body":"Python Sotfware Foundation (PSF) Open Science Labs ha recibido una subvención de la Python Software Foundation (PSF) en Abril del 2023 para mejorar una plantilla de proyecto Python (para cookiecutter o cookieninja) que implementa todas (tanto como sea posible) las mejores prácticas recomendadas por pyOpenSci, pero no restringidas a eso. Ofrece todos los enfoques y herramientas de mejores prácticas actuales como opciones, incluyendo CI, documentación, herramientas de análisis estático, etc. Gracias a la subvención se actualizarán las dependencias y se realizarán algunos cambios de configuración.\nPuedes visitar el proyecto OSL Python Package Template en: https://github.com/osl-incubator/osl-python-template\n","link":"https://opensciencelabs.org/acknowledges/index-es/","section":"acknowledges","tags":null,"title":""},{"body":"Pycafe charlas DevOps Charlas Anuncios de eventos https://twitter.com/opensciencelabs/status/1570867241138245633?s=20\u0026amp;t=UjgCpGqlFdXKkZWXfVNP_g Si quieres conocer más sobre Jupyter Notebook, lee nuestro blog 👉 https://t.co/Wz9yKHSJch pic.twitter.com/fJcc9oknzi\n\u0026mdash; OpenScienceLabs (@opensciencelabs) September 16, 2022 ","link":"https://opensciencelabs.org/archives/","section":"","tags":null,"title":""},{"body":"¿Qué es Open Science Labs (OSL)? Open Science Labs es una comunidad que tiene como objetivo unir a personas de todas partes del mundo, especialmente de países latinoamericanos y crear un espacio abierto para enseñar, aprender y compartir temas relacionados con la ciencia abierta y las herramientas computacionales.\n¿Qué actividades realizan? Creamos y contribuimos a la comunidad OpenSource enfocada en Ciencia Abierta, creando artículos sobre herramientas para la Ciencia Abierta, Proyectos en DevOps, Ciencia de Datos y Open Hardware. También disponemos de espacios de intercambio de información a través de Discord y desarrollamos procesos de Mentorías y capacitaciones específicas, favoreciendo la adquisición de nuevas destrezas en quienes nos contactan.\n¿Quiénes componen Open Science Labs? En la comunidad están varias personas curiosas con diferentes profesiones y que realizan diversas actividades y que colaboran de forma voluntaria. Algunas de las profesiones de quienes conforman Open Science Labs son: destrezas técnicas en electricidad, ingeniería ambiental, fullStack developers, ciencias políticas e ingeniería informática ubicadas todas en diferentes partes de Latinoamérica.\n¿Cómo puedo aportar a la comunidad? Puedes llenar el formulario para que nosotros te podamos contactar y coordinar una videollamada para establecer actividades. click aquí O también puedes solicitar que tu aporte como artículo o código fuente se comparta en las redes sociales de la comunidad o el repositorio, a través de Discord. Una vez que tu aporte sea incorporado este será de Código Abierto con licencia tipo CC BY-SA 4.0 y se agregará tu nombre a la lista de quienes contribuyen con Open Science Labs. ¿Ofrecen mentorías? Sí, para hacerte un mentorado de OSL solo llena este formulario y te avisaremos a la brevedad notificándote si tenemos un tutor disponible. También puedes ser tutor o mentor, para lo cual llena este otro formulario de aquí.\n¿Qué actividades específicas están haciendo actualmente? En Open Science Labs estamos trabajando en:\nPuesta en marcha y mantenimiento de nuestra página web. Mentorías en DevOps. Guias de herramientas para R y otras herramientas de uso frecuente en Ciencia Abierta. Creación de artículos sobre tecnologías emergentes y Ciencia Abierta. Manejo de redes sociales. ¿Les están pagando algo? No, la comunidad se mantiene gracias al voluntariado que aporta su tiempo libre a la comunidad. Aunque está entre nuestros planes conseguir apoyos para el sostenimiento de nuestra labor.\nTengo algunas sugerencias. ¿Cómo me contacto con OSL? Puedes hacerlo a través de Discord, casi siempre está un administrador que puede responderte. Discord Group\n¿Quiénes dirigen OSL? Tenemos una Junta directiva(Steering Council), la cual se reúne semanalmete para fijar actividades y metas para la comunidad.\n¿Qué tipo de licencia tiene OpenScienceLabs? Todo lo que compartimos está bajo la Licencia CC BY-SA 4.0, es decir que puedes compartir, redistribuir o transformar el material siempre que: se dé el crédito apropiado al autor y que si los transformas se debe distribuir bajo la misma licencia. Para más detalles sobre la licencia puedes visitar la página web de Creative Commons Attribution-ShareAlike 4.0 Internacional.\n¿Cuál es su motivación para aportar a la comunidad Open Source? Creemos que la educación y la tecnología deberían ser lo más accesible posible para todos. Y para lograrlo ¡OpenScienceLabs es un buen lugar!\n","link":"https://opensciencelabs.org/faq/","section":"","tags":null,"title":""},{"body":" Open Science Labs Partners OSL is a Open-Source community and everyone can join, check our GitHub to be apart of the issues. Partners AlertaDengue InfoDengue is an early-warning system to all states of Brazil, the system is based on the continuous analysis of hybrid data generated through the research of climate and epidemiological data and social scraping.\nEpiGraphHub Health Data Hub \u0026amp; Data Analysis Ecosystem for Rapid Epidemic Outbreak Response.\nArxLang Arx compiler aims to provide arrow datatypes as native datatypes.\npyOpenSci pyOpenSci promotes open and reproducible research through peer-review of scientific Python packages.\nA Python package for data structures and algorithms.\nInstitute for Globally Distributed Open Research and Education (IGDORE) is an independent research institute dedicated to improving the quality of science, science education, and quality of life for scientists, students and their families. ","link":"https://opensciencelabs.org/partners/","section":"","tags":null,"title":""},{"body":"","link":"https://opensciencelabs.org/acknowledges/","section":"acknowledges","tags":null,"title":"Acknowledges"},{"body":"","link":"https://opensciencelabs.org/series/","section":"series","tags":null,"title":"Series"}]